{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7hYqUsxYQtl"
      },
      "source": [
        "# (LoRA) Fine-tuning Stablelm2 LLM\n",
        "\n",
        "### This notebook is meant for running only on google colab.\n",
        "\n",
        "The objective of this colab notebook is to finetune an LLM that accurately responds to UOB Banking Contents as part of our TDP Capstone Project.\n",
        "\n",
        "The outline of this notebook is as follow:\n",
        "\n",
        "> 1. Identifying the LLM to finetune on (HF model)\n",
        "> 2. Configuring and quantising the model with qLoRA\n",
        "> 3. Loading and structuring the dataset\n",
        "> 4. Finetuning the LLM based on parameter config\n",
        "> 5. Exporting and deploying the model to Ollama\n",
        "\n",
        "Information on model finetuning have been referenced from the following websites\n",
        "- [Fine-Tuning Ollama Models with Unsloth](https://medium.com/@yuxiaojian/fine-tuning-ollama-models-with-unsloth-a504ff9e8002)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23m6t8pd86xs"
      },
      "source": [
        "### Pre Fine-Tuning Checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvFaMmwL9DNQ",
        "outputId": "df9de115-b5fd-44bb-879c-a533694344fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Oct  1 14:19:15 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT-8d3vZYG4W"
      },
      "source": [
        "### Imports and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XeaOnjP2zsy-",
        "outputId": "5ea06d8f-f57f-4bbb-f49e-9e173d448870"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting auto-gptq\n",
            "  Downloading auto_gptq-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.34.2)\n",
            "Collecting datasets (from auto-gptq)\n",
            "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.26.4)\n",
            "Collecting rouge (from auto-gptq)\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting gekko (from auto-gptq)\n",
            "  Downloading gekko-1.2.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (2.4.1+cu121)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.4.5)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (4.44.2)\n",
            "Collecting peft>=0.5.0 (from auto-gptq)\n",
            "  Downloading peft-0.13.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (4.66.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->auto-gptq) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->auto-gptq) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->auto-gptq) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->auto-gptq) (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (2024.6.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (0.19.1)\n",
            "Collecting pyarrow>=15.0.0 (from datasets->auto-gptq)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->auto-gptq)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (2.1.4)\n",
            "Collecting xxhash (from datasets->auto-gptq)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets->auto-gptq)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (3.10.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge->auto-gptq) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->auto-gptq) (2.1.5)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->auto-gptq) (1.3.0)\n",
            "Downloading auto_gptq-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.13.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.5/322.5 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gekko-1.2.1-py3-none-any.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, rouge, pyarrow, gekko, dill, multiprocess, peft, datasets, auto-gptq\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed auto-gptq-0.7.1 datasets-3.0.1 dill-0.3.8 gekko-1.2.1 multiprocess-0.70.16 peft-0.13.0 pyarrow-17.0.0 rouge-1.0.1 xxhash-3.5.0\n",
            "Collecting optimum\n",
            "  Downloading optimum-1.22.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting coloredlogs (from optimum)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum) (1.13.3)\n",
            "Requirement already satisfied: transformers<4.45.0,>=4.29 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<4.45.0,>=4.29->optimum) (4.44.2)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.10/dist-packages (from optimum) (2.4.1+cu121)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from optimum) (24.1)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from optimum) (1.26.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from optimum) (0.24.7)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from optimum) (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (2024.6.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->optimum) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->optimum) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<4.45.0,>=4.29->transformers[sentencepiece]<4.45.0,>=4.29->optimum) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.45.0,>=4.29->transformers[sentencepiece]<4.45.0,>=4.29->optimum) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<4.45.0,>=4.29->transformers[sentencepiece]<4.45.0,>=4.29->optimum) (0.19.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<4.45.0,>=4.29->optimum) (3.20.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<4.45.0,>=4.29->optimum) (0.2.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->optimum)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (2.1.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (3.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11->optimum) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum) (1.16.0)\n",
            "Downloading optimum-1.22.0-py3-none-any.whl (453 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.7/453.7 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, optimum\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 optimum-1.22.0\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.4.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.44.1\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.18.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.15.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading wandb-0.18.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.15.0-py2.py3-none-any.whl (310 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.0/311.0 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.15.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.18.2\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.4.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.24.7)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.4.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.34.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install auto-gptq\n",
        "!pip3 install optimum\n",
        "!pip3 install bitsandbytes\n",
        "!pip3 install wandb\n",
        "!pip3 install transformers\n",
        "!pip3 install accelerate\n",
        "!pip3 install peft\n",
        "!pip3 install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfSl5xRs0y8J",
        "outputId": "2326ac40-b625-4f5b-9159-019c7cb48af4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:auto_gptq.nn_modules.qlinear.qlinear_cuda:CUDA extension not installed.\n",
            "WARNING:auto_gptq.nn_modules.qlinear.qlinear_cuda_old:CUDA extension not installed.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, set_seed, Trainer, AutoModel\n",
        "from peft import LoraConfig, get_peft_model, PeftModel, prepare_model_for_kbit_training\n",
        "from auto_gptq import AutoGPTQForCausalLM, BaseQuantizeConfig\n",
        "from datasets import load_dataset, Dataset\n",
        "from google.colab import files\n",
        "\n",
        "import transformers\n",
        "import pandas as pd\n",
        "import json\n",
        "import torch\n",
        "import os\n",
        "import gc\n",
        "import wandb\n",
        "import uuid\n",
        "import shutil\n",
        "\n",
        "\n",
        "from accelerate import Accelerator\n",
        "from functools import partial\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pfPbZns-6mc"
      },
      "source": [
        "Before we define the model and tokeniser from our parent model (i.e HF), we will establish the key variables: accelerator, set_seed() and run_id\n",
        "\n",
        "> Accelerator: This refers to hardware components like GPUs or TPUs, which accelerate model training or inference. In the context of Hugging Face’s LLM, this ensures that models are properly allocated to available hardware (e.g., CPUs, GPUs, or even multiple GPUs) without requiring you to manually manage device placement.\n",
        "\n",
        "> set_seed(): This ensures reproducibility by fixing the random seed. In machine learning, some aspects of model training, such as weight initialization or shuffling of data, can introduce randomness.\n",
        "\n",
        "> run_id: This is a unique identifier for a specific training or fine-tuning session. It’s typically used in logging frameworks like WandB (Weights and Biases) or TensorBoard to track individual runs. This variable helps in managing and comparing different experiments, making it easier to analyze metrics such as loss, accuracy, and other performance indicators across multiple runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MrvBk36cyMO2"
      },
      "outputs": [],
      "source": [
        "accelerator = Accelerator()\n",
        "set_seed(42)\n",
        "run_id = str(uuid.uuid4())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVstnrh-0m2x"
      },
      "source": [
        "### Load Model and Tokenizer from HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371,
          "referenced_widgets": [
            "5653ac1286fb4fd48265e4f2a87c1fea",
            "49ce788a98a345519a5d5748f6214e25",
            "60e78d6539414a0f841c49b2a17554eb",
            "9079a2eac26441caa0003091d4a0bb86",
            "7f6a46b74d6e4c9cbe351a8ff5539348",
            "5b1dbc2613844998a9b885cf0a27406b",
            "b118f0b8d6274bb0877057bccc4724ab",
            "4a24b11079ed4dffa5e709d2fcd6a935",
            "77378f5ffd144bd3816eb22d0e82bf9d",
            "3434046db9ce4c4e886f1a19540bafc0",
            "df46052c6ad34b869a24f15e9f18f471",
            "0d33255960fb4500ba4fbb6d4f8ac70b",
            "fa126eea47bc47eab85f04528586a702",
            "1b83eb86128642cdb7461970fbcdd814",
            "f4fe561341d244c48c14e45f5daabfd5",
            "92c50421005347c083e114673c137636",
            "ae0df6f2ecb5434c8c2a4da20e57e871",
            "989f3ae751404deb9cc1f496fb1386a1",
            "4a8d463f7a754ac1a3821ee563df3cd9",
            "d73e13bd537b4409a70c0492d01ede03",
            "57dc961c243b4d9a88f7512fc036cae2",
            "38d31a9345a54b36afb185991b289eb8",
            "c09978d8ce6d4c1c857fd0bf84d0baaa",
            "6c9a54cd07f94024a717002536e88e0e",
            "2ee9ea9c164c43b0b51e722053ec2c6d",
            "60174b47f1fb4c968a90fff592ca5ad0",
            "4b237243c5b14dadb7aafaaf9ad56d7f",
            "28b06d3f34c3487db5a949680e7af2fb",
            "611289e800484b739a452f6972beabf5",
            "26b8018898ba457cbe99f862b6a7d35b",
            "6c57cce9fb044bec805fabf17dd13430",
            "af8502dd84ca461ba2007b05fc8c3905",
            "f9ba62604f0e42c69e66d470749895ac",
            "920c8c71fa1447fb9e8713240f59e754",
            "9675b71001a7498faba5fea6c2ecc3bd",
            "d69bc87d52f74657a087a8499d931524",
            "f800765a9e3e4e12a0b114c98780f706",
            "eece0ba8d45b460e95c7c7b94a4fc64f",
            "0201f1448c0249b89b2fe71bd874fda7",
            "0962fbf95241460aab6348e7f73185d9",
            "55683e303a3e477ea7a9f1e7bc582ac3",
            "da2e325a62e3473389846d1d35bb9f56",
            "f9fa68db8e804f47bd251e29b17a0640",
            "3ae0f756e3834aa1816b3c97cdd48d44",
            "1ea19c77a3354775ba855808159e796d",
            "e282227485bf44388be7f7e798f19488",
            "c9ab56284a1348ba80a894a11520929b",
            "628edcaad42c49fc99d8124aa03046e0",
            "070a1e66e98940eb95d3cef2a4d99d9e",
            "94de1d60000c4bcdb9a012781d991388",
            "8e7d3b7aaab345b6afe30a0f1ccd3224",
            "22a7a65991234125a4311e75552263cf",
            "4b5966fd1e06425f917fdf65c5936a9c",
            "7cd4e20b2cce48f581cd8f8bb3e6a316",
            "05abd2e1e4f947b2b54bd9b52df3a9a8",
            "3468089bb5ee470c92391a1017b824d6",
            "c01d5a76b93d4980a7403360e677a595",
            "090eb5b8a1c2402eb9e698c10f7b104d",
            "e3c841d07aff448b8dbfc597672b7848",
            "6b8e8c9dbc9042c2ba70db5041341bca",
            "1f7284253958462ea4c543a80a773c03",
            "c48dc25df06e403ba89f8df778162286",
            "4e27a37a2d554637964b940ded4a3add",
            "db31141c74564eafb9115c3e66c85978",
            "b8f7ce9232cb4a3f844eefc4f910ac78",
            "c48d320ce6a540859c2d16d92ce34a87",
            "83ff78060dc94bd980f920d93364c0da",
            "cbf670d03cb04ad0a5e7d8acc4177bbd",
            "636599867a984788876f71746ac61306",
            "49bd504e600d469ebd41857c5f193090",
            "994046c4a89d4319b481403aeb2518e6",
            "f4997d0bd24746c59f46760c2e321dea",
            "fc0899a34b3a41f68099c914a73ba595",
            "dd35c4a339214fc380b289f4bff2464a",
            "86eb74d22fe14228a3eb4e155d3a75d8",
            "e466de9d9aab4f24a8b34945eab163ef",
            "12c84a660401439cb322aa2008a19a0f",
            "8b91b9cd20634b23b9a2e683241854d1",
            "b5d26b29ddaf49e6878306f267d0c6a6",
            "5104a78a08174ea6865cd8b402a04705",
            "eda5fead2f124a41a074af2d6b1f31aa",
            "398d2114becd4bf78ba290b2d7e301ec",
            "8b69b96a7eb842b69630f069543ca8fb",
            "584e5da9547d4ff7bc90adf28ffb5a0d",
            "f032c1f9646847c8a5745808634d12f4",
            "f66101576b9a4d63b8802c52e0e0f69a",
            "a8998522442b4ee9ac6da7764bf7263c",
            "c018cecf43f248d79b3c649d4d4d9280"
          ]
        },
        "id": "GFcKal6c96su",
        "outputId": "93685854-19b0-417c-f268-6fc4b0bb5194"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5653ac1286fb4fd48265e4f2a87c1fea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d33255960fb4500ba4fbb6d4f8ac70b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.29G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c09978d8ce6d4c1c857fd0bf84d0baaa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/121 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "920c8c71fa1447fb9e8713240f59e754",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/895 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ea19c77a3354775ba855808159e796d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/2.01M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3468089bb5ee470c92391a1017b824d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/917k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83ff78060dc94bd980f920d93364c0da",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b91b9cd20634b23b9a2e683241854d1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/784 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "  \"stabilityai/stablelm-2-1_6b\",\n",
        "  device_map=\"auto\",\n",
        "  torch_dtype=\"auto\"\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "  \"stabilityai/stablelm-2-1_6b\",\n",
        "  trust_remote_code=True,\n",
        "  use_fast=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnFiyBOc329l"
      },
      "source": [
        "### Using Base Model to test Pre-Training Performance\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOZOwyO4thX-"
      },
      "outputs": [],
      "source": [
        "# model.cuda()\n",
        "\n",
        "# inputs = tokenizer(\"The weather is always wonderful\", return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "# tokens = model.generate(\n",
        "#   **inputs,\n",
        "#   max_new_tokens=64,\n",
        "#   temperature=0.70,\n",
        "#   top_p=0.95,\n",
        "#   do_sample=True,\n",
        "# )\n",
        "\n",
        "# print(tokenizer.decode(tokens[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXc8pBsVIy2N"
      },
      "source": [
        "### Prepare Model for Training\n",
        "\n",
        "> model.train(): This switches the model to training mode. Since certain layers in the model behave differently compared to inference (evaluation) mode. (e.g layers like dropout and batch normalization are activated in training mode), running the train() command ensures that these components behave correctly for training\n",
        "\n",
        "> model.gradient_checkpointing_enable(): In large models, storing all the intermediate activations during the forward pass can use up a lot of memory, especially when training on GPUs. This line enables gradient checkpointing for the model, which can be particularly useful when working with large transformer models that require substantial GPU memory.\n",
        "\n",
        "> prepare_model_for_kbit_training(model): This line prepares the model for k-bit quantized training. Quantized training reduces the precision of the model weights from 32-bit floating-point numbers (commonly used in deep learning) to a smaller number of bits, such as 8-bit or 4-bit (k-bits). This can greatly reduce the memory footprint of the model and accelerate the training process by using more compact representations of the weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "K3PesDIyI1Hn"
      },
      "outputs": [],
      "source": [
        "model.train() # model in training mode (dropout modules are activated)\n",
        "\n",
        "# enable gradient check pointing\n",
        "model.gradient_checkpointing_enable()\n",
        "\n",
        "# enable quantized training\n",
        "model = prepare_model_for_kbit_training(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cloHRp4BiOj"
      },
      "source": [
        "Low-Rank Adaptation (LoRA) is a technique used to reduce the number of trainable parameters in large models, which makes the overall fine-tuning more efficient.\n",
        "\n",
        "> <b>r</b>: This is the rank of the low-rank adaptation. In LoRA, instead of updating the full model weights, a low-rank matrix is trained, and r determines the size of this matrix. A lower r means fewer parameters, making the training more efficient.\n",
        "\n",
        "> <b>lora_alpha</b>: This is a scaling factor for LoRA. After the low-rank adaptation, the result is scaled by this factor to control the magnitude of updates. It adjusts the learning rate for the low-rank adaptation.\n",
        "\n",
        "> <b>target_modules</b>: This specifies which parts of the model should use LoRA. In this case, specifying (q_proj) module means that 'query projection' of the transformer will be adapted using LoRA. LoRA can be applied selectively to certain layers or components to reduce computational overhead while still effectively fine-tuning the model.\n",
        "\n",
        "> <b>lora_dropout</b>: LoRA introduces dropout in the low-rank matrices to prevent overfitting. A value of 0.05 means that 5% of the weights in the low-rank adaptation will be dropped out during training.\n",
        "\n",
        "> <b>bias</b>: This specifies how biases are treated. In this case, the bias terms in the model are not trainable (none), meaning that only the LoRA-adapted parts of the model are modified during training.\n",
        "\n",
        "> <b>task_type</b>: This defines the type of task the model is being trained for. Here, the task is Causal Language Modeling (CAUSAL_LM), which is commonly used in autoregressive models like GPT, where the model predicts the next word in a sequence based on previous words.\n",
        "\n",
        "Once we have defined the LoRA config, we will run the peft function (Parameter-Efficient Fine-Tuning)\n",
        "\n",
        "> <b>get_peft_model()</b>: PEFT wraps the original model with the LoRA-adapted layers, so that only the specified target_modules (in this case, the q_proj) are fine-tuned using the low-rank adaptation, while the rest of the model remains frozen (not updated). This approach significantly reduces the number of trainable parameters, making fine-tuning much more memory-efficient and computationally cheaper, especially for very large models\n",
        "\n",
        "> <b>print_trainable_parameters()</b>: This prints out the number of trainable parameters in the model. Since LoRA only fine-tunes a small portion of the model (in this case, the query projection), this number will be much smaller than the full parameter count of the original model. This is useful for understanding the efficiency gains provided by LoRA, as it highlights the reduction in the number of parameters that need to be updated during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXOHXZcII5FS",
        "outputId": "cd6032c8-e7f1-4d26-8ce4-51e70e42a5cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 786,432 || all params: 1,645,301,760 || trainable%: 0.0478\n"
          ]
        }
      ],
      "source": [
        "# LoRA config\n",
        "config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\"], # You can specify more targetted modules here, but it could impact the overall computational time (e.g [\"q_proj\", \"v_proj\", \"k_proj\", \"out_proj\"])\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "# LoRA trainable version of model\n",
        "model = get_peft_model(model, config)\n",
        "\n",
        "# Trainable parameter count\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tssCKXx3hUqM"
      },
      "source": [
        "### Preparing Dataset\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOZczP9G1YJ1"
      },
      "source": [
        "### Variable Instantiation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5s5ZdMt4v3pn"
      },
      "outputs": [],
      "source": [
        "dataset_name=\"LLM Model Training\"\n",
        "modelpath=\"stabilityai/stablelm-2-1_6b\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxiohUbEuJKQ",
        "outputId": "9bd06792-c555-40fd-f941-b045f0622c6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train.csv  training.json\n",
            "File exists! Formatting dataset...\n"
          ]
        }
      ],
      "source": [
        "!ls \"/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/datasets/\" # Check the contents of the folder\n",
        "file_path = '/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/datasets/train.csv' # Check if the file exists\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "  print(\"File exists! Formatting dataset...\")\n",
        "  data = pd.read_csv(file_path)\n",
        "  data = data[['user_input', 'response']]\n",
        "\n",
        "  formatted = {}\n",
        "  formatted['conversation'] = []\n",
        "  for index, row in data.iterrows():\n",
        "    formatted['conversation'].append({\n",
        "      \"content\": row['user_input'],\n",
        "      \"role\": \"user\"\n",
        "    })\n",
        "    formatted['conversation'].append({\n",
        "      \"content\": row['response'],\n",
        "      \"role\": \"assistant\"\n",
        "    })\n",
        "\n",
        "  with open(\"/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/datasets/training.json\", \"w\") as json_file:\n",
        "    json.dump(formatted, json_file, indent=2)\n",
        "else:\n",
        "  print(\"File not found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoPlBzBCwVEN"
      },
      "source": [
        "### Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZgsbJYtwnTz",
        "outputId": "6e97f0ac-ddd0-4a0e-ee66-16e936fcbd77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'content': 'How can I sign up for the TMRW app?', 'role': 'user'},\n",
              " {'content': 'You can sign up for the TMRW app via our website or directly on the app from the App Store.',\n",
              "  'role': 'assistant'},\n",
              " {'content': 'What documents do I need to apply for a credit card?',\n",
              "  'role': 'user'},\n",
              " {'content': \"You'll need your NRIC, latest income documents, and proof of residence to apply for a credit card.\",\n",
              "  'role': 'assistant'},\n",
              " {'content': 'How can I apply for a personal loan?', 'role': 'user'},\n",
              " {'content': 'You can apply for a personal loan through our online banking portal or by visiting a UOB branch.',\n",
              "  'role': 'assistant'},\n",
              " {'content': \"Quels services d'investissement proposez-vous ?\",\n",
              "  'role': 'user'},\n",
              " {'content': \"UOB propose des options d'investissement telles que des fonds communs, des obligations et des dépôts structurés.\",\n",
              "  'role': 'assistant'},\n",
              " {'content': 'How do I check my TMRW app balance?', 'role': 'user'}]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open(\"/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/datasets/training.json\", 'r') as json_file:\n",
        "  training = json.load(json_file)\n",
        "\n",
        "training['conversation'][0:9]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY1VHiucDdkA"
      },
      "source": [
        "Be sure to read up on the documentation of each LLM used for finetuning at the [official website](https://ollama.com/library)\n",
        "\n",
        "In the case of StableLM2, which is a significantly smaller LLM compared to models like Mistral and LLama3, the prompt-response interaction used during its fine-tuning can be seen below:\n",
        "\n",
        "```\n",
        "{{ if .System }}<|im_start|>system\n",
        "{{ .System }}<|im_end|>\n",
        "{{ end }}{{ if .Prompt }}<|im_start|>user\n",
        "{{ .Prompt }}<|im_end|>\n",
        "{{ end }}<|im_start|>assistant\n",
        "{{ .Response }}<|im_end|>\n",
        "```\n",
        "\n",
        "What this means is that the dataset should contain the following information:\n",
        "\n",
        "> System Message (Optional): If provided, a system message sets the context or defines how the assistant should behave (e.g., polite, informative, task-specific). It is optional and only included if needed.\n",
        "\n",
        "> User Message (Prompt): The user's input (a question, command, or request) is always included when it exists. This forms the core of the conversation, and the model uses it to generate its response.\n",
        "\n",
        "> Assistant Response: This is the generated output from the model, representing the assistant's reply to the user’s input.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqWGy2UBI8bo",
        "outputId": "bfe57724-81c8-4051-aa34-9859b05f294d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['conversations'],\n",
              "        num_rows: 425\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['conversations'],\n",
              "        num_rows: 48\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pairs = []\n",
        "for i in range(0, len(training['conversation'])-1, 2):  # step by 2 to get pairs of user and assistant\n",
        "  if training['conversation'][i]['role'] == 'user' and training['conversation'][i+1]['role'] == 'assistant':\n",
        "    pairs.append([\n",
        "      {'content': training['conversation'][i]['content'], 'role': training['conversation'][i]['role']},\n",
        "      {'content': training['conversation'][i+1]['content'], 'role': training['conversation'][i+1]['role']}\n",
        "    ])\n",
        "\n",
        "custom_dataset = Dataset.from_dict({\n",
        "  \"conversations\": pairs\n",
        "})\n",
        "\n",
        "dataset_split = custom_dataset.train_test_split(test_size=0.1)\n",
        "dataset_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6elVw4Zxjgt"
      },
      "source": [
        "### EOS and Model Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n25nU6uYEyu6"
      },
      "source": [
        "The following code snippet deals with setting up the end-of-sequence (EOS) token for the tokenizer and model configuration, and it also defines templates for message formatting. In addition, it introduces a specific value for ignored tokens during loss calculation.\n",
        "\n",
        "\n",
        "> tokenizer.encode(\"<|im_end|>\")[0]: Encodes the token \"<|im_end|>\" using the tokenizer, turning it into a sequence of token IDs. The [0] is used to extract the first token ID from the encoded result, which corresponds to the end-of-sequence marker.\n",
        "\n",
        "> tokenizer.eos_token_id: This sets the eos_token_id (end-of-sequence token) in the tokenizer to the token ID corresponding to \"<|im_end|>\".\n",
        "model.config.eos_token_id = tokenizer.eos_token_id: After setting the EOS token ID for the tokenizer, the same token ID is applied to the model configuration. This ensures that both the tokenizer and the model understand what token to look for to mark the end of a sequence. The EOS token is typically used to signal the end of a generated sequence, ensuring that the model knows when to stop predicting.\n",
        "\n",
        "Once that is done, we will specify the format when they are passed to the model. Each template wraps the message ({msg}) with the respective special tokens to distinguish between the user's and assistant's parts in a conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6Ck3A4Q-xmWt"
      },
      "outputs": [],
      "source": [
        "tokenizer.eos_token_id = tokenizer.encode(\"<|im_end|>\")[0]\n",
        "model.config.eos_token_id = tokenizer.eos_token_id\n",
        "\n",
        "templates = [\n",
        "  \"<|im_start|>assistant\\n{msg}<|im_end|>\",\n",
        "  \"<|im_start|>user\\n{msg}<|im_end|>\"\n",
        "]\n",
        "IGNORE_INDEX=-100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xapGgnQxzBT",
        "outputId": "0c8edf2a-06c8-49e3-ffd8-17ae14dbc9ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): StableLmForCausalLM(\n",
              "      (model): StableLmModel(\n",
              "        (embed_tokens): Embedding(100352, 2048)\n",
              "        (layers): ModuleList(\n",
              "          (0-23): 24 x StableLmDecoderLayer(\n",
              "            (self_attn): StableLmSdpaAttention(\n",
              "              (q_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "              (rotary_emb): StableLmRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): StableLmMLP(\n",
              "              (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
              "              (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
              "              (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "            (post_attention_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (lm_head): Linear(in_features=2048, out_features=100352, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1yssm17x1X2",
        "outputId": "d2f5a6d5-2f51-4d93-c9fb-d5252c909fab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPT2TokenizerFast(name_or_path='stabilityai/stablelm-2-1_6b', vocab_size=100289, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|im_end|>', 'unk_token': '<|endoftext|>', 'additional_special_tokens': ['<|reg_extra|>', '<|endoftext|>', '<|fim_prefix|>', '<|fim_middle|>', '<|fim_suffix|>', '<|fim_pad|>', '<gh_stars>', '<filename>', '<issue_start>', '<issue_comment>', '<issue_closed>', '<jupyter_start>', '<jupyter_text>', '<jupyter_code>', '<jupyter_output>', '<empty_output>', '<commit_before>', '<commit_msg>', '<commit_after>', '<reponame>', '<|endofprompt|>', '<|im_start|>', '<|im_end|>', '<|pause|>', '<|reg0|>', '<|reg1|>', '<|reg2|>', '<|reg3|>', '<|reg4|>', '<|reg5|>', '<|reg6|>', '<|reg7|>', '<|extra0|>']}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
              "\t100256: AddedToken(\"<|reg_extra|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100257: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100258: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100259: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100260: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100261: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100262: AddedToken(\"<gh_stars>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100263: AddedToken(\"<filename>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100264: AddedToken(\"<issue_start>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100265: AddedToken(\"<issue_comment>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100266: AddedToken(\"<issue_closed>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100267: AddedToken(\"<jupyter_start>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100268: AddedToken(\"<jupyter_text>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100269: AddedToken(\"<jupyter_code>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100270: AddedToken(\"<jupyter_output>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100271: AddedToken(\"<empty_output>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100272: AddedToken(\"<commit_before>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100273: AddedToken(\"<commit_msg>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100274: AddedToken(\"<commit_after>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100275: AddedToken(\"<reponame>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100276: AddedToken(\"<|endofprompt|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100277: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100278: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100279: AddedToken(\"<|pause|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100280: AddedToken(\"<|reg0|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100281: AddedToken(\"<|reg1|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100282: AddedToken(\"<|reg2|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100283: AddedToken(\"<|reg3|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100284: AddedToken(\"<|reg4|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100285: AddedToken(\"<|reg5|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100286: AddedToken(\"<|reg6|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100287: AddedToken(\"<|reg7|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100288: AddedToken(\"<|extra0|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YBEvJNc0i9k"
      },
      "source": [
        "### Tokenizing our Data\n",
        "\n",
        "We will define the tokenize and collate functions respectively.\n",
        "\n",
        "\n",
        "> The tokenize function prepares conversational data by converting messages into token IDs, attention masks, and labels. User inputs are ignored during training (label set to IGNORE_INDEX), while assistant responses are the target labels.\n",
        "\n",
        "> The collate function ensures that batches of data are properly padded to the same length, which is necessary for efficient training.\n",
        "\n",
        "> The dataset is then tokenized using the map() function and multithreading, ensuring that it is ready for training in the required format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "7a3f1672e7f546668304e2c2440c30e8",
            "49e000824a744fa997eacf82e857e114",
            "b17bf7633de54da6ba7fc5214823cd37",
            "14fc6131676d49bd9fb9291a7f38b4c9",
            "09380cc645cc442aa316e6e03afe18d7",
            "e0add396f9134d32bd5d85b5582ac747",
            "2a394b972188460a8e1dfd67029a347a",
            "fc245434fabe4912a46860704557278c",
            "9435b6e68b924d1c990fbb3d99c59dfc",
            "575833f960dd4506875881f44fb01949",
            "a09acacb19194fd2b7ae959cb941fb0e",
            "4fe90e4917aa4df5aaf53dcab1b35b3a",
            "15a249fa525c4f5da77ad795ed791f07",
            "3f57c34a13544fb8b57e63e3f6ca62df",
            "ecd8170e95f7459a9b11cb91887e1c39",
            "7170ea832f9a4cb0aa9c7581d743b9b8",
            "d5edf315263f479eac1f44e2a888d34c",
            "6abb9c4a09124dbaa6e6c94c97cf0e89",
            "13f3a584d5594486be19ed7ef9e0fdcf",
            "b0ea52da58b54ec8940ad3c5e8d4722d",
            "59c35900928d41aa886e73a56d28ddd7",
            "f4f46740704e4baa9ceb9d01b63ce3c4"
          ]
        },
        "id": "D9LEA_g9gZPF",
        "outputId": "63e91506-c684-4680-93e5-e10906bbef14"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a3f1672e7f546668304e2c2440c30e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/425 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4fe90e4917aa4df5aaf53dcab1b35b3a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/48 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Defining our tokenize function\n",
        "def tokenize(input, max_length):\n",
        "  input_ids, attention_mask, labels = [], [], []\n",
        "\n",
        "  for i, msg in enumerate(input[\"conversations\"]):\n",
        "    isHuman = msg[\"role\"] == \"user\"\n",
        "    msg_chatml = templates[isHuman].format(msg = msg[\"content\"])\n",
        "    msg_tokenized = tokenizer(msg_chatml, truncation = False, add_special_tokens = False)\n",
        "\n",
        "    input_ids += msg_tokenized[\"input_ids\"]\n",
        "    attention_mask += msg_tokenized[\"attention_mask\"]\n",
        "    labels += [IGNORE_INDEX] * len(msg_tokenized[\"input_ids\"]) if isHuman else msg_tokenized[\"input_ids\"]\n",
        "\n",
        "  return {\n",
        "    \"input_ids\": input_ids[:max_length],\n",
        "    \"attention_mask\": attention_mask[:max_length],\n",
        "    \"labels\": labels[:max_length],\n",
        "  }\n",
        "\n",
        "# Defining our collate function - to transform list of dictionaries [ {input_ids: [123, ..]}, {.. ]\n",
        "# to single batch dictionary { input_ids: [..], labels: [..], attention_mask: [..] }\n",
        "def collate(elements):\n",
        "  tokens = [e[\"input_ids\"] for e in elements]\n",
        "  tokens_maxlen = max([len(t) for t in tokens])\n",
        "\n",
        "  for i, sample in enumerate(elements):\n",
        "    input_ids = sample[\"input_ids\"]\n",
        "    labels = sample[\"labels\"]\n",
        "    attention_mask = sample[\"attention_mask\"]\n",
        "\n",
        "    pad_len = tokens_maxlen-len(input_ids)\n",
        "\n",
        "    input_ids.extend( pad_len * [tokenizer.pad_token_id] )\n",
        "    labels.extend( pad_len * [IGNORE_INDEX] )\n",
        "    attention_mask.extend( pad_len * [0] )\n",
        "\n",
        "  batch = {\n",
        "    \"input_ids\": torch.tensor( [e[\"input_ids\"] for e in elements] ),\n",
        "    \"labels\": torch.tensor( [e[\"labels\"] for e in elements] ),\n",
        "    \"attention_mask\": torch.tensor( [e[\"attention_mask\"] for e in elements] ),\n",
        "  }\n",
        "\n",
        "  return batch\n",
        "\n",
        "# tokenize training and validation datasets\n",
        "dataset_tokenized = dataset_split.map(\n",
        "  partial(tokenize, max_length = 1600),\n",
        "  batched = False,\n",
        "  num_proc = os.cpu_count() // accelerator.num_processes,    # multithreaded\n",
        "  remove_columns = dataset_split[\"train\"].column_names\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTnkedvuGXpb"
      },
      "source": [
        "> Setting the Padding Token: The eos_token is used as the padding token to ensure consistency in how the model handles padding.\n",
        "\n",
        "> Collator Setup: The data collator ensures that the tokenized data is appropriately batched and padded, ready to be fed into the language model for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pow8yLjKcJM8"
      },
      "outputs": [],
      "source": [
        "# setting pad token\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "# data collator\n",
        "data_collator = transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-evbaTxhQTC"
      },
      "source": [
        "### Fine-tuning the LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NZuPvKEGsHs"
      },
      "source": [
        "#### Display pre-finetuning statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEzPJs0XhLBB",
        "outputId": "fab44fdb-3602-49cb-b0a5-4b436f7228ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU = Tesla T4. Max memory = 14.748 GB.\n",
            "7.586 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OO9NzeCK40uM"
      },
      "source": [
        "#### Fine-Tuning Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "e1PPLr4McNii",
        "outputId": "932c95c4-14b8-4741-a933-147e3c8e2eb6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/wandb/out-34fce262-cdc5-44fc-9680-d08ed96a3178/wandb/run-20241001_142634-2c6mq9gp</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/kevintanyj-uob/OA2-finetune/runs/2c6mq9gp' target=\"_blank\">stablelm-2-1_6b_LLM Model Training_bs-4_LR-0.0002_maxlen-1024_34fce262-cdc5-44fc-9680-d08ed96a3178</a></strong> to <a href='https://wandb.ai/kevintanyj-uob/OA2-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/kevintanyj-uob/OA2-finetune' target=\"_blank\">https://wandb.ai/kevintanyj-uob/OA2-finetune</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/kevintanyj-uob/OA2-finetune/runs/2c6mq9gp' target=\"_blank\">https://wandb.ai/kevintanyj-uob/OA2-finetune/runs/2c6mq9gp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [130/130 02:32, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.497700</td>\n",
              "      <td>1.886894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.708500</td>\n",
              "      <td>1.573246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.484400</td>\n",
              "      <td>1.467443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.382600</td>\n",
              "      <td>1.433948</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        }
      ],
      "source": [
        "# hyperparameters\n",
        "lr = 2e-4\n",
        "batch_size = 4\n",
        "num_epochs = 5\n",
        "grad_acc_steps = 4\n",
        "dataset_name=\"LLM Model Training\"\n",
        "modelpath = \"stabilityai/stablelm-2-1_6b\"\n",
        "max_length = 1024\n",
        "output_dir = f'/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/wandb/out-{run_id}'\n",
        "\n",
        "# define training arguments\n",
        "training_args = transformers.TrainingArguments(\n",
        "  output_dir= output_dir,\n",
        "  learning_rate=lr,\n",
        "  per_device_train_batch_size=batch_size,\n",
        "  per_device_eval_batch_size=batch_size,\n",
        "  num_train_epochs=num_epochs,\n",
        "  weight_decay=0.01,\n",
        "  logging_strategy=\"epoch\",\n",
        "  eval_strategy=\"epoch\",\n",
        "  save_strategy=\"epoch\",\n",
        "  load_best_model_at_end=True,\n",
        "  gradient_accumulation_steps=grad_acc_steps,\n",
        "  warmup_steps=2,\n",
        "  fp16=True,\n",
        "  optim=\"paged_adamw_8bit\",\n",
        ")\n",
        "\n",
        "trainer = transformers.Trainer(\n",
        "  model=model,\n",
        "  args=training_args,\n",
        "  data_collator=collate,\n",
        "  train_dataset=dataset_tokenized[\"train\"],\n",
        "  eval_dataset=dataset_tokenized[\"test\"],\n",
        ")\n",
        "\n",
        "# The weights and biases logs are automatically saved on wandb. But we can also view it in the path saved under the google drive\n",
        "if accelerator.is_main_process:\n",
        "  run = wandb.init(\n",
        "    project=\"OA2-finetune\",\n",
        "    dir=output_dir, # Configure accordingly to save the log in google drive. Modify accordingly if run locally\n",
        "    name=\"stabilityai/stablelm-2-1_6b\".split(\"/\")[1]+\"_\"+dataset_name+f\"_bs-{batch_size}_LR-{lr}_maxlen-{max_length}_{run_id}\",\n",
        "    config = {\n",
        "      \"model_name\": \"StableLM2_TDP\",\n",
        "      \"run_id\": run_id,\n",
        "      \"dataset\": dataset_name,\n",
        "      \"output_dir\": output_dir, # Configure accordingly to save the log in google drive. Modify accordingly if run locally\n",
        "      \"lr\": lr,\n",
        "      \"max_length\": max_length,\n",
        "      \"train_batch_size\": batch_size,\n",
        "      \"validation_batch_size\": batch_size,\n",
        "      \"ga_steps\": grad_acc_steps,\n",
        "      \"training_args\": training_args,\n",
        "      \"GPUs\": accelerator.num_processes,\n",
        "    }\n",
        "  )\n",
        "\n",
        "model.config.use_cache = False\n",
        "trainer.save_model(f'/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/llm-adapter/{run_id}')\n",
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOsA6P-yMYmj"
      },
      "source": [
        "#### Show final memory and time stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OS8eKWiQMne4",
        "outputId": "b5e34f0e-59d5-42e0-d1cc-2c8b89138011"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "154.8072 seconds used for training.\n",
            "2.58 minutes used for training.\n",
            "Peak reserved memory = 9.01 GB.\n",
            "Peak reserved memory for training = 1.424 GB.\n",
            "Peak reserved memory % of max memory = 61.093 %.\n",
            "Peak reserved memory for training % of max memory = 9.656 %.\n"
          ]
        }
      ],
      "source": [
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory         /max_memory*100, 3)\n",
        "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3-3yynACoX0"
      },
      "source": [
        "### Push model to huggingface hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_c5KhuhpCno-"
      },
      "outputs": [],
      "source": [
        "# from huggingface_hub import notebook_login\n",
        "# notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8ayZ62aNlrr"
      },
      "source": [
        "### Clear the memory\n",
        "\n",
        "> gc.collect(): Forces the Python garbage collector to release memory that is no longer in use. In situations where there are circular references (e.g., objects referencing each other), the garbage collector may not automatically free that memory. This helps in reclaiming that memory, which is especially useful in long-running scripts or training loops where memory usage might increase over time, leading to potential out-of-memory errors.\n",
        "\n",
        "> empty_cache(): It releases all unused memory that PyTorch has cached on the GPU. This is helpful when you need to reduce GPU memory usage, especially after large tensor computations or when switching between different models during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rJfWVc5LNocf"
      },
      "outputs": [],
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AnhaAKjPHVa"
      },
      "source": [
        "Rerun the necessary imports for the model export. We no longer need other libraries stated at the start."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9GNTNudSPMwZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "from peft import PeftModel\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C-lPkKv4aS-"
      },
      "source": [
        "### Save the Fine-Tuned Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV7cDjhJFZ7Q",
        "outputId": "223904b8-c08b-42d9-8f3d-2f9c777d65c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folder created at: /content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/fine-tuned\n"
          ]
        }
      ],
      "source": [
        "# Define the path where you want to create the folders\n",
        "model_saved_path = '/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/fine-tuned'\n",
        "# os.makedirs(model_saved_path, exist_ok=True) # Create the folder. Comment or delete this statement after running once\n",
        "print(f\"Folder created at: {model_saved_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBRx0FM8Et7Q"
      },
      "source": [
        "1. On google colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8Q5TB9dEwfn",
        "outputId": "1c15e047-a3ae-4207-9529-a64ff78be991"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/fine-tuned/tdp_stablelm2_ft/tokenizer_config.json',\n",
              " '/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/fine-tuned/tdp_stablelm2_ft/special_tokens_map.json',\n",
              " '/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/fine-tuned/tdp_stablelm2_ft/vocab.json',\n",
              " '/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/fine-tuned/tdp_stablelm2_ft/merges.txt',\n",
              " '/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/fine-tuned/tdp_stablelm2_ft/added_tokens.json',\n",
              " '/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/fine-tuned/tdp_stablelm2_ft/tokenizer.json')"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained(f'{model_saved_path}/tdp_stablelm2_ft')\n",
        "tokenizer.save_pretrained(f'{model_saved_path}/tdp_stablelm2_ft')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD0vuBkKEr6S"
      },
      "source": [
        "2. On Local Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "id": "uxgV2B4J4dJm",
        "outputId": "061c6ca1-d968-4bc2-ffb6-1030f7d0ad3c"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_cff8eb00-26d2-40f7-b002-b149458e00b6\", \"tdp_stablelm2_ft.zip\", 5366238)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# model.save_pretrained('./tdp_stablelm2_ft')\n",
        "# tokenizer.save_pretrained('./tdp_stablelm2_ft')\n",
        "\n",
        "# # Zip the saved model directory\n",
        "# shutil.make_archive('tdp_stablelm2_ft', 'zip', './tdp_stablelm2_ft')\n",
        "\n",
        "# files.download('tdp_stablelm2_ft.zip')\n",
        "\n",
        "\n",
        "# RUN THIS IF YOU RAN THE CODE ABOVE TO SAVE COPY ON GOOGLE DRIVE\n",
        "# Zip the saved model directory\n",
        "# shutil.make_archive('tdp_stablelm2_ft', 'zip', f'{model_saved_path}/tdp_stablelm2_ft')\n",
        "\n",
        "# Download the zipped file (optional)\n",
        "# files.download(f'{model_saved_path}/tdp_stablelm2_ft.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usT78VPP5Zpm"
      },
      "source": [
        "### Loading the Fine-Tuned Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQcfGEea5YIA",
        "outputId": "c7044611-6f3e-4dd7-bd08-a9b4570ca607"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Loading adapter weights from ./tdp_stablelm2_ft led to unexpected keys not found in the model:  ['model.layers.0.self_attn.q_proj.lora_A.default.weight', 'model.layers.0.self_attn.q_proj.lora_B.default.weight', 'model.layers.1.self_attn.q_proj.lora_A.default.weight', 'model.layers.1.self_attn.q_proj.lora_B.default.weight', 'model.layers.10.self_attn.q_proj.lora_A.default.weight', 'model.layers.10.self_attn.q_proj.lora_B.default.weight', 'model.layers.11.self_attn.q_proj.lora_A.default.weight', 'model.layers.11.self_attn.q_proj.lora_B.default.weight', 'model.layers.12.self_attn.q_proj.lora_A.default.weight', 'model.layers.12.self_attn.q_proj.lora_B.default.weight', 'model.layers.13.self_attn.q_proj.lora_A.default.weight', 'model.layers.13.self_attn.q_proj.lora_B.default.weight', 'model.layers.14.self_attn.q_proj.lora_A.default.weight', 'model.layers.14.self_attn.q_proj.lora_B.default.weight', 'model.layers.15.self_attn.q_proj.lora_A.default.weight', 'model.layers.15.self_attn.q_proj.lora_B.default.weight', 'model.layers.16.self_attn.q_proj.lora_A.default.weight', 'model.layers.16.self_attn.q_proj.lora_B.default.weight', 'model.layers.17.self_attn.q_proj.lora_A.default.weight', 'model.layers.17.self_attn.q_proj.lora_B.default.weight', 'model.layers.18.self_attn.q_proj.lora_A.default.weight', 'model.layers.18.self_attn.q_proj.lora_B.default.weight', 'model.layers.19.self_attn.q_proj.lora_A.default.weight', 'model.layers.19.self_attn.q_proj.lora_B.default.weight', 'model.layers.2.self_attn.q_proj.lora_A.default.weight', 'model.layers.2.self_attn.q_proj.lora_B.default.weight', 'model.layers.20.self_attn.q_proj.lora_A.default.weight', 'model.layers.20.self_attn.q_proj.lora_B.default.weight', 'model.layers.21.self_attn.q_proj.lora_A.default.weight', 'model.layers.21.self_attn.q_proj.lora_B.default.weight', 'model.layers.22.self_attn.q_proj.lora_A.default.weight', 'model.layers.22.self_attn.q_proj.lora_B.default.weight', 'model.layers.23.self_attn.q_proj.lora_A.default.weight', 'model.layers.23.self_attn.q_proj.lora_B.default.weight', 'model.layers.3.self_attn.q_proj.lora_A.default.weight', 'model.layers.3.self_attn.q_proj.lora_B.default.weight', 'model.layers.4.self_attn.q_proj.lora_A.default.weight', 'model.layers.4.self_attn.q_proj.lora_B.default.weight', 'model.layers.5.self_attn.q_proj.lora_A.default.weight', 'model.layers.5.self_attn.q_proj.lora_B.default.weight', 'model.layers.6.self_attn.q_proj.lora_A.default.weight', 'model.layers.6.self_attn.q_proj.lora_B.default.weight', 'model.layers.7.self_attn.q_proj.lora_A.default.weight', 'model.layers.7.self_attn.q_proj.lora_B.default.weight', 'model.layers.8.self_attn.q_proj.lora_A.default.weight', 'model.layers.8.self_attn.q_proj.lora_B.default.weight', 'model.layers.9.self_attn.q_proj.lora_A.default.weight', 'model.layers.9.self_attn.q_proj.lora_B.default.weight']. \n",
            "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BaseModelOutputWithPast(last_hidden_state=tensor([[[ -5.2231,   2.3152,  -4.0828,  ...,   8.7993,   3.0453,  -0.8264],\n",
            "         [ -2.6569,   1.4298,  -3.7546,  ...,   8.7502,   3.0141,   2.1007],\n",
            "         [ -3.7972,   0.2874, -10.5286,  ...,   9.0043,  -1.4867,   2.3723],\n",
            "         ...,\n",
            "         [ -0.8138,  -4.1902,  -6.1144,  ...,  -0.2880,  -0.9248,   0.6036],\n",
            "         [ -3.7965,  -5.7221,  -8.9033,  ...,  -3.1065,   4.0865,  -1.0431],\n",
            "         [ -2.8160,  -2.0190,   2.5456,  ...,   4.1146,   4.4637,   1.2360]]]), past_key_values=((tensor([[[[-2.2908e+00,  8.6010e+00,  2.1892e-01,  ...,  9.3315e-01,\n",
            "           -9.6343e-01, -7.3244e-01],\n",
            "          [ 6.2671e-01,  8.2429e+00,  1.6056e-01,  ...,  7.7811e-01,\n",
            "           -1.0604e+00, -8.0578e-01],\n",
            "          [ 2.9366e+00,  6.8564e+00,  1.5531e-01,  ...,  1.2075e+00,\n",
            "           -1.0381e+00, -8.2465e-01],\n",
            "          ...,\n",
            "          [ 3.4593e+00, -8.6954e+00,  3.4498e-03,  ..., -1.9549e-01,\n",
            "           -8.1097e-01, -6.1023e-01],\n",
            "          [ 9.5302e-01, -9.6312e+00,  9.1087e-01,  ..., -2.2063e-01,\n",
            "           -4.1216e-01, -4.0971e-02],\n",
            "          [-1.5640e+00, -7.8444e+00, -4.5473e-02,  ...,  1.0701e+00,\n",
            "           -1.0251e+00, -7.1659e-01]],\n",
            "\n",
            "         [[ 5.6381e-02, -1.1150e-01, -1.0205e-01,  ..., -8.6139e-01,\n",
            "           -8.9666e-01, -8.1554e-01],\n",
            "          [ 3.6770e-02,  2.8869e-02, -3.3709e-02,  ..., -9.4605e-01,\n",
            "           -1.0032e+00, -9.3192e-01],\n",
            "          [ 4.3075e-03, -1.7546e-02,  3.4709e-02,  ..., -9.4303e-01,\n",
            "           -9.7554e-01, -8.8638e-01],\n",
            "          ...,\n",
            "          [-7.9821e-01,  1.4672e+00, -1.3098e+00,  ..., -1.3311e-01,\n",
            "           -2.0852e-01, -1.1005e-01],\n",
            "          [-1.9586e-01,  2.5059e-01, -3.5059e-01,  ..., -5.6319e-01,\n",
            "           -6.0920e-01, -5.2549e-01],\n",
            "          [ 5.4003e-02, -6.3230e-02,  4.7263e-02,  ..., -1.0189e+00,\n",
            "           -9.6845e-01, -9.2100e-01]],\n",
            "\n",
            "         [[-4.4399e-01,  4.6059e-01, -4.4284e-01,  ...,  4.1735e-01,\n",
            "           -5.0080e-01,  2.8895e-01],\n",
            "          [-6.3634e-02,  5.9833e-02,  7.9677e-02,  ...,  1.1487e+00,\n",
            "           -9.1450e-01,  7.0775e-01],\n",
            "          [ 6.3019e-02,  1.8266e-02,  1.6287e-01,  ...,  1.1597e+00,\n",
            "           -9.6006e-01,  7.2113e-01],\n",
            "          ...,\n",
            "          [-3.4903e-02, -3.0859e-02,  3.0983e-01,  ...,  1.0869e+00,\n",
            "           -5.5230e-01,  4.5020e-01],\n",
            "          [-4.9046e-03, -6.2614e-02, -7.7729e-02,  ...,  7.6375e-01,\n",
            "           -7.0875e-01,  2.4993e-01],\n",
            "          [ 1.2724e-02, -1.4500e-01, -5.0914e-01,  ...,  1.3107e+00,\n",
            "           -9.9779e-01, -1.8574e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.2296e-02, -5.9842e-01, -5.4513e-01,  ..., -5.5616e-01,\n",
            "            1.8290e+00, -2.2943e+00],\n",
            "          [-3.3555e-03, -5.8507e-01, -4.8782e-01,  ..., -5.2881e-01,\n",
            "            2.0624e+00, -2.3012e+00],\n",
            "          [ 2.7500e-01, -1.0091e+00, -6.1188e-01,  ..., -4.8641e-01,\n",
            "            1.4993e+00, -2.2096e+00],\n",
            "          ...,\n",
            "          [-8.2662e-02, -2.7244e-01,  4.5843e-01,  ..., -1.9672e+00,\n",
            "            1.9059e+00, -1.4042e+00],\n",
            "          [ 1.7172e-01, -6.8132e-01,  4.1975e-01,  ..., -1.8193e+00,\n",
            "            1.1634e+00, -2.0121e+00],\n",
            "          [-2.4823e-01,  9.4369e-01,  9.3197e-02,  ..., -1.0682e+00,\n",
            "            1.9075e+00, -1.9677e+00]],\n",
            "\n",
            "         [[ 4.7871e-01, -3.7726e-01, -5.6152e-02,  ..., -5.4225e+00,\n",
            "           -6.2361e+00, -2.8134e+00],\n",
            "          [ 1.1802e+00,  1.1148e-01,  1.2448e-02,  ..., -5.8601e+00,\n",
            "           -6.6089e+00, -3.2601e+00],\n",
            "          [ 9.1493e-01, -3.6632e-02, -2.1142e-01,  ..., -5.5419e+00,\n",
            "           -6.2954e+00, -2.9268e+00],\n",
            "          ...,\n",
            "          [-2.3268e-01, -6.6856e-01, -5.6676e-01,  ..., -3.9720e+00,\n",
            "           -5.1185e+00, -1.5532e+00],\n",
            "          [-8.3661e-02, -5.1440e-02, -3.5268e-01,  ..., -3.7791e+00,\n",
            "           -4.9469e+00, -1.1692e+00],\n",
            "          [-1.2083e+00, -6.4196e-02, -6.6890e-01,  ..., -5.5101e+00,\n",
            "           -6.0728e+00, -2.4919e+00]],\n",
            "\n",
            "         [[ 1.1247e+01, -2.2053e+00, -2.7435e+00,  ...,  3.9413e+00,\n",
            "           -1.9681e+00, -4.7589e+00],\n",
            "          [ 2.0572e+01, -4.6517e-01, -2.8375e+00,  ...,  4.1415e+00,\n",
            "           -1.9826e+00, -4.9845e+00],\n",
            "          [ 1.3606e+01, -3.2783e-01, -3.7701e+00,  ...,  4.1274e+00,\n",
            "           -1.6548e+00, -4.8710e+00],\n",
            "          ...,\n",
            "          [-1.7988e+00,  2.1634e+00, -4.7128e+00,  ...,  4.0654e+00,\n",
            "           -1.8778e+00, -4.5855e+00],\n",
            "          [-1.6588e+01,  1.6939e+00, -5.0285e+00,  ...,  3.9116e+00,\n",
            "           -1.6409e+00, -4.4827e+00],\n",
            "          [-2.4621e+01,  2.1224e+00, -7.6509e+00,  ...,  3.6270e+00,\n",
            "           -2.0332e+00, -4.4071e+00]]]]), tensor([[[[ 4.4416e-03, -2.0941e-03, -1.0302e-02,  ...,  2.2210e-03,\n",
            "           -5.6728e-03,  2.6139e-03],\n",
            "          [ 6.1729e-03, -2.2890e-04,  2.7780e-03,  ..., -1.0260e-04,\n",
            "           -1.3382e-03, -1.5846e-03],\n",
            "          [ 3.7368e-03,  1.8719e-03,  2.8520e-04,  ...,  5.1631e-04,\n",
            "           -9.1297e-04,  4.1771e-04],\n",
            "          ...,\n",
            "          [-8.8250e-03, -2.8453e-03,  7.6167e-03,  ..., -1.0613e-03,\n",
            "           -2.6264e-02,  2.4513e-02],\n",
            "          [ 1.1682e-04,  2.1384e-04, -1.7645e-02,  ...,  5.7378e-03,\n",
            "            5.0796e-03,  1.1383e-02],\n",
            "          [ 3.0112e-03,  3.0653e-04, -3.7049e-05,  ..., -3.4018e-03,\n",
            "           -1.3129e-03,  5.4580e-04]],\n",
            "\n",
            "         [[ 4.5992e-03, -1.3661e-03,  2.9561e-03,  ...,  9.9008e-03,\n",
            "           -2.4041e-02,  1.2200e-02],\n",
            "          [ 5.5664e-03, -3.1247e-03, -2.6179e-03,  ..., -1.2297e-03,\n",
            "           -7.1519e-03,  7.4583e-03],\n",
            "          [-1.1233e-03,  1.3858e-03, -3.3898e-03,  ..., -1.8475e-03,\n",
            "           -4.4415e-03, -2.2613e-04],\n",
            "          ...,\n",
            "          [-2.7100e-02, -4.5269e-03, -2.6878e-04,  ...,  1.9972e-02,\n",
            "            4.5460e-01, -5.4800e-03],\n",
            "          [-1.7121e-03, -8.9157e-03,  7.6815e-03,  ..., -1.2399e-02,\n",
            "            7.0212e-02, -1.4456e-02],\n",
            "          [-9.2813e-04, -6.1948e-03, -3.2076e-03,  ...,  1.4375e-03,\n",
            "           -5.1196e-03,  1.3179e-03]],\n",
            "\n",
            "         [[-3.9815e-04, -1.1358e-02,  1.0027e-03,  ...,  1.8658e-03,\n",
            "           -7.3307e-03, -2.1680e-03],\n",
            "          [-2.2345e-03,  2.8700e-03, -6.1130e-03,  ...,  1.5122e-03,\n",
            "           -7.0104e-03,  1.6348e-03],\n",
            "          [ 3.3386e-03, -3.0299e-03, -4.8680e-03,  ..., -7.5249e-03,\n",
            "           -1.7021e-03,  3.6154e-04],\n",
            "          ...,\n",
            "          [-7.4928e-03, -1.7601e-02, -2.9712e-02,  ...,  1.3482e-03,\n",
            "           -4.7018e-03, -4.8344e-03],\n",
            "          [ 3.3622e-03,  3.6369e-03,  1.0606e-02,  ..., -2.6570e-03,\n",
            "           -1.7444e-02,  4.6078e-03],\n",
            "          [ 3.9016e-05, -2.6919e-03,  1.3781e-03,  ..., -2.0068e-03,\n",
            "           -4.7554e-02, -2.2823e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.7849e-04, -4.3982e-02,  2.1480e-03,  ..., -5.5859e-03,\n",
            "           -3.3252e-04, -7.0539e-04],\n",
            "          [-2.9074e-03, -4.9478e-02,  5.2446e-04,  ...,  2.5144e-03,\n",
            "            4.7463e-03,  3.1813e-03],\n",
            "          [ 7.7130e-04, -9.5838e-02,  1.6345e-03,  ...,  1.0309e-02,\n",
            "           -9.0660e-03,  6.2081e-03],\n",
            "          ...,\n",
            "          [-4.2217e-03,  1.9181e-01,  1.4729e-03,  ..., -1.0219e-02,\n",
            "            2.0550e-02,  1.5391e-03],\n",
            "          [ 5.8056e-03,  6.4441e-02, -1.1544e-02,  ..., -4.3412e-03,\n",
            "           -1.7604e-02, -1.8054e-02],\n",
            "          [ 6.5886e-03, -1.1597e-01,  3.3735e-03,  ..., -6.7100e-03,\n",
            "           -1.5759e-03,  2.4653e-03]],\n",
            "\n",
            "         [[ 3.4442e-01,  6.0207e-03,  2.3288e-02,  ...,  2.3000e-03,\n",
            "            5.4362e-04, -3.4415e-03],\n",
            "          [ 4.4114e-01, -5.7679e-03,  2.0620e-02,  ...,  1.0348e-02,\n",
            "            6.1760e-03, -2.0187e-03],\n",
            "          [ 3.7574e-01, -2.7580e-03, -1.2772e-02,  ...,  7.4264e-03,\n",
            "           -4.3737e-04,  2.9571e-04],\n",
            "          ...,\n",
            "          [-2.6923e-02,  2.1511e-03, -3.8225e-04,  ..., -2.5408e-03,\n",
            "            2.0049e-02,  2.4119e-02],\n",
            "          [-2.4636e-01, -6.2173e-03, -5.4714e-03,  ...,  1.4749e-03,\n",
            "            1.2968e-03, -8.4518e-03],\n",
            "          [ 3.3236e-01, -3.0424e-03,  5.4674e-03,  ..., -7.7981e-03,\n",
            "           -2.2267e-03,  3.9202e-03]],\n",
            "\n",
            "         [[-7.8715e-03, -1.4268e-04, -1.1274e-02,  ..., -2.1782e-03,\n",
            "            5.2750e-03, -5.1585e-02],\n",
            "          [-8.3800e-03,  1.6260e-03,  2.4935e-03,  ...,  8.1986e-03,\n",
            "           -1.3790e-03, -2.3194e-02],\n",
            "          [-7.6731e-03,  4.4532e-03,  6.5030e-03,  ...,  5.5473e-03,\n",
            "           -5.7804e-03, -1.1526e-01],\n",
            "          ...,\n",
            "          [ 1.1223e-02, -1.2533e-02, -1.8414e-03,  ...,  7.5648e-03,\n",
            "           -2.7274e-03, -1.4253e-02],\n",
            "          [ 3.7904e-03,  2.2261e-03,  5.3703e-03,  ..., -4.4105e-03,\n",
            "            5.0974e-03,  2.2590e-04],\n",
            "          [-1.3854e-03,  2.0222e-03, -3.0341e-04,  ..., -1.8696e-02,\n",
            "            5.4166e-03,  1.1646e-01]]]])), (tensor([[[[ 1.3767e+00, -1.4200e+00, -2.2421e+00,  ...,  4.8850e+00,\n",
            "           -2.8440e-01,  7.0826e-01],\n",
            "          [-1.9182e+00, -2.7057e-01, -1.8646e+00,  ...,  4.4289e+00,\n",
            "           -6.3297e-01, -2.8087e-01],\n",
            "          [-2.5572e+00,  7.2284e-01, -1.4339e+00,  ...,  4.9100e+00,\n",
            "            4.9600e-02,  2.9910e-01],\n",
            "          ...,\n",
            "          [-7.6330e+00,  3.5547e+00, -8.8533e-01,  ...,  3.8275e+00,\n",
            "           -4.5029e-01,  7.5755e-01],\n",
            "          [ 4.6363e-01,  2.1459e+00, -2.6173e-01,  ...,  4.1686e+00,\n",
            "           -3.5189e-01,  9.4965e-02],\n",
            "          [ 1.7013e-01, -3.7950e-01,  7.5601e-02,  ...,  5.0211e+00,\n",
            "           -1.0735e-01,  3.8813e-01]],\n",
            "\n",
            "         [[ 8.9935e-01,  7.9042e-01, -7.1111e-01,  ...,  2.0280e-01,\n",
            "           -6.0268e-01, -4.4698e-02],\n",
            "          [ 1.0330e-01,  2.5889e+00, -1.8488e+00,  ..., -1.0016e+00,\n",
            "           -4.9656e-01,  3.9496e-01],\n",
            "          [-5.7330e-01,  1.2980e+00, -1.2301e+00,  ...,  2.5721e-01,\n",
            "           -4.2334e-01,  4.3787e-02],\n",
            "          ...,\n",
            "          [-2.5005e+00, -1.2440e+00, -6.1339e+00,  ...,  5.9933e-01,\n",
            "           -8.3878e-01, -1.7064e-02],\n",
            "          [-3.8762e+00, -3.1221e+00, -5.9556e+00,  ...,  1.6034e+00,\n",
            "           -6.6491e-01, -7.9844e-01],\n",
            "          [ 1.5418e-01, -9.5456e-01, -2.0853e+00,  ...,  4.0542e-01,\n",
            "           -3.1331e-01, -2.1882e-01]],\n",
            "\n",
            "         [[ 2.0576e-01,  1.1860e+00, -5.0116e+00,  ..., -1.2435e-01,\n",
            "            4.3765e-01,  1.4345e-01],\n",
            "          [-1.0427e-01,  2.0680e+00, -5.7217e+00,  ..., -1.1213e+00,\n",
            "           -1.5872e-02,  3.1311e-01],\n",
            "          [-5.9173e-01,  1.7503e+00, -5.3525e+00,  ..., -3.4120e-01,\n",
            "            4.1465e-01, -4.5746e-01],\n",
            "          ...,\n",
            "          [-1.9251e-01, -1.3751e+00, -3.1767e+00,  ...,  5.2222e-01,\n",
            "            5.5458e-01, -8.0972e-02],\n",
            "          [ 2.2990e-01, -2.0480e+00, -3.1286e+00,  ...,  5.8960e-01,\n",
            "           -3.3343e-01, -2.1820e-01],\n",
            "          [-8.0663e-02, -1.3847e+00, -2.3057e+00,  ..., -5.1228e-01,\n",
            "           -3.5173e-01, -2.2655e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.7445e-01,  5.6259e-01, -3.9923e-01,  ..., -3.7487e-01,\n",
            "            5.7209e-01,  1.1139e+00],\n",
            "          [ 2.1410e+00,  6.0241e-01, -1.8047e+00,  ...,  4.5003e-01,\n",
            "            1.4933e+00,  1.0166e+00],\n",
            "          [-1.1173e+00, -7.2204e-01, -2.3319e-01,  ...,  5.8767e-02,\n",
            "            2.1536e-01,  5.1000e-01],\n",
            "          ...,\n",
            "          [-7.4827e-01, -1.4597e+00, -1.6917e+00,  ...,  4.5585e-01,\n",
            "            1.7806e+00,  9.9779e-01],\n",
            "          [-1.3982e+00, -4.3635e-01, -9.4412e-01,  ...,  4.6631e-01,\n",
            "            2.2921e+00,  1.1311e+00],\n",
            "          [-1.0766e-01, -5.0168e-02, -2.0528e-01,  ..., -9.4239e-02,\n",
            "            1.1174e-01,  1.2459e+00]],\n",
            "\n",
            "         [[ 1.2955e-01, -1.2214e-01, -1.3984e+00,  ...,  7.0457e-02,\n",
            "            1.9194e-01, -4.9460e-02],\n",
            "          [ 2.4889e-01,  8.2753e-01, -1.1392e+00,  ..., -3.5898e-01,\n",
            "           -1.5698e-01,  1.8318e+00],\n",
            "          [-2.4498e-01,  3.9061e-01, -1.4835e+00,  ...,  9.0463e-01,\n",
            "           -4.0081e-01,  1.5192e-01],\n",
            "          ...,\n",
            "          [-6.5758e-01, -6.9432e-01,  5.3964e-02,  ..., -7.9137e-02,\n",
            "           -4.1954e-01,  7.5947e-01],\n",
            "          [-2.2850e-01, -2.6457e-01,  4.4105e-01,  ..., -1.3226e+00,\n",
            "            6.4951e-02,  8.2664e-01],\n",
            "          [-1.0498e-02, -4.4209e-01, -8.4151e-01,  ..., -7.0787e-01,\n",
            "           -1.6798e-01,  5.9076e-02]],\n",
            "\n",
            "         [[ 2.9799e-01,  1.7709e-02, -2.3946e-01,  ...,  4.8758e-01,\n",
            "            6.6815e-01,  8.6431e-01],\n",
            "          [-5.7141e-01,  8.8849e-01, -1.1023e+00,  ..., -4.1840e-01,\n",
            "            7.3207e-01, -2.1891e-01],\n",
            "          [-1.5337e-01,  2.0488e-01, -3.4009e-01,  ...,  6.6128e-01,\n",
            "           -1.9910e-03,  7.4800e-01],\n",
            "          ...,\n",
            "          [-5.5646e-01, -4.6193e-01, -9.6970e-02,  ...,  1.3085e+00,\n",
            "            1.3156e+00, -2.7248e-01],\n",
            "          [ 1.0266e+00, -6.3029e-01, -3.7638e-01,  ...,  8.2763e-01,\n",
            "           -3.3745e-01,  1.4398e+00],\n",
            "          [ 2.7170e-01, -4.5990e-01, -1.9403e-01,  ...,  5.9019e-01,\n",
            "            3.3247e-01,  9.2817e-01]]]]), tensor([[[[-9.7569e-03, -1.0042e-03,  6.1269e-02,  ...,  2.4036e-03,\n",
            "           -1.5608e-03, -2.2092e-03],\n",
            "          [ 2.6080e-01, -4.1425e-02, -2.2937e-01,  ...,  5.8100e-02,\n",
            "            3.7024e-03, -8.7567e-02],\n",
            "          [-7.3144e-02,  8.3685e-04,  2.2246e-02,  ..., -2.6655e-02,\n",
            "            2.5691e-02,  1.1387e-02],\n",
            "          ...,\n",
            "          [-3.0681e-01,  4.3598e-01,  7.5100e-02,  ...,  7.6756e-01,\n",
            "           -3.1993e-03, -5.7562e-01],\n",
            "          [-4.0138e-01, -1.3078e-01,  2.4433e-01,  ..., -8.7353e-02,\n",
            "            1.4156e-01,  1.9406e-01],\n",
            "          [-1.2553e-04, -4.1210e-03,  2.5037e-03,  ..., -8.7689e-03,\n",
            "           -1.4880e-02,  6.7646e-03]],\n",
            "\n",
            "         [[-6.9896e-03, -1.6800e-02,  3.7259e-02,  ...,  6.0275e-03,\n",
            "           -5.5701e-03,  9.9834e-03],\n",
            "          [ 1.1734e-01,  1.6309e-01, -1.3176e-01,  ..., -2.0943e-01,\n",
            "           -1.3056e-02,  3.4203e-01],\n",
            "          [-4.3138e-02, -3.9773e-02, -1.1882e-01,  ..., -8.3337e-02,\n",
            "            9.4565e-03, -1.5233e-01],\n",
            "          ...,\n",
            "          [-3.0823e-01, -8.0460e-02,  5.8263e-01,  ...,  2.0628e-01,\n",
            "            4.3339e-02, -5.4691e-01],\n",
            "          [-2.1655e-01,  4.4743e-02,  1.2261e-01,  ..., -2.1207e-01,\n",
            "           -5.0568e-02,  3.2700e-03],\n",
            "          [-1.0896e-01,  2.2665e-02,  4.0070e-03,  ...,  1.1638e-01,\n",
            "           -2.3979e-02, -1.3615e-01]],\n",
            "\n",
            "         [[ 1.6244e-02, -3.3132e-03,  9.7967e-03,  ...,  1.1591e-02,\n",
            "            5.0508e-03, -2.8797e-02],\n",
            "          [-1.8841e-02,  1.3217e-01, -4.4323e-02,  ...,  8.3612e-03,\n",
            "           -7.5279e-02,  5.8696e-03],\n",
            "          [ 5.3618e-03, -1.2565e-02,  2.4500e-02,  ..., -3.4712e-02,\n",
            "            1.9395e-02, -1.0665e-02],\n",
            "          ...,\n",
            "          [ 9.4449e-02,  1.1170e-02,  1.9967e-01,  ...,  5.6762e-02,\n",
            "           -6.2562e-02, -1.2862e-01],\n",
            "          [ 1.3155e-01,  4.7763e-02, -4.8595e-02,  ..., -2.1019e-01,\n",
            "            1.8552e-02,  2.2415e-02],\n",
            "          [-4.2519e-03,  8.7937e-02, -1.1291e-01,  ...,  6.9797e-02,\n",
            "           -2.3489e-02,  4.6596e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3625e-02,  1.1138e-02, -1.2758e-02,  ..., -7.0780e-03,\n",
            "           -1.7929e-02, -1.0476e-03],\n",
            "          [-2.0802e-02,  4.3277e-02,  2.8091e-02,  ...,  4.8022e-02,\n",
            "           -1.5200e-01,  6.7613e-02],\n",
            "          [ 5.2352e-02,  1.2118e-02,  8.1974e-02,  ..., -1.4252e-02,\n",
            "            6.2045e-02, -6.5213e-04],\n",
            "          ...,\n",
            "          [ 1.7256e-02,  5.0140e-03, -1.2623e-01,  ..., -6.5685e-02,\n",
            "            7.5290e-02, -1.1396e-01],\n",
            "          [-1.1523e-01,  1.2847e-01, -2.1933e-02,  ..., -1.1425e-01,\n",
            "           -5.8747e-02, -9.5231e-02],\n",
            "          [ 6.6570e-03, -3.3800e-02, -1.0069e-02,  ..., -3.6652e-03,\n",
            "           -2.0204e-02,  2.0728e-02]],\n",
            "\n",
            "         [[ 2.9989e-03,  2.0384e-02, -3.2934e-03,  ..., -1.1458e-03,\n",
            "           -2.0949e-02, -1.1211e-02],\n",
            "          [ 1.4038e-01,  1.9617e-01, -7.7986e-02,  ..., -1.8629e-01,\n",
            "           -2.2309e-01,  1.6992e-02],\n",
            "          [ 4.6984e-02, -7.6800e-02,  4.7211e-02,  ...,  6.9678e-02,\n",
            "            4.3200e-02,  1.5892e-02],\n",
            "          ...,\n",
            "          [ 2.2138e-01, -3.1095e-01, -3.9325e-02,  ..., -7.5689e-02,\n",
            "            9.4941e-02,  1.1522e-01],\n",
            "          [-1.3045e-01, -1.0251e-01,  8.4720e-02,  ..., -7.8545e-03,\n",
            "            1.4221e-01, -1.4762e-01],\n",
            "          [-1.1381e-01, -5.8733e-02,  2.0576e-02,  ..., -1.1221e-02,\n",
            "           -2.5134e-02,  4.0531e-02]],\n",
            "\n",
            "         [[ 2.0335e-02, -3.8824e-03, -1.0473e-02,  ...,  5.1524e-03,\n",
            "           -1.2905e-02, -3.2721e-02],\n",
            "          [-6.1085e-02, -8.4570e-02, -4.7842e-02,  ..., -5.9064e-02,\n",
            "           -4.2756e-02, -4.6360e-02],\n",
            "          [-3.0082e-02, -7.3591e-03,  2.2530e-03,  ..., -3.5284e-02,\n",
            "           -5.7823e-02,  5.5032e-02],\n",
            "          ...,\n",
            "          [ 1.5864e-02, -1.5695e-02, -1.1139e-01,  ...,  1.9747e-01,\n",
            "            9.5913e-02,  4.9051e-02],\n",
            "          [ 2.2473e-01,  5.4856e-02,  1.2481e-01,  ..., -2.3257e-02,\n",
            "           -1.2558e-01, -3.2011e-01],\n",
            "          [ 3.5722e-02, -1.7420e-02, -8.2609e-04,  ...,  5.7313e-02,\n",
            "            2.8848e-02,  5.1323e-03]]]])), (tensor([[[[-1.3669e-02,  3.4135e-02,  1.8698e-01,  ..., -9.6730e-01,\n",
            "           -5.4726e-01, -9.0686e-01],\n",
            "          [ 2.7377e+00,  1.3650e+00,  5.8888e-01,  ..., -4.1545e-01,\n",
            "           -5.8454e-01, -1.6605e+00],\n",
            "          [ 1.4111e+00,  1.5543e+00,  8.1009e-01,  ..., -1.6362e+00,\n",
            "           -6.7299e-01, -4.8401e-02],\n",
            "          ...,\n",
            "          [-1.5148e+00, -2.8422e-01,  2.6684e+00,  ..., -9.7513e-01,\n",
            "           -1.9797e-01, -1.0722e+00],\n",
            "          [-5.2705e+00, -1.1419e+00,  2.9324e+00,  ..., -1.1659e+00,\n",
            "           -9.6318e-01, -7.3751e-02],\n",
            "          [-1.5073e-01, -7.2159e-02,  7.2582e-01,  ..., -9.0452e-01,\n",
            "           -3.9601e-01, -9.3791e-01]],\n",
            "\n",
            "         [[ 1.1967e-02,  4.6409e-03, -4.2015e-02,  ...,  1.6469e-01,\n",
            "            2.6094e-02, -7.1297e-01],\n",
            "          [ 5.8590e-01,  2.2805e-01, -1.4608e+00,  ..., -1.0184e+00,\n",
            "           -8.7163e-02,  1.3210e+00],\n",
            "          [ 3.4698e-01,  9.3716e-02, -3.6847e-01,  ..., -9.8756e-01,\n",
            "            4.0560e-01,  7.1957e-01],\n",
            "          ...,\n",
            "          [ 5.4695e-01, -1.0632e+00, -1.1994e+00,  ..., -1.1788e-01,\n",
            "            1.2162e-02, -8.8767e-01],\n",
            "          [-6.8485e-01, -5.2548e-01, -7.4743e-01,  ...,  2.9392e-01,\n",
            "            1.6365e-01, -3.5173e-01],\n",
            "          [-2.0626e-02, -2.1391e-01,  7.7973e-01,  ..., -2.1262e-01,\n",
            "            1.1019e-01,  6.2224e-01]],\n",
            "\n",
            "         [[ 2.0060e-02,  3.8395e-03, -2.7617e-02,  ..., -3.8807e-01,\n",
            "            8.0529e-01, -3.0058e-02],\n",
            "          [-2.9627e-01, -1.1006e+00, -1.7539e-01,  ..., -6.9205e-01,\n",
            "           -6.7137e-02,  3.1019e-01],\n",
            "          [ 2.0367e-01, -6.4893e-01, -4.8138e-01,  ...,  7.9062e-01,\n",
            "            2.4239e-01,  2.3295e-01],\n",
            "          ...,\n",
            "          [ 7.7970e-02,  6.9791e-01, -3.5214e-01,  ..., -6.4819e-01,\n",
            "            1.3863e+00, -1.8949e+00],\n",
            "          [-1.0923e-02,  2.0658e-01,  2.0193e-01,  ...,  1.6731e-01,\n",
            "            1.4793e+00, -1.0184e+00],\n",
            "          [-3.2603e-02,  9.4811e-02, -3.2886e-01,  ...,  6.3630e-01,\n",
            "            4.3213e-01, -4.9874e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.2209e-02,  1.2626e-01, -1.3530e+00,  ...,  2.1849e-01,\n",
            "            1.1315e-01,  2.3073e-01],\n",
            "          [-8.2831e-01,  6.6447e-01, -2.8131e+00,  ...,  1.5579e+00,\n",
            "            7.3126e-03,  5.2341e-01],\n",
            "          [-1.8357e-01, -6.4614e-02, -2.1094e+00,  ...,  7.1501e-01,\n",
            "            4.0848e-01,  2.9638e-01],\n",
            "          ...,\n",
            "          [-1.8808e+00, -2.2849e+00, -3.5819e+00,  ...,  7.1961e-01,\n",
            "           -1.1128e+00, -1.1418e-01],\n",
            "          [ 9.3166e-01, -2.2802e+00, -3.7172e+00,  ...,  7.8795e-01,\n",
            "            3.1197e-01,  5.2604e-01],\n",
            "          [-8.0874e-03, -6.4633e-01, -3.6578e+00,  ...,  1.8111e+00,\n",
            "            1.7515e-01,  3.0650e-01]],\n",
            "\n",
            "         [[ 1.8018e-02, -6.9238e-02, -1.6849e-01,  ..., -2.5293e-01,\n",
            "           -5.8370e-01, -5.3863e-02],\n",
            "          [-2.0965e+00, -2.8540e+00, -2.2153e+00,  ..., -7.8110e-01,\n",
            "           -1.3671e+00, -5.4595e-02],\n",
            "          [ 1.0377e-02, -3.1263e+00, -2.0024e+00,  ...,  4.0021e-01,\n",
            "            7.1185e-02, -3.0096e-01],\n",
            "          ...,\n",
            "          [-4.5514e-01,  2.0294e+00, -3.8570e+00,  ..., -5.5320e-01,\n",
            "           -1.2103e+00,  2.7565e-02],\n",
            "          [ 2.8698e+00,  2.4850e+00, -3.6659e+00,  ..., -2.0312e+00,\n",
            "            6.3935e-01,  1.0191e+00],\n",
            "          [-9.5029e-02,  2.6421e-01, -1.7803e+00,  ..., -7.9910e-01,\n",
            "           -4.6599e-01, -1.8593e-01]],\n",
            "\n",
            "         [[-4.9645e-02, -1.6464e-02,  2.1710e-02,  ..., -5.7522e-02,\n",
            "           -9.4918e-02, -4.3195e-01],\n",
            "          [ 6.7090e+00, -4.7462e+00,  3.0986e+00,  ..., -3.7179e-01,\n",
            "           -8.9711e-01, -1.0693e+00],\n",
            "          [ 1.5502e+00, -1.7985e+00,  1.9878e+00,  ...,  3.1860e-01,\n",
            "            8.4721e-02, -1.5067e+00],\n",
            "          ...,\n",
            "          [-1.6521e+00,  4.7292e+00,  4.8404e+00,  ..., -1.4635e+00,\n",
            "            8.2564e-01,  4.0214e-01],\n",
            "          [-7.6216e+00,  5.6814e+00,  3.6469e+00,  ..., -1.3261e-01,\n",
            "            3.0641e-01, -2.7994e-01],\n",
            "          [-2.6805e+00,  3.4087e+00,  3.7932e+00,  ...,  6.1327e-01,\n",
            "           -2.6294e-01, -5.9178e-01]]]]), tensor([[[[-6.0291e-03, -2.4503e-02, -7.8924e-03,  ...,  3.3832e-02,\n",
            "           -2.8360e-02, -2.8786e-02],\n",
            "          [ 3.4274e-02, -4.3224e-02,  3.6390e-01,  ..., -2.6019e-01,\n",
            "            3.7734e-01,  4.2688e-01],\n",
            "          [ 3.6702e-01,  1.1229e-02, -7.2991e-02,  ..., -4.1154e-01,\n",
            "            1.6007e-02,  1.2006e-02],\n",
            "          ...,\n",
            "          [-4.0270e-01,  4.6646e-01, -5.7094e-01,  ...,  2.1802e-01,\n",
            "           -1.4058e-01,  2.5869e-02],\n",
            "          [-3.7509e-01, -6.6425e-01, -1.6510e-01,  ...,  1.2147e-01,\n",
            "            7.6987e-01,  7.5490e-01],\n",
            "          [ 4.8056e-02, -2.0956e-01,  5.5763e-02,  ..., -7.9612e-02,\n",
            "            2.3798e-03,  1.8976e-02]],\n",
            "\n",
            "         [[-4.4300e-03, -1.7723e-03, -2.0542e-03,  ..., -9.9356e-03,\n",
            "           -2.1833e-04,  3.1569e-03],\n",
            "          [-3.6872e-01, -6.0644e-01, -4.5516e-01,  ..., -2.3997e-01,\n",
            "            1.4917e-01, -4.1921e-02],\n",
            "          [-4.5455e-02, -4.5872e-02,  3.8073e-02,  ..., -8.5872e-02,\n",
            "           -4.3757e-02, -8.5559e-03],\n",
            "          ...,\n",
            "          [ 1.1128e+00, -3.4304e-01,  9.0349e-01,  ...,  9.5720e-01,\n",
            "           -1.9614e-01, -3.1490e-01],\n",
            "          [ 4.0745e-01,  3.0427e-01, -5.2457e-01,  ..., -4.9222e-02,\n",
            "           -4.4137e-01,  3.4206e-02],\n",
            "          [ 5.5250e-02,  1.9706e-01, -2.8676e-01,  ..., -3.7728e-02,\n",
            "           -9.8265e-02, -5.8364e-02]],\n",
            "\n",
            "         [[-4.0461e-03,  1.4692e-02, -4.4502e-03,  ...,  7.4313e-03,\n",
            "            1.0250e-03, -4.5001e-03],\n",
            "          [-3.0742e-01,  4.4396e-02, -1.1627e+00,  ...,  5.7545e-02,\n",
            "            5.3072e-01,  3.1973e-01],\n",
            "          [ 1.1214e-01,  9.6182e-03, -4.5180e-01,  ..., -1.6378e-01,\n",
            "            5.7073e-01,  3.6625e-01],\n",
            "          ...,\n",
            "          [ 4.6634e-01, -3.1787e-01,  3.5016e-01,  ..., -3.6247e-01,\n",
            "           -9.7948e-01, -3.2241e-01],\n",
            "          [-2.7408e-01, -4.0763e-01,  7.2820e-01,  ...,  4.3206e-01,\n",
            "           -1.1917e+00,  3.1442e-01],\n",
            "          [-1.8648e-01, -2.0385e-01, -1.3436e-01,  ...,  2.0099e-01,\n",
            "           -1.2864e-02, -1.5836e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.9225e-03, -3.2115e-02, -2.6587e-03,  ..., -3.2232e-02,\n",
            "           -1.4635e-03,  2.0287e-03],\n",
            "          [ 2.5545e-02,  4.9056e-01,  4.4107e-01,  ...,  1.0726e-01,\n",
            "            5.1817e-02, -8.7917e-02],\n",
            "          [ 1.0619e-01, -8.0418e-02,  6.1317e-02,  ...,  1.1578e-01,\n",
            "            3.1503e-02,  3.7249e-02],\n",
            "          ...,\n",
            "          [ 6.8829e-02,  2.7016e-01, -5.1811e-02,  ...,  6.9721e-02,\n",
            "           -4.9294e-01,  9.5946e-03],\n",
            "          [-1.8817e-01,  5.1076e-01, -3.9277e-01,  ..., -4.7704e-01,\n",
            "            4.3584e-01, -3.4267e-01],\n",
            "          [ 1.6670e-01,  1.0766e-01,  1.9687e-01,  ..., -3.7035e-01,\n",
            "           -1.3196e-01,  2.7993e-03]],\n",
            "\n",
            "         [[ 6.6646e-04, -7.1750e-03,  8.3985e-03,  ..., -6.7922e-04,\n",
            "            7.3339e-03, -1.2464e-02],\n",
            "          [-2.1203e-01, -1.3323e-02, -4.8465e-02,  ..., -4.1816e-02,\n",
            "           -8.0822e-01, -4.8789e-01],\n",
            "          [-1.7520e-01,  3.8346e-02,  1.4695e-01,  ..., -1.3585e-01,\n",
            "            2.4615e-01,  2.9912e-03],\n",
            "          ...,\n",
            "          [-5.4677e-02,  1.9105e-02,  1.1287e-01,  ...,  7.7336e-01,\n",
            "           -2.7088e-01, -2.5932e-01],\n",
            "          [-3.6562e-01,  3.2753e-01, -2.7548e-01,  ...,  1.8421e-01,\n",
            "           -4.9118e-01, -2.5340e-01],\n",
            "          [-9.1129e-02,  4.9159e-02, -2.4317e-02,  ..., -2.9968e-02,\n",
            "           -2.9640e-01,  1.8270e-01]],\n",
            "\n",
            "         [[-1.0276e-02, -1.2365e-02, -1.6255e-02,  ..., -5.3097e-03,\n",
            "            2.0619e-02, -2.9849e-03],\n",
            "          [ 4.1704e-01,  3.4963e-01,  1.7737e-02,  ...,  2.6444e-01,\n",
            "            3.6503e-01,  2.3458e-01],\n",
            "          [-2.0630e-01,  4.4703e-01,  1.1433e-01,  ...,  1.1846e-02,\n",
            "            2.7529e-01,  2.8002e-01],\n",
            "          ...,\n",
            "          [ 2.3991e-01, -2.0284e-02, -4.5308e-01,  ...,  2.2829e-01,\n",
            "            1.1539e+00, -3.4185e-01],\n",
            "          [-4.1017e-01,  3.5441e-02, -2.5728e-02,  ..., -3.0775e-01,\n",
            "           -4.9174e-01,  1.1308e-01],\n",
            "          [-6.0505e-02,  1.0079e-01, -2.8093e-02,  ..., -1.1538e-01,\n",
            "           -4.8247e-01,  1.5323e-02]]]])), (tensor([[[[ 3.2532e-02, -5.5330e-02, -1.6742e-01,  ..., -5.1241e-01,\n",
            "           -5.3691e-01, -8.6378e-02],\n",
            "          [ 7.4531e-02, -1.8185e+00, -1.4190e+00,  ...,  4.2731e-01,\n",
            "           -7.6449e-01, -1.3539e+00],\n",
            "          [-7.3890e-01, -5.5982e-01, -1.2230e+00,  ..., -2.2699e-01,\n",
            "           -3.2618e-01, -9.7637e-01],\n",
            "          ...,\n",
            "          [-2.5621e+00,  5.0814e+00,  1.3428e+00,  ...,  3.9482e-01,\n",
            "           -1.5264e-02,  3.2081e-01],\n",
            "          [-2.7485e+00,  3.0261e+00,  1.1542e+00,  ...,  1.1563e+00,\n",
            "           -2.7795e-01, -4.1836e-01],\n",
            "          [ 8.8743e-03,  7.3965e-01,  3.1230e-01,  ..., -3.8627e-01,\n",
            "           -6.2621e-01, -5.9124e-01]],\n",
            "\n",
            "         [[ 2.3753e-02,  4.5873e-02, -1.3202e-02,  ..., -9.8429e-03,\n",
            "           -6.5897e-02,  4.7633e-01],\n",
            "          [ 1.4088e+00, -1.4010e+00, -2.0845e+00,  ...,  2.4663e+00,\n",
            "           -2.0523e-01,  1.4973e+00],\n",
            "          [ 1.2737e+00, -8.8940e-01, -1.5529e+00,  ...,  1.2226e+00,\n",
            "           -8.2861e-02,  1.0274e-01],\n",
            "          ...,\n",
            "          [ 1.1922e+00, -9.4964e-01, -2.5312e+00,  ..., -1.9694e-01,\n",
            "           -1.0699e+00, -3.0335e-01],\n",
            "          [-6.3772e-01,  5.2121e-01, -1.2051e+00,  ..., -8.3742e-01,\n",
            "           -2.4637e-01,  7.1000e-01],\n",
            "          [-3.9072e-02, -4.3455e-02, -1.5570e+00,  ...,  1.8614e-01,\n",
            "           -9.9608e-02, -5.2525e-01]],\n",
            "\n",
            "         [[-6.8975e-02, -1.5000e-01,  2.8047e-01,  ..., -5.5449e-02,\n",
            "            9.6052e-01, -2.6468e-01],\n",
            "          [-1.4353e-01, -2.1549e+00,  5.9954e+00,  ...,  3.3471e-01,\n",
            "            1.0643e+00,  4.6124e-01],\n",
            "          [ 1.1868e+00, -7.5245e-01,  4.6965e+00,  ..., -8.3686e-01,\n",
            "            1.2938e+00, -5.3587e-01],\n",
            "          ...,\n",
            "          [ 1.6203e+00,  3.4269e+00,  1.6968e+00,  ..., -7.6961e-01,\n",
            "            1.5555e+00, -1.5074e-02],\n",
            "          [ 1.3774e+00,  2.3699e+00,  1.5551e+00,  ..., -8.4200e-01,\n",
            "           -9.8349e-02,  3.9096e-01],\n",
            "          [-6.5014e-01,  2.1482e+00,  3.8541e+00,  ..., -6.0359e-01,\n",
            "            1.2244e+00,  6.1355e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.3482e-03, -4.0880e-02, -1.2431e-01,  ...,  4.1255e-01,\n",
            "           -6.3855e-03, -4.1667e-01],\n",
            "          [ 5.9373e+00, -2.3183e+00, -2.6896e+00,  ...,  1.7008e+00,\n",
            "           -1.4696e+00, -1.9054e-01],\n",
            "          [ 2.4275e+00, -1.0268e-01, -2.0999e+00,  ...,  2.7749e-01,\n",
            "           -3.5560e-02,  1.8306e-02],\n",
            "          ...,\n",
            "          [ 2.5690e-03,  3.5761e+00, -9.6343e-01,  ..., -7.4124e-01,\n",
            "            1.1645e-02,  4.3834e-01],\n",
            "          [-5.2074e+00, -7.2859e-02, -9.5435e-01,  ...,  4.6974e-01,\n",
            "            1.6747e+00,  9.0240e-01],\n",
            "          [-2.0195e+00,  1.4687e+00,  3.0327e-01,  ..., -4.8748e-02,\n",
            "           -5.0021e-02,  9.0767e-01]],\n",
            "\n",
            "         [[-1.7798e-02, -2.6900e-02,  6.8911e-02,  ...,  5.3599e-01,\n",
            "            3.4003e+00,  5.4737e-01],\n",
            "          [-5.9644e-02, -4.7931e-01,  2.5804e-01,  ..., -4.2547e-01,\n",
            "            1.4574e+00,  8.6413e-01],\n",
            "          [-6.9717e-02,  5.6140e-01,  7.9363e-01,  ..., -5.2178e-01,\n",
            "            4.5608e-01,  9.7462e-01],\n",
            "          ...,\n",
            "          [-1.1071e+00, -7.7425e-01, -5.9408e-01,  ..., -2.5857e-01,\n",
            "            1.1280e+00,  3.5449e-01],\n",
            "          [-1.7552e-01,  2.2648e-01, -8.8302e-02,  ..., -1.0087e+00,\n",
            "            1.3849e+00, -6.6959e-02],\n",
            "          [-1.2904e-01,  8.4541e-02, -2.7345e-01,  ..., -6.9456e-01,\n",
            "            2.6868e+00,  4.7031e-01]],\n",
            "\n",
            "         [[ 3.5414e-02,  4.5040e-02,  6.4194e-02,  ...,  1.7686e-01,\n",
            "            1.7900e-01,  3.7756e-01],\n",
            "          [-1.8722e+00,  2.7619e+00,  2.2398e+00,  ..., -2.4802e-01,\n",
            "            1.2861e+00, -2.7852e-01],\n",
            "          [-1.3881e+00,  1.7266e+00,  1.5404e+00,  ..., -2.8437e-01,\n",
            "            6.2663e-01,  7.5080e-01],\n",
            "          ...,\n",
            "          [-1.1091e+00, -2.9190e+00,  3.4558e+00,  ...,  1.3031e+00,\n",
            "            9.0192e-02,  1.6785e-01],\n",
            "          [ 5.4936e+00, -3.0656e+00,  1.4134e+00,  ...,  2.1883e+00,\n",
            "           -6.5349e-01, -4.5203e-01],\n",
            "          [ 3.0067e-02, -5.3270e-01,  1.3099e+00,  ..., -6.4045e-01,\n",
            "            3.1699e-02, -2.3635e-01]]]]), tensor([[[[-2.5515e-03,  1.7349e-02, -5.0839e-03,  ...,  7.6694e-04,\n",
            "           -8.1776e-03,  1.1256e-02],\n",
            "          [ 1.9544e-01,  4.8131e-01, -3.3062e-01,  ..., -5.2173e-01,\n",
            "           -5.6787e-02, -8.3186e-02],\n",
            "          [ 2.6655e-02, -1.8905e-01,  1.7300e-01,  ..., -1.0632e-01,\n",
            "            4.7029e-02,  6.1501e-02],\n",
            "          ...,\n",
            "          [-3.5517e-01, -2.6635e-01,  3.3336e-01,  ...,  6.8448e-02,\n",
            "            4.3671e-01, -4.7017e-01],\n",
            "          [ 7.0732e-02, -6.4364e-01, -1.1346e-01,  ...,  2.0847e-01,\n",
            "           -3.7532e-01, -4.3273e-02],\n",
            "          [-3.0893e-01,  1.5012e-01, -8.4488e-02,  ...,  1.2832e-01,\n",
            "            2.5119e-02, -4.7846e-02]],\n",
            "\n",
            "         [[-1.2373e-03,  3.2374e-03,  3.9704e-05,  ..., -1.2723e-02,\n",
            "           -1.3507e-02,  1.0914e-02],\n",
            "          [ 2.2393e-01,  5.3062e-01,  6.9422e-03,  ..., -4.1080e-01,\n",
            "            6.0528e-01, -5.1039e-01],\n",
            "          [-1.1376e-01, -1.2688e-01, -1.1191e-01,  ..., -4.8552e-02,\n",
            "            7.3324e-03, -1.7241e-01],\n",
            "          ...,\n",
            "          [-2.5564e-01, -7.8769e-03, -2.4123e-01,  ...,  5.0653e-01,\n",
            "            3.6411e-01,  4.3278e-01],\n",
            "          [ 4.9075e-01,  3.6789e-01,  7.9788e-01,  ...,  7.5351e-01,\n",
            "            8.1063e-01, -8.3458e-02],\n",
            "          [-1.1051e-01,  4.0689e-02, -2.4436e-01,  ..., -4.6228e-01,\n",
            "           -6.0640e-01, -2.0028e-01]],\n",
            "\n",
            "         [[-1.8458e-02,  3.7145e-03,  1.4525e-03,  ...,  6.1828e-04,\n",
            "           -1.7978e-02, -4.0680e-03],\n",
            "          [ 1.0334e-02, -7.5704e-02, -1.4182e-01,  ...,  3.1967e-01,\n",
            "            3.9892e-01, -2.2682e-01],\n",
            "          [ 1.7761e-01,  4.3896e-02,  2.2107e-02,  ..., -2.6249e-01,\n",
            "            4.6360e-01, -1.5744e-01],\n",
            "          ...,\n",
            "          [ 5.3354e-01,  2.0049e-01, -7.6348e-02,  ..., -7.5225e-01,\n",
            "            2.3610e-01,  3.1162e-01],\n",
            "          [ 1.3858e-01, -2.0843e-01,  3.6249e-01,  ..., -1.2143e-02,\n",
            "           -1.9461e-01,  7.6678e-03],\n",
            "          [-8.7206e-02,  6.2003e-02,  2.0553e-01,  ..., -2.7628e-01,\n",
            "           -3.3926e-01,  1.4989e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.8956e-03,  3.4743e-03,  1.2772e-02,  ..., -9.9076e-04,\n",
            "            1.5566e-02, -5.3064e-03],\n",
            "          [-4.8601e-02, -1.4485e-01, -6.6040e-01,  ...,  5.0214e-01,\n",
            "            2.2118e-01,  5.1246e-01],\n",
            "          [ 6.7159e-02, -2.8732e-01, -4.7082e-01,  ..., -8.4048e-03,\n",
            "           -3.7720e-02, -9.7427e-02],\n",
            "          ...,\n",
            "          [ 2.6341e-01, -1.0992e-01, -3.7336e-02,  ..., -5.9388e-02,\n",
            "           -3.2320e-01, -3.6179e-01],\n",
            "          [ 3.6100e-02,  1.2473e+00, -5.1151e-01,  ...,  8.3505e-01,\n",
            "           -6.2356e-01, -3.6773e-01],\n",
            "          [-1.0078e-01, -1.0010e-01,  2.3974e-01,  ..., -9.1226e-02,\n",
            "           -7.1274e-02, -2.7050e-03]],\n",
            "\n",
            "         [[-1.0014e-02,  9.9464e-03, -3.1134e-02,  ..., -1.1828e-02,\n",
            "           -2.5475e-03,  1.1246e-02],\n",
            "          [-6.6309e-01,  2.5015e-01,  4.4119e-01,  ..., -6.0996e-01,\n",
            "            1.1517e+00, -7.6356e-02],\n",
            "          [-2.3198e-01, -3.4144e-01, -4.7904e-02,  ...,  1.0777e-01,\n",
            "           -4.4701e-01, -2.1384e-01],\n",
            "          ...,\n",
            "          [-8.9002e-02, -1.8659e-02,  7.0137e-01,  ...,  2.7300e-01,\n",
            "           -3.0908e-01, -2.7591e-01],\n",
            "          [-2.3122e-01,  4.2738e-01,  1.1596e+00,  ...,  1.2738e-01,\n",
            "            2.8055e-01,  3.8061e-01],\n",
            "          [-6.8981e-02,  2.7693e-01, -4.4883e-01,  ...,  9.2161e-03,\n",
            "            6.1995e-02, -1.1236e-01]],\n",
            "\n",
            "         [[ 4.8121e-03, -2.4370e-03,  4.0525e-03,  ..., -1.2023e-02,\n",
            "           -7.0942e-03, -5.3106e-03],\n",
            "          [ 6.6050e-02, -2.2559e-01, -2.0008e-01,  ..., -4.3029e-01,\n",
            "           -4.3400e-02,  7.6458e-02],\n",
            "          [ 1.0037e-01, -2.0164e-01, -1.9025e-01,  ...,  1.1746e-01,\n",
            "           -3.3426e-03, -1.2176e-01],\n",
            "          ...,\n",
            "          [-3.9677e-01,  9.7634e-01,  5.8849e-01,  ...,  6.8025e-01,\n",
            "           -1.3628e-01,  6.7218e-01],\n",
            "          [ 1.2761e-01, -2.4866e-01,  3.5150e-01,  ...,  2.5532e-01,\n",
            "           -1.1152e-01,  1.6618e-01],\n",
            "          [-2.0602e-01,  3.0811e-01,  4.5512e-01,  ..., -1.3464e-01,\n",
            "            1.3589e-01,  1.2169e-01]]]])), (tensor([[[[ 4.1557e-02, -7.9409e-02, -8.3765e-03,  ...,  2.5940e-01,\n",
            "            3.1541e-01,  3.0678e-01],\n",
            "          [-8.8786e-01, -4.6350e-01,  9.0143e-01,  ...,  8.4446e-01,\n",
            "            6.3238e-01,  3.4020e-02],\n",
            "          [-1.5863e+00,  3.2215e-01,  1.1676e+00,  ...,  4.8954e-01,\n",
            "           -1.3304e-01, -3.6139e-01],\n",
            "          ...,\n",
            "          [-2.4762e+00,  4.2257e+00,  4.8633e+00,  ...,  1.1977e+00,\n",
            "           -1.0121e+00,  1.0608e+00],\n",
            "          [ 1.8049e+00,  5.9672e-03,  3.5334e+00,  ...,  6.8727e-01,\n",
            "           -7.1085e-01, -5.1841e-01],\n",
            "          [ 1.6652e-01,  1.2518e-01,  1.9938e+00,  ...,  8.9889e-01,\n",
            "           -4.8377e-01,  6.1030e-01]],\n",
            "\n",
            "         [[-2.3147e+00, -1.7124e+00, -1.5041e+00,  ...,  3.1666e-01,\n",
            "           -4.5570e-02, -2.6840e-01],\n",
            "          [-4.6826e-01, -1.6809e+00, -2.7600e+00,  ...,  5.7529e-01,\n",
            "           -1.4321e-01,  7.0880e-02],\n",
            "          [ 7.4439e-01,  1.6872e+00,  2.5292e-01,  ...,  8.5092e-01,\n",
            "           -4.2793e-01,  1.1058e-01],\n",
            "          ...,\n",
            "          [ 1.9730e+00,  4.6092e+00,  3.7950e+00,  ...,  1.9894e-01,\n",
            "            3.0953e-01, -1.1173e-01],\n",
            "          [-1.0285e+00,  2.4796e+00,  4.9993e+00,  ..., -3.0536e-01,\n",
            "            1.5811e-01,  1.9781e-01],\n",
            "          [-1.2172e+00, -6.7171e-02,  6.1008e+00,  ...,  1.1879e-01,\n",
            "           -3.0508e-02, -2.3634e-01]],\n",
            "\n",
            "         [[-2.6019e-02,  6.8645e-03, -7.0653e-02,  ...,  7.7254e-01,\n",
            "           -7.5164e-01,  5.8249e-01],\n",
            "          [ 6.5185e-01, -2.4476e+00, -2.0982e+00,  ..., -7.1523e-01,\n",
            "            5.4242e-01,  4.4377e-01],\n",
            "          [ 1.8096e+00, -2.1910e+00, -1.3910e+00,  ...,  7.5199e-01,\n",
            "            4.3432e-01,  5.7086e-01],\n",
            "          ...,\n",
            "          [ 2.4895e+00, -2.0246e+00, -4.3230e+00,  ...,  4.6388e-01,\n",
            "           -6.8678e-01, -5.5525e-01],\n",
            "          [ 3.3267e-01,  7.9240e-01, -3.0120e+00,  ..., -9.4486e-01,\n",
            "           -1.3226e+00, -6.9917e-01],\n",
            "          [-7.8060e-01,  5.5566e-01, -1.2258e+00,  ..., -3.4354e-01,\n",
            "            6.5119e-01,  2.5406e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.6376e-03, -1.2381e-02,  4.0980e-02,  ...,  1.2760e-01,\n",
            "            2.1473e-01,  4.8854e-02],\n",
            "          [-1.1299e+00, -1.4149e+00,  2.0912e+00,  ...,  2.5207e-01,\n",
            "           -2.9954e-01,  2.1936e-01],\n",
            "          [-6.4370e-01, -9.8089e-01,  2.1889e+00,  ..., -5.5436e-01,\n",
            "            6.0624e-03,  3.8836e-01],\n",
            "          ...,\n",
            "          [-2.8129e+00,  4.6414e+00,  4.0099e+00,  ...,  7.3334e-01,\n",
            "            7.5268e-01,  1.1500e+00],\n",
            "          [ 1.1184e+00,  3.7896e+00,  3.6941e+00,  ..., -1.3538e+00,\n",
            "            1.2513e+00, -9.7621e-03],\n",
            "          [ 1.0764e-01,  4.7356e-01,  2.0296e+00,  ...,  1.1733e+00,\n",
            "           -7.6865e-01,  1.0789e+00]],\n",
            "\n",
            "         [[ 4.3534e-02, -1.3149e-02,  1.0571e-02,  ...,  2.4468e-01,\n",
            "            6.1142e-01,  7.1770e-02],\n",
            "          [-1.6617e-01, -5.5553e-01, -6.1135e-01,  ...,  4.9317e-01,\n",
            "            1.4130e+00,  4.3552e-01],\n",
            "          [ 6.3292e-01, -7.6570e-01, -3.1987e-01,  ...,  4.4743e-01,\n",
            "            8.7228e-01, -6.1056e-02],\n",
            "          ...,\n",
            "          [ 8.8079e-01,  6.9919e-01, -8.9966e-01,  ...,  3.4748e-01,\n",
            "            5.5422e-01, -2.1967e-01],\n",
            "          [ 3.7111e-01,  2.2952e-01, -7.4036e-01,  ...,  4.8787e-01,\n",
            "           -5.1672e-02,  2.2557e-01],\n",
            "          [ 2.2246e-01,  3.2781e-01, -2.8577e-01,  ..., -9.9881e-02,\n",
            "            6.7157e-01, -4.1258e-01]],\n",
            "\n",
            "         [[-2.5773e-02, -5.1237e-02,  8.6398e-02,  ..., -1.3061e+00,\n",
            "            3.4308e-04, -6.0624e-01],\n",
            "          [-1.5108e+00,  1.5611e+00,  3.6785e+00,  ...,  1.0538e+00,\n",
            "           -3.9918e-01, -3.4620e-01],\n",
            "          [ 6.8586e-01,  2.4938e+00,  3.3635e+00,  ..., -1.2863e+00,\n",
            "            1.9158e-01, -6.8804e-01],\n",
            "          ...,\n",
            "          [ 3.8972e+00,  1.3098e+00,  3.8624e+00,  ..., -1.7559e+00,\n",
            "           -7.3913e-01,  1.0779e+00],\n",
            "          [ 3.4509e+00, -6.2029e-01,  3.7028e+00,  ...,  1.6771e-01,\n",
            "           -9.5089e-01, -5.9621e-01],\n",
            "          [ 1.0449e+00, -1.3537e+00,  3.1376e+00,  ..., -8.1364e-01,\n",
            "            2.9245e-01, -1.3436e+00]]]]), tensor([[[[-1.4047e-02, -9.7267e-03, -1.4424e-03,  ..., -4.2557e-04,\n",
            "           -1.0161e-02, -1.2013e-02],\n",
            "          [ 4.3338e-02, -1.9170e-02,  3.2207e-01,  ..., -2.5101e-02,\n",
            "           -4.9591e-01, -4.5110e-02],\n",
            "          [ 4.0166e-01, -1.5372e-01, -2.4376e-02,  ..., -1.9263e-01,\n",
            "           -3.3449e-01, -1.0406e-01],\n",
            "          ...,\n",
            "          [ 5.2965e-02,  1.5268e-01,  1.0323e-01,  ..., -1.8580e-01,\n",
            "            6.8627e-02,  3.5413e-01],\n",
            "          [-2.2765e-01,  1.7480e-01, -5.8281e-01,  ..., -5.0021e-01,\n",
            "            2.2768e-01,  7.9563e-02],\n",
            "          [ 3.1438e-01, -2.4363e-01,  2.4395e-01,  ..., -5.7991e-02,\n",
            "           -2.7686e-01,  2.4580e-01]],\n",
            "\n",
            "         [[ 2.3437e-02, -7.0946e-04, -3.0762e-02,  ..., -7.4419e-03,\n",
            "           -1.6919e-03, -1.5296e-02],\n",
            "          [ 4.6370e-01,  7.6080e-02,  8.1268e-01,  ...,  2.0912e-01,\n",
            "           -3.1766e-02,  4.6283e-01],\n",
            "          [-1.0549e-01, -8.8464e-03,  3.3738e-02,  ...,  4.4450e-03,\n",
            "            7.4480e-02,  1.7966e-01],\n",
            "          ...,\n",
            "          [-1.3632e-01,  1.7107e-01,  1.1432e-01,  ...,  2.6186e-01,\n",
            "            3.4950e-01, -4.2636e-01],\n",
            "          [ 3.3940e-01,  9.2680e-02,  4.0244e-01,  ..., -1.6778e-01,\n",
            "            7.0465e-03, -4.8024e-02],\n",
            "          [ 5.2459e-02, -1.9656e-01,  6.6125e-02,  ..., -4.6243e-02,\n",
            "           -4.3546e-03,  1.5235e-01]],\n",
            "\n",
            "         [[-6.3714e-03,  1.2991e-02, -4.9764e-03,  ...,  5.0048e-03,\n",
            "            1.1276e-02, -2.8650e-03],\n",
            "          [ 5.5039e-02,  2.5585e-01, -1.3480e-01,  ..., -1.4843e-01,\n",
            "            3.2200e-01, -7.5255e-01],\n",
            "          [ 3.4780e-01,  7.9786e-02, -2.9640e-01,  ...,  2.4297e-01,\n",
            "            3.2264e-02, -8.8873e-02],\n",
            "          ...,\n",
            "          [-1.2172e-01,  8.5426e-02, -2.7841e-01,  ...,  3.0044e-01,\n",
            "            3.4245e-02,  4.5680e-02],\n",
            "          [ 6.1666e-01,  2.8466e-01, -3.7999e-01,  ...,  3.5310e-01,\n",
            "            3.7116e-01,  3.4664e-01],\n",
            "          [-1.5831e-01,  1.2309e-01, -3.5886e-02,  ..., -1.7360e-01,\n",
            "           -1.6962e-01,  2.4805e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.7799e-04,  1.0059e-03, -3.6636e-03,  ..., -6.4386e-03,\n",
            "            2.3438e-02,  1.2251e-02],\n",
            "          [-1.5836e-01, -2.0702e-02,  9.3984e-02,  ..., -4.9164e-01,\n",
            "           -2.8802e-01,  5.5656e-01],\n",
            "          [-2.5880e-01, -8.0630e-03,  5.1648e-01,  ...,  2.0331e-01,\n",
            "           -7.9586e-02, -1.6648e-02],\n",
            "          ...,\n",
            "          [ 5.8156e-01,  5.0143e-01,  3.8526e-01,  ..., -1.2269e-01,\n",
            "            1.1293e-01,  3.4022e-01],\n",
            "          [-3.9497e-01, -2.8328e-01, -3.7560e-01,  ..., -6.0262e-01,\n",
            "            7.2630e-03,  1.5169e-01],\n",
            "          [-6.4742e-02,  3.1310e-01,  1.0466e-01,  ...,  1.7537e-01,\n",
            "            3.4130e-01,  4.0291e-01]],\n",
            "\n",
            "         [[ 2.5639e-03, -2.4717e-03,  6.9573e-03,  ...,  1.9030e-03,\n",
            "           -4.5408e-03,  2.6508e-03],\n",
            "          [-7.6580e-01, -3.9924e-01, -4.7778e-01,  ..., -4.6595e-01,\n",
            "            1.5298e-03,  1.6311e-01],\n",
            "          [-1.4080e-01,  1.7316e-01, -5.7345e-02,  ..., -4.5059e-01,\n",
            "           -1.2761e-01,  2.7157e-01],\n",
            "          ...,\n",
            "          [ 1.4519e-01, -3.2691e-02,  2.2440e-01,  ..., -7.1909e-01,\n",
            "            3.3465e-01, -3.7708e-01],\n",
            "          [ 3.0324e-01, -2.6107e-01,  2.1814e-01,  ..., -5.7046e-01,\n",
            "            7.3070e-01, -5.0612e-01],\n",
            "          [ 1.6185e-01,  1.6721e-01, -1.8856e-01,  ...,  1.3839e-01,\n",
            "            1.1119e-01, -1.3304e-01]],\n",
            "\n",
            "         [[ 2.0964e-02, -1.1701e-02,  1.1192e-02,  ...,  5.2482e-03,\n",
            "           -1.9587e-03,  2.2484e-04],\n",
            "          [-4.1024e-01,  3.0744e-01, -6.4178e-01,  ...,  3.0606e-01,\n",
            "            2.7368e-01,  3.1205e-01],\n",
            "          [-3.8003e-02,  3.9317e-01, -1.9185e-01,  ...,  1.0214e-01,\n",
            "            1.7343e-01,  2.5861e-02],\n",
            "          ...,\n",
            "          [-2.1121e-01, -1.2440e-01,  2.4739e-01,  ..., -1.1927e-01,\n",
            "            1.8545e-01,  3.7033e-01],\n",
            "          [ 2.5567e-01, -4.3500e-01, -6.0938e-01,  ..., -9.0345e-02,\n",
            "           -1.1122e-01,  6.6564e-01],\n",
            "          [-2.8221e-01,  2.4044e-01, -3.3405e-01,  ...,  4.5365e-02,\n",
            "           -2.7381e-01, -2.1318e-01]]]])), (tensor([[[[-1.6448e-01,  2.0219e-01, -1.3342e-01,  ..., -1.5501e+00,\n",
            "            1.5787e+00,  1.7127e-01],\n",
            "          [ 2.7883e-01,  1.3088e+00,  1.7365e+00,  ..., -1.9140e+00,\n",
            "            1.0170e+00,  3.6144e-01],\n",
            "          [ 1.5578e-01,  2.0586e+00,  2.2378e+00,  ..., -1.8335e+00,\n",
            "            1.7183e+00,  7.2260e-01],\n",
            "          ...,\n",
            "          [ 1.5030e+00, -1.1839e+00,  1.0908e+00,  ..., -3.0468e-01,\n",
            "            2.2042e+00, -1.1609e+00],\n",
            "          [-5.4168e-01, -7.8913e-01,  5.9399e-01,  ...,  3.1492e-01,\n",
            "            1.6156e+00, -1.0085e+00],\n",
            "          [-1.3652e-01, -3.5081e-01,  6.5905e-01,  ...,  9.7899e-02,\n",
            "            1.6313e+00, -3.7128e-01]],\n",
            "\n",
            "         [[ 2.2137e-04,  2.4327e-02,  3.5854e-02,  ..., -7.4416e-02,\n",
            "            5.6311e-01, -4.7816e-01],\n",
            "          [-1.5011e+00,  1.7530e+00,  1.3146e+00,  ..., -8.5818e-01,\n",
            "            2.1062e-01,  3.0962e-02],\n",
            "          [-2.9643e-01,  1.8138e+00,  1.6035e+00,  ..., -2.1466e-01,\n",
            "           -1.0340e-01, -4.8993e-01],\n",
            "          ...,\n",
            "          [ 6.1044e-01, -5.5070e-01,  2.4422e+00,  ...,  3.8182e-01,\n",
            "           -9.9446e-01,  6.9845e-02],\n",
            "          [ 7.9118e-01, -7.6865e-01,  5.3444e-01,  ..., -2.6928e-01,\n",
            "            5.5164e-01, -2.2343e-01],\n",
            "          [ 1.4372e-01, -4.0349e-01,  3.3462e-01,  ...,  4.1704e-02,\n",
            "            1.8552e-01, -5.0882e-01]],\n",
            "\n",
            "         [[-1.8473e-02,  2.6562e-02,  5.2061e-02,  ..., -4.8417e-01,\n",
            "           -5.1432e-02,  1.3996e-01],\n",
            "          [ 6.9237e-01,  1.8461e+00,  1.5905e+00,  ...,  4.1086e-01,\n",
            "            2.1760e-01,  6.6701e-01],\n",
            "          [-1.0945e+00, -5.7981e-01,  1.0468e+00,  ..., -1.1276e+00,\n",
            "           -4.4152e-02,  7.0605e-01],\n",
            "          ...,\n",
            "          [-2.1317e+00, -3.3514e+00,  1.0832e+00,  ..., -1.9490e-01,\n",
            "           -1.0982e-02, -4.9804e-01],\n",
            "          [-5.2337e-01, -1.1063e+00,  8.6341e-02,  ...,  1.4601e-01,\n",
            "           -2.3487e-01, -2.8491e-01],\n",
            "          [-1.4122e-01, -3.9941e-01, -1.2979e+00,  ...,  1.3794e+00,\n",
            "           -1.1246e-01,  2.6405e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.1167e-02, -2.5587e-02, -4.5742e-02,  ..., -2.6288e-01,\n",
            "           -1.6256e+00,  6.3315e-01],\n",
            "          [ 1.3170e+00,  3.0562e+00, -2.4126e+00,  ..., -1.5344e+00,\n",
            "            1.8208e-01, -1.5274e-01],\n",
            "          [-2.2419e-02,  2.7819e+00, -2.7672e+00,  ..., -8.9507e-01,\n",
            "           -7.3055e-01,  2.4207e-01],\n",
            "          ...,\n",
            "          [-1.5703e+00, -2.3506e+00, -1.4006e+00,  ..., -5.6839e-01,\n",
            "           -3.3847e+00,  1.0692e+00],\n",
            "          [-3.2976e+00, -2.3366e+00, -1.3756e+00,  ...,  4.2807e-01,\n",
            "           -8.3471e-01,  9.0152e-01],\n",
            "          [ 7.8839e-01, -2.1070e+00,  1.5759e-01,  ..., -2.8583e-01,\n",
            "            2.9924e-01, -1.3318e-01]],\n",
            "\n",
            "         [[ 2.3673e-03,  7.6910e-02,  7.2217e-02,  ...,  1.3606e-01,\n",
            "            5.6268e-01,  4.1328e-01],\n",
            "          [-1.0930e+00, -2.1926e+00,  1.2707e-01,  ...,  1.7698e+00,\n",
            "           -1.1069e+00, -5.9811e-02],\n",
            "          [-4.4995e-01, -1.8787e+00,  3.5870e-01,  ...,  1.6376e+00,\n",
            "           -4.5816e-01,  8.6538e-02],\n",
            "          ...,\n",
            "          [ 2.2731e-02,  2.7731e-01,  2.8896e-01,  ..., -6.4304e-01,\n",
            "            6.0597e-01,  3.2644e-02],\n",
            "          [ 1.6212e+00,  1.0128e-01,  4.6459e-01,  ...,  5.9090e-01,\n",
            "            1.5645e-01, -1.2608e+00],\n",
            "          [ 2.4699e-01,  4.1599e-01, -5.8451e-01,  ...,  5.0646e-01,\n",
            "           -9.1904e-01, -2.5737e-01]],\n",
            "\n",
            "         [[ 1.6955e-02,  1.7252e-02, -2.2555e-02,  ..., -2.5349e-01,\n",
            "            5.5296e-01,  3.2680e-01],\n",
            "          [-2.0476e+00, -3.7560e+00, -2.8731e+00,  ...,  2.2773e-02,\n",
            "            1.7203e-02,  1.5277e+00],\n",
            "          [-1.5365e+00, -3.3424e+00, -2.5700e+00,  ...,  1.2113e-01,\n",
            "           -4.5787e-01, -1.2677e-02],\n",
            "          ...,\n",
            "          [-9.3844e-01,  1.6040e+00, -1.4193e+00,  ...,  1.5835e+00,\n",
            "           -7.3959e-01, -3.5939e-01],\n",
            "          [ 4.3849e+00,  2.4663e+00, -6.4938e-01,  ...,  4.5302e-01,\n",
            "           -6.4337e-01,  4.6439e-01],\n",
            "          [ 1.3422e+00,  2.2235e+00,  2.8492e-01,  ...,  1.4203e-01,\n",
            "           -7.6714e-02,  8.4385e-01]]]]), tensor([[[[-4.7699e+00,  2.9879e-01,  5.2281e+00,  ..., -1.3090e+00,\n",
            "           -5.8094e-01,  4.0745e+00],\n",
            "          [ 2.9588e-02,  4.9886e-01,  2.3364e-01,  ..., -2.4481e-02,\n",
            "           -5.1645e-02, -2.2839e-01],\n",
            "          [ 2.1306e-01, -8.0287e-02,  4.3143e-02,  ...,  1.4790e-01,\n",
            "           -3.8165e-02, -1.2251e-01],\n",
            "          ...,\n",
            "          [ 1.4370e-01, -1.5257e-01,  4.0013e-01,  ..., -2.3720e-01,\n",
            "            1.6624e-01,  1.7682e-01],\n",
            "          [ 3.7497e-01,  5.9143e-02, -9.1039e-01,  ..., -5.8955e-02,\n",
            "           -9.7512e-01, -2.0182e-01],\n",
            "          [ 2.4019e-01, -1.2184e-01,  6.9999e-01,  ...,  2.5383e-01,\n",
            "            1.0516e-01, -3.6996e-01]],\n",
            "\n",
            "         [[ 2.8271e-03,  7.3235e-03, -3.1530e-03,  ..., -4.5797e-02,\n",
            "           -2.7279e-03,  7.2972e-04],\n",
            "          [ 5.3941e-01,  1.4795e-01,  5.5227e-01,  ...,  4.4861e-01,\n",
            "           -6.2848e-01,  2.6197e-01],\n",
            "          [ 1.8154e-01, -4.9665e-01, -1.2928e-01,  ...,  1.6637e-01,\n",
            "           -2.6714e-01,  1.4358e-01],\n",
            "          ...,\n",
            "          [-4.9499e-02,  8.9031e-01,  4.7452e-01,  ..., -1.0264e-01,\n",
            "            1.8433e-01,  6.7848e-01],\n",
            "          [-6.0506e-01, -3.5637e-01,  3.3526e-01,  ...,  1.4510e-01,\n",
            "           -4.8132e-01,  8.3417e-01],\n",
            "          [-1.0148e+00, -5.0443e-01,  2.4443e-01,  ..., -6.9511e-01,\n",
            "           -2.7204e-01, -1.5356e-01]],\n",
            "\n",
            "         [[-7.0197e-03,  2.5181e-03,  1.3996e-01,  ..., -1.1389e-02,\n",
            "            1.2100e-02,  9.0997e-03],\n",
            "          [-5.8489e-02, -1.0151e-01, -4.9755e-01,  ..., -7.1093e-03,\n",
            "            7.5869e-01,  1.1895e-01],\n",
            "          [ 7.2311e-02, -2.1646e-01,  2.8808e-01,  ..., -4.1956e-02,\n",
            "            6.0816e-01,  4.0529e-01],\n",
            "          ...,\n",
            "          [ 5.2266e-01, -3.6980e-01, -4.9102e-01,  ...,  8.0005e-01,\n",
            "           -5.1654e-01,  1.7102e-01],\n",
            "          [ 1.8252e-01, -2.6759e-01, -5.5301e-01,  ...,  3.6269e-01,\n",
            "           -4.5713e-01, -2.4108e-02],\n",
            "          [-4.9535e-01,  8.6951e-01, -4.8792e-01,  ..., -3.4067e-01,\n",
            "           -2.6203e-01, -3.1171e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.0880e-02,  9.0611e-02,  6.6844e-03,  ...,  1.5280e-02,\n",
            "           -1.6396e-02,  3.5105e-02],\n",
            "          [ 5.5602e-01,  1.5396e-01, -1.7121e-01,  ...,  1.5483e-01,\n",
            "           -1.0024e-01,  4.3298e-02],\n",
            "          [ 2.7665e-01,  5.5295e-02,  4.1134e-02,  ..., -2.0917e-01,\n",
            "           -8.5469e-02, -6.1018e-03],\n",
            "          ...,\n",
            "          [-7.1852e-01, -4.2571e-01,  1.0163e+00,  ..., -5.8693e-02,\n",
            "           -7.9026e-01,  4.9661e-02],\n",
            "          [-2.2006e-01,  6.1848e-01, -2.5565e-01,  ..., -8.7127e-01,\n",
            "           -7.4441e-02, -8.6552e-01],\n",
            "          [-5.3051e-01,  6.8677e-01,  7.8956e-02,  ..., -2.2862e-01,\n",
            "           -6.7641e-02, -4.1463e-01]],\n",
            "\n",
            "         [[ 1.2243e-03, -6.0401e-03,  6.7064e-03,  ..., -6.1032e-02,\n",
            "            1.3973e-02,  1.0528e-02],\n",
            "          [ 2.9674e-01, -8.3183e-01, -4.4138e-01,  ..., -8.6065e-01,\n",
            "           -1.1190e-01,  1.4001e+00],\n",
            "          [ 7.3496e-02, -8.4843e-02, -5.8711e-02,  ..., -8.6013e-01,\n",
            "           -3.1122e-01,  2.2790e-01],\n",
            "          ...,\n",
            "          [ 8.9127e-02,  7.5120e-01, -3.0102e-01,  ...,  3.2189e-01,\n",
            "            9.7999e-02,  5.9280e-01],\n",
            "          [-3.3165e-01,  2.4516e-01, -2.9390e-01,  ..., -1.5151e-01,\n",
            "            5.3442e-01, -1.5723e-01],\n",
            "          [ 5.6591e-01, -9.8687e-01, -4.6183e-01,  ..., -9.1117e-01,\n",
            "           -1.5276e-01,  6.6375e-01]],\n",
            "\n",
            "         [[ 1.5984e-02, -5.3925e-03, -1.8793e-04,  ...,  1.1420e-03,\n",
            "            3.3872e-03,  7.9424e-03],\n",
            "          [ 1.2653e-01, -1.0880e-01, -6.6223e-02,  ..., -4.2104e-01,\n",
            "            4.4816e-02, -7.8207e-02],\n",
            "          [ 2.1154e-01,  2.6014e-01,  1.4447e-01,  ..., -1.0526e-01,\n",
            "            2.0856e-01,  1.2876e-01],\n",
            "          ...,\n",
            "          [-2.9934e-01,  7.0825e-01, -2.0586e-01,  ..., -3.1634e-01,\n",
            "           -7.6656e-02,  5.4771e-01],\n",
            "          [-6.5137e-01,  1.4975e-02, -3.7752e-01,  ...,  6.2056e-01,\n",
            "           -6.5078e-01,  1.8301e-01],\n",
            "          [ 1.2440e-01, -8.7393e-02,  1.3298e-01,  ...,  5.0629e-01,\n",
            "           -4.4019e-02,  1.2987e-01]]]])), (tensor([[[[-3.4803e-03, -5.4738e-03,  8.1615e-03,  ..., -3.9087e-01,\n",
            "            1.4746e-01, -2.7758e-01],\n",
            "          [ 6.9990e-02, -2.8312e-01,  2.5205e+00,  ..., -1.4016e-01,\n",
            "           -1.8537e+00,  2.4075e-01],\n",
            "          [-2.7755e-01,  2.9990e-01,  1.9535e+00,  ..., -5.5496e-02,\n",
            "           -1.0407e-01,  6.4753e-01],\n",
            "          ...,\n",
            "          [-1.7920e+00,  2.4720e+00, -1.6100e-02,  ..., -9.8819e-01,\n",
            "            7.0677e-01,  8.4012e-01],\n",
            "          [-2.9911e-01,  9.4662e-01,  1.1358e-01,  ..., -7.1549e-01,\n",
            "            8.9804e-01,  2.9929e-02],\n",
            "          [ 2.4718e-01, -2.4933e-01, -3.3433e-01,  ..., -1.3857e+00,\n",
            "            5.8469e-01,  5.3849e-01]],\n",
            "\n",
            "         [[-4.8204e-04, -2.2382e-02, -3.5711e-03,  ...,  8.5461e+00,\n",
            "           -2.0282e-01,  4.1225e+00],\n",
            "          [-8.0590e-02,  2.9584e-01,  6.4903e-01,  ...,  8.5693e+00,\n",
            "            5.7756e-02,  4.8035e+00],\n",
            "          [ 1.8171e-01,  5.1133e-02,  6.4836e-01,  ...,  8.4274e+00,\n",
            "           -7.3032e-01,  5.2037e+00],\n",
            "          ...,\n",
            "          [-6.4968e-01, -5.0699e-01,  9.5243e-01,  ...,  8.7061e+00,\n",
            "            7.9882e-04,  3.9911e+00],\n",
            "          [-2.3723e-01, -7.0566e-01,  8.6039e-01,  ...,  8.1332e+00,\n",
            "           -5.7124e-01,  3.6455e+00],\n",
            "          [ 5.6551e-01, -4.0438e-01,  8.0455e-01,  ...,  8.2797e+00,\n",
            "           -1.3471e+00,  4.0952e+00]],\n",
            "\n",
            "         [[-1.3357e-02, -4.8802e-03,  2.0273e-03,  ...,  2.6644e-01,\n",
            "           -3.4759e-01,  3.4653e-01],\n",
            "          [ 1.4730e+00, -3.4059e+00,  6.2183e+00,  ..., -1.4100e+00,\n",
            "            2.3630e-01, -8.8129e-01],\n",
            "          [ 7.2606e-01, -2.1793e+00,  5.8274e+00,  ..., -1.4146e+00,\n",
            "           -8.9135e-02, -2.1267e+00],\n",
            "          ...,\n",
            "          [ 1.7007e+00,  4.8316e+00,  3.7606e+00,  ...,  1.4505e+00,\n",
            "            9.1806e-01, -9.4213e-01],\n",
            "          [-2.6100e+00,  5.0880e+00,  3.1733e+00,  ...,  1.3234e+00,\n",
            "            6.3278e-01, -6.6516e-01],\n",
            "          [-1.6233e+00,  1.2125e+00,  4.1787e-01,  ..., -4.6104e-01,\n",
            "           -3.3776e-01, -1.0983e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.2775e-03,  1.2343e-03, -1.9999e-03,  ..., -7.0870e-02,\n",
            "           -5.3969e-02,  6.9337e-01],\n",
            "          [-2.6823e+00,  3.7793e+00, -1.8674e+00,  ..., -3.3264e-01,\n",
            "            4.7577e-01,  1.4775e+00],\n",
            "          [-2.0988e+00,  2.6597e+00,  7.1101e-01,  ..., -9.6917e-01,\n",
            "            1.0734e+00,  1.1808e+00],\n",
            "          ...,\n",
            "          [-1.1194e+00, -4.8352e+00,  2.0407e+00,  ...,  5.0345e-01,\n",
            "            2.1078e-01,  5.7670e-01],\n",
            "          [ 2.8008e+00, -5.0368e+00,  1.8395e+00,  ...,  1.2729e+00,\n",
            "           -6.4424e-01, -1.3139e+00],\n",
            "          [ 2.8458e+00, -4.2847e+00,  2.9240e+00,  ...,  9.9519e-01,\n",
            "            6.2954e-01, -1.1632e+00]],\n",
            "\n",
            "         [[-8.7621e-03, -8.0721e-03,  1.1675e-02,  ...,  3.1910e-01,\n",
            "           -4.6311e-01,  4.6235e-01],\n",
            "          [ 1.7409e-01, -6.1721e+00,  3.6652e-01,  ...,  1.2869e+00,\n",
            "            1.4967e+00,  7.0235e-01],\n",
            "          [ 1.2960e+00, -5.9680e+00,  3.1598e-01,  ...,  1.5141e+00,\n",
            "            6.8613e-01,  1.5480e+00],\n",
            "          ...,\n",
            "          [ 2.7747e+00,  3.8877e+00, -2.1742e+00,  ...,  4.2047e-01,\n",
            "            6.6756e-01,  9.5363e-01],\n",
            "          [-1.1477e+00,  5.0201e+00, -2.2952e+00,  ...,  5.0765e-01,\n",
            "           -6.8968e-01,  5.0084e-01],\n",
            "          [-2.3920e+00,  5.0839e+00, -4.3447e+00,  ...,  1.5017e+00,\n",
            "           -4.6537e-01,  1.4216e+00]],\n",
            "\n",
            "         [[-3.5997e-03,  7.5971e-04,  6.9498e-03,  ...,  1.8417e-01,\n",
            "            1.6544e-01, -3.6817e-01],\n",
            "          [-5.9725e-01, -8.3829e-01,  3.0646e+00,  ..., -5.9618e-01,\n",
            "            2.0500e-01, -1.2207e+00],\n",
            "          [ 3.3455e-01, -1.2705e+00,  3.3725e+00,  ...,  1.6097e-01,\n",
            "            2.4957e-01, -8.4636e-01],\n",
            "          ...,\n",
            "          [-6.1593e-01, -1.1482e+00,  1.9756e+00,  ...,  8.6813e-01,\n",
            "            8.1973e-01,  1.1833e+00],\n",
            "          [ 1.8890e-01, -8.2496e-01,  1.9559e+00,  ...,  7.6030e-02,\n",
            "            9.9291e-01,  1.5267e+00],\n",
            "          [ 3.0976e-01, -7.8498e-01,  2.2704e+00,  ..., -1.1868e-01,\n",
            "            6.8904e-02,  1.6531e+00]]]]), tensor([[[[-1.7807e-03,  1.1529e-02, -1.0488e-02,  ..., -1.9731e-02,\n",
            "            1.0325e-02, -1.3234e-04],\n",
            "          [ 4.8232e-01,  9.9009e-02, -4.6789e-01,  ...,  1.8221e-01,\n",
            "            8.4284e-02, -3.2530e-01],\n",
            "          [-9.9386e-02, -5.0487e-02, -2.7317e-01,  ...,  3.9349e-01,\n",
            "            6.7661e-02, -2.6600e-01],\n",
            "          ...,\n",
            "          [ 4.2643e-01, -5.6259e-01,  5.8974e-01,  ...,  1.5815e-01,\n",
            "           -4.0170e-01,  2.3962e-01],\n",
            "          [ 2.6919e-01,  8.3498e-02,  3.3369e-01,  ..., -1.3320e-01,\n",
            "            5.2354e-01, -3.0867e-01],\n",
            "          [ 2.7373e-01, -5.6085e-02,  5.4709e-02,  ..., -3.8608e-01,\n",
            "            1.2291e-01,  5.9842e-02]],\n",
            "\n",
            "         [[ 1.6107e-03,  2.1739e-03, -9.2730e-03,  ..., -3.1767e-02,\n",
            "           -1.0079e-03, -8.3280e-03],\n",
            "          [ 3.6584e-01,  2.3217e-01, -2.3784e-01,  ...,  2.3926e-02,\n",
            "           -1.5071e-02, -8.1214e-02],\n",
            "          [-1.6788e-01,  3.8507e-01,  2.3769e-01,  ..., -3.8472e-01,\n",
            "            3.3454e-01, -6.1031e-01],\n",
            "          ...,\n",
            "          [ 4.9913e-01,  2.4812e-01,  1.1356e-01,  ..., -8.2332e-02,\n",
            "            1.8789e-01, -2.8757e-01],\n",
            "          [-7.9259e-02,  7.4021e-02, -1.4559e-02,  ...,  5.0345e-01,\n",
            "            3.2782e-01,  2.7175e-02],\n",
            "          [ 1.0887e-01,  2.1558e-02, -1.2413e-01,  ...,  2.9295e-01,\n",
            "           -1.3084e-01, -1.0136e-01]],\n",
            "\n",
            "         [[ 1.0915e-02,  2.8739e-03,  1.4827e-02,  ..., -6.9161e-03,\n",
            "            3.1250e-01, -4.2016e-03],\n",
            "          [ 1.0422e-01, -1.0765e-01, -4.1354e-01,  ...,  1.3578e-01,\n",
            "           -5.1302e-01, -1.7748e-01],\n",
            "          [-1.9889e-01,  2.2344e-01, -1.8828e-01,  ..., -2.5437e-01,\n",
            "           -7.0073e-01, -3.8173e-01],\n",
            "          ...,\n",
            "          [-7.2280e-02,  3.3516e-02,  3.1484e-01,  ...,  3.9279e-01,\n",
            "           -9.5943e-01, -2.9196e-01],\n",
            "          [-5.0020e-02,  6.1483e-01, -1.3599e-01,  ...,  2.3457e-02,\n",
            "           -4.6079e-01, -1.2039e-01],\n",
            "          [-6.7193e-01, -2.5043e-01, -6.1067e-01,  ...,  9.2569e-02,\n",
            "           -1.0382e+00, -6.2955e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.9598e-02, -4.5415e-03, -1.8112e-02,  ...,  2.4446e-02,\n",
            "            6.0231e-03, -5.6761e-03],\n",
            "          [ 3.8191e-01, -4.1300e-01,  8.4358e-01,  ..., -3.7946e-02,\n",
            "            3.3997e-01, -3.9819e-01],\n",
            "          [-2.0592e-01, -6.4628e-01,  1.3234e+00,  ..., -6.0942e-01,\n",
            "            1.8093e-01, -3.1838e-01],\n",
            "          ...,\n",
            "          [ 4.9768e-01, -7.8172e-01, -9.5395e-02,  ...,  1.0513e-01,\n",
            "           -5.4722e-01, -1.3328e-01],\n",
            "          [-1.9237e-01, -6.2240e-01,  6.9527e-02,  ...,  4.2381e-01,\n",
            "           -2.3847e-01,  3.5353e-01],\n",
            "          [ 7.3340e-01,  3.7044e-01, -2.2812e-01,  ...,  6.1715e-01,\n",
            "            2.3349e-02, -2.6583e-01]],\n",
            "\n",
            "         [[-4.1960e-03,  2.3632e-02,  7.7707e-03,  ...,  1.1846e-02,\n",
            "           -6.6012e-02, -4.6450e-02],\n",
            "          [-4.4947e-01,  4.8743e-01,  4.8735e-02,  ...,  7.0050e-01,\n",
            "            1.2483e-01,  4.2184e-01],\n",
            "          [ 9.7679e-03,  1.7621e-01,  6.3813e-01,  ..., -9.0464e-01,\n",
            "            5.8744e-01,  5.1589e-02],\n",
            "          ...,\n",
            "          [-3.6119e-01,  1.7884e-01,  8.3139e-01,  ..., -4.8448e-01,\n",
            "            4.3208e-01,  4.2857e-01],\n",
            "          [-1.2847e-01,  2.3796e-03, -2.1459e-01,  ..., -1.8356e-01,\n",
            "           -1.3586e+00,  2.3818e-01],\n",
            "          [-7.2035e-03,  3.4180e-01, -1.5363e-01,  ..., -3.8620e-01,\n",
            "            6.1737e-01,  6.1522e-01]],\n",
            "\n",
            "         [[-5.5227e-03,  1.7576e-03,  1.8844e-04,  ...,  1.0149e-03,\n",
            "           -4.6516e-03, -9.3371e-04],\n",
            "          [ 3.3015e-01, -2.7544e-01, -3.7467e-01,  ...,  6.7242e-01,\n",
            "            2.7312e-01,  1.0646e-01],\n",
            "          [ 7.7323e-02, -2.4771e-01,  1.2694e-01,  ...,  2.6017e-01,\n",
            "           -1.1652e-01,  6.3164e-01],\n",
            "          ...,\n",
            "          [ 4.0016e-01, -9.0840e-01,  1.7739e-01,  ..., -3.1388e-01,\n",
            "            1.0421e-01, -1.1728e-01],\n",
            "          [-1.1768e-01, -4.7656e-01, -3.7434e-01,  ...,  2.9269e-01,\n",
            "            3.2480e-01, -1.6042e-01],\n",
            "          [ 8.7045e-02, -6.0719e-01,  3.5391e-01,  ..., -6.5445e-01,\n",
            "            3.5695e-01,  4.9125e-01]]]])), (tensor([[[[ 1.4183e-03, -4.7930e-03,  4.7953e-03,  ..., -1.9462e-01,\n",
            "           -3.8151e-01, -1.3820e-01],\n",
            "          [-2.5082e+00, -5.7027e-01,  1.9594e+00,  ...,  4.2805e-01,\n",
            "           -3.5899e-01,  3.1799e-01],\n",
            "          [-1.4112e+00, -3.5492e-01,  1.8023e+00,  ...,  1.6665e-01,\n",
            "           -1.0530e+00, -1.0073e+00],\n",
            "          ...,\n",
            "          [-6.9084e-01, -6.0737e-01,  1.3554e+00,  ..., -3.9433e-01,\n",
            "           -2.6560e-01, -9.7110e-01],\n",
            "          [ 1.5700e+00, -3.8812e-01,  1.5974e+00,  ..., -5.1029e-01,\n",
            "            2.3128e-01, -6.6067e-02],\n",
            "          [ 7.0442e-01,  4.6760e-01,  6.4360e-01,  ..., -1.1112e-01,\n",
            "           -4.5961e-02, -1.6434e-01]],\n",
            "\n",
            "         [[-6.4022e-03,  5.0510e-03, -4.2089e-03,  ..., -2.1346e-01,\n",
            "            4.4172e-01, -2.2409e-01],\n",
            "          [-6.5327e-01, -1.2049e+00,  1.2439e+00,  ..., -2.3735e-01,\n",
            "            9.3312e-01, -3.7538e-02],\n",
            "          [-2.4950e+00, -3.1415e+00,  2.7888e+00,  ..., -2.9279e-01,\n",
            "           -4.1395e-01,  6.6082e-02],\n",
            "          ...,\n",
            "          [-7.1234e-01,  9.8167e-01,  5.0926e-01,  ..., -8.2183e-01,\n",
            "            5.4092e-01, -1.5026e+00],\n",
            "          [ 2.9912e-02,  2.7051e-01, -6.4620e-02,  ..., -7.7561e-01,\n",
            "            8.2983e-02, -1.0021e+00],\n",
            "          [ 4.8404e-02,  6.2966e-01, -1.3842e-01,  ..., -9.8854e-01,\n",
            "            3.9142e-01, -1.3153e+00]],\n",
            "\n",
            "         [[-1.6245e-03, -1.7551e-03, -6.1944e-03,  ..., -1.6644e-01,\n",
            "            3.6654e-01,  3.6153e-01],\n",
            "          [-3.5605e-01,  1.9368e-01, -1.4915e+00,  ...,  1.0095e+00,\n",
            "           -5.1535e-01, -1.0896e+00],\n",
            "          [ 3.1669e-02,  5.3486e-02, -1.1761e+00,  ...,  1.8422e+00,\n",
            "            3.2740e-03, -1.5464e-01],\n",
            "          ...,\n",
            "          [-1.5717e+00, -1.4864e+00, -1.6235e+00,  ..., -3.0809e-02,\n",
            "            8.7577e-01, -3.1730e-01],\n",
            "          [ 7.6064e-01, -3.2203e-01, -7.0178e-01,  ..., -1.1699e+00,\n",
            "            1.5252e+00, -7.1178e-02],\n",
            "          [ 4.9919e-02,  5.6714e-01, -1.0611e+00,  ..., -1.8300e+00,\n",
            "            2.2727e+00,  1.4403e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.6486e-03,  4.3679e-03, -6.1740e-03,  ..., -3.0223e-01,\n",
            "            3.4083e-01,  2.6392e-01],\n",
            "          [-2.8280e+00, -8.0502e-01,  8.4351e-01,  ...,  2.7134e-01,\n",
            "            1.4789e+00,  8.6010e-01],\n",
            "          [ 1.0806e-01, -1.4025e-01,  9.2607e-01,  ..., -6.3806e-01,\n",
            "            1.0212e+00,  9.6263e-01],\n",
            "          ...,\n",
            "          [-5.7677e-01,  1.0316e+00,  7.4423e-01,  ..., -3.7443e-01,\n",
            "            1.7014e-01,  1.3088e+00],\n",
            "          [ 1.1412e-01,  3.7302e-01,  6.1205e-01,  ..., -3.9549e-01,\n",
            "            3.1831e-01, -3.7359e-01],\n",
            "          [ 1.7048e-01,  8.4946e-01,  8.7217e-01,  ..., -9.4935e-01,\n",
            "            3.3920e-01,  1.1150e+00]],\n",
            "\n",
            "         [[-7.0543e-01,  4.5499e+00,  4.6373e-01,  ..., -5.2358e-01,\n",
            "           -3.7959e-01,  5.7654e-01],\n",
            "          [-2.7337e+00,  5.6528e+00, -2.1207e+00,  ..., -9.9077e-01,\n",
            "           -7.7241e-01,  1.1267e+00],\n",
            "          [-3.5825e-01,  4.9419e+00, -2.6378e+00,  ..., -1.2525e+00,\n",
            "           -1.2205e+00,  6.2625e-01],\n",
            "          ...,\n",
            "          [-8.0386e-01, -5.3413e+00, -5.0949e+00,  ...,  2.2696e-01,\n",
            "           -3.4539e-01,  5.4238e-01],\n",
            "          [ 2.3585e+00, -7.6645e+00, -5.0731e+00,  ...,  1.3652e+00,\n",
            "           -4.0276e-01,  3.3603e-01],\n",
            "          [ 2.1206e+00, -7.1068e+00, -7.4835e+00,  ...,  1.4431e+00,\n",
            "           -6.7514e-01,  3.2327e-01]],\n",
            "\n",
            "         [[-8.0333e-03,  4.3576e-03,  6.3718e-03,  ...,  3.2704e-03,\n",
            "           -2.8437e-01, -6.2070e-02],\n",
            "          [-3.5099e-01,  2.7956e-01,  5.4084e-01,  ..., -9.2441e-01,\n",
            "           -4.5437e-01, -1.3515e+00],\n",
            "          [ 2.1656e-01, -2.7816e-01, -1.2748e-01,  ..., -4.1399e-01,\n",
            "           -8.5687e-01, -8.9833e-01],\n",
            "          ...,\n",
            "          [-1.4640e+00, -1.2533e-01,  6.6670e-01,  ..., -1.8148e+00,\n",
            "           -9.9086e-01,  2.2856e+00],\n",
            "          [ 3.3076e-01, -5.9877e-01,  3.5247e-01,  ..., -9.9873e-01,\n",
            "           -1.2454e+00,  2.4616e+00],\n",
            "          [ 5.0424e-01, -2.9027e-01,  1.1090e+00,  ..., -1.9178e+00,\n",
            "           -2.3452e-01,  5.2548e-01]]]]), tensor([[[[ 7.2464e-03, -4.3275e-03, -1.7011e-02,  ...,  1.3992e-03,\n",
            "           -2.6662e-02, -1.9080e-02],\n",
            "          [-4.6367e-01, -1.1554e+00,  6.4331e-01,  ...,  7.4035e-01,\n",
            "            4.6753e-01, -1.1417e-02],\n",
            "          [-2.9869e-01, -8.6038e-01,  2.8245e-02,  ..., -9.5652e-02,\n",
            "            4.8214e-01,  6.8757e-01],\n",
            "          ...,\n",
            "          [-1.1470e+00, -3.7505e-01,  1.6147e-01,  ..., -5.4180e-02,\n",
            "            8.1223e-01, -6.0416e-01],\n",
            "          [-9.7378e-01,  6.4890e-02, -4.9426e-02,  ...,  3.5782e-02,\n",
            "           -6.7848e-01, -6.6274e-01],\n",
            "          [-2.7690e-01, -4.9471e-01, -4.5993e-01,  ...,  3.5344e-01,\n",
            "           -1.8495e-01, -5.2650e-01]],\n",
            "\n",
            "         [[-1.2814e-03, -1.8960e-02,  1.2989e-02,  ..., -2.9168e-02,\n",
            "           -6.0250e-03, -1.5580e-02],\n",
            "          [ 2.9119e-01, -8.8692e-02, -5.2451e-01,  ..., -1.2793e-02,\n",
            "           -1.0690e-01,  1.2289e-01],\n",
            "          [ 5.4331e-01,  3.0855e-01, -6.9633e-01,  ..., -1.4430e-01,\n",
            "            9.8399e-03, -3.2853e-01],\n",
            "          ...,\n",
            "          [-1.4437e+00, -7.0948e-01, -6.2947e-01,  ..., -2.4371e-01,\n",
            "            1.6947e-01,  7.8663e-01],\n",
            "          [-2.8934e-01, -4.1005e-01,  4.7706e-01,  ..., -6.0239e-01,\n",
            "            4.8543e-03,  7.9285e-01],\n",
            "          [-6.5371e-01,  1.4725e-01, -1.0514e+00,  ..., -8.4869e-01,\n",
            "           -9.9254e-02,  2.4985e-01]],\n",
            "\n",
            "         [[-8.4475e-03, -4.5973e-03,  9.7157e-03,  ...,  1.7099e-03,\n",
            "           -6.8745e-03,  4.1227e-03],\n",
            "          [ 5.2632e-01, -1.6253e-01,  8.8660e-03,  ..., -9.0538e-02,\n",
            "            2.5083e-01,  6.3844e-02],\n",
            "          [ 8.5380e-02, -3.7709e-01, -2.1965e-01,  ...,  3.8453e-01,\n",
            "            1.3460e-01, -2.5172e-02],\n",
            "          ...,\n",
            "          [ 1.4037e-01, -1.5465e-01, -3.7236e-01,  ..., -6.6563e-02,\n",
            "            1.9634e-01, -3.6791e-02],\n",
            "          [ 4.2958e-01,  1.2398e-01, -6.9174e-03,  ..., -4.1225e-01,\n",
            "            5.9879e-01, -1.8907e-02],\n",
            "          [ 1.4510e-01,  1.9240e-01,  4.7310e-01,  ..., -3.1116e-01,\n",
            "            1.5656e-01, -3.2847e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.6063e-02,  6.8338e-03,  4.9020e-03,  ..., -1.8263e-02,\n",
            "           -5.5634e-03, -2.7093e-03],\n",
            "          [-1.1434e+00,  8.9438e-01, -7.5685e-01,  ...,  1.0070e-01,\n",
            "            6.2362e-01,  6.8532e-01],\n",
            "          [-7.6501e-01,  1.5747e+00,  2.2062e-02,  ..., -4.0012e-01,\n",
            "           -5.0558e-01,  3.8821e-01],\n",
            "          ...,\n",
            "          [-8.4141e-01, -1.9102e-01,  7.2697e-01,  ...,  1.2456e+00,\n",
            "           -9.9047e-01,  2.6088e-01],\n",
            "          [ 4.5716e-01, -3.2296e-01,  2.5236e-01,  ...,  6.6271e-01,\n",
            "           -2.5298e-02,  4.4252e-01],\n",
            "          [ 3.3351e-01,  2.2395e-01,  1.6556e-01,  ...,  3.8591e-01,\n",
            "            4.5509e-01,  1.2256e+00]],\n",
            "\n",
            "         [[-1.8800e-01,  7.0529e-02,  1.2201e-02,  ...,  1.2432e+00,\n",
            "           -4.2559e-02,  5.1325e-02],\n",
            "          [-6.6368e-02, -1.8237e-01, -2.1727e-01,  ...,  1.2330e+00,\n",
            "            3.2773e-01, -9.1390e-01],\n",
            "          [-1.1394e-01, -1.0842e-01, -1.8841e-01,  ...,  9.4283e-01,\n",
            "            5.9572e-01, -8.5496e-01],\n",
            "          ...,\n",
            "          [-4.5727e-01,  3.1170e-01, -5.6443e-01,  ..., -9.5198e-01,\n",
            "            4.0642e-02, -7.2079e-01],\n",
            "          [-3.4130e-01,  4.0569e-01, -1.7921e-01,  ..., -6.6720e-01,\n",
            "           -6.3851e-01,  5.9709e-01],\n",
            "          [ 5.1634e-03, -9.3380e-02,  7.2409e-02,  ...,  1.8177e+00,\n",
            "            8.4932e-02,  9.4278e-01]],\n",
            "\n",
            "         [[ 7.0114e-03,  2.3901e-02,  7.8115e-03,  ...,  2.6842e-01,\n",
            "           -3.5276e-04,  2.2535e-02],\n",
            "          [ 1.0947e+00, -4.4294e-01,  6.7237e-01,  ...,  5.8760e-01,\n",
            "           -3.1063e-01,  6.1731e-01],\n",
            "          [ 1.3565e+00,  4.6885e-01,  4.9518e-01,  ..., -1.2455e-01,\n",
            "           -2.3653e-01,  5.2572e-01],\n",
            "          ...,\n",
            "          [ 4.6475e-01, -1.1488e-01,  6.7781e-01,  ..., -1.7090e+00,\n",
            "           -1.1799e+00, -1.4822e-01],\n",
            "          [-1.4264e-01, -1.7513e-01, -1.0061e-01,  ..., -2.6089e+00,\n",
            "           -5.3096e-01, -3.2123e-01],\n",
            "          [ 4.6630e-01, -6.7312e-01, -5.6465e-01,  ..., -1.3060e+00,\n",
            "           -1.8656e-01, -2.2446e-01]]]])), (tensor([[[[ 1.2219e-05, -1.4212e-03, -4.9071e-03,  ...,  2.5412e-01,\n",
            "            1.9422e-01,  3.0634e-02],\n",
            "          [-8.5972e-01, -2.9881e-01, -1.1335e+00,  ...,  4.3647e-01,\n",
            "           -1.4412e+00,  8.2340e-01],\n",
            "          [-2.7128e-01,  9.8569e-01, -2.8584e-01,  ...,  1.5706e+00,\n",
            "           -2.7801e-01,  1.1261e+00],\n",
            "          ...,\n",
            "          [ 1.2597e+00, -1.7087e+00, -1.3708e+00,  ..., -3.6398e-02,\n",
            "            1.4699e+00,  1.1411e+00],\n",
            "          [ 1.0130e+00, -1.0196e+00, -4.7976e-01,  ..., -3.1591e-01,\n",
            "            1.0949e+00,  3.6782e-01],\n",
            "          [ 8.0711e-02, -1.0393e+00, -2.8302e-01,  ...,  2.1100e-01,\n",
            "            8.3052e-01,  8.9516e-01]],\n",
            "\n",
            "         [[ 4.5010e-03, -1.4131e-03,  9.9107e-03,  ...,  2.1282e-01,\n",
            "           -3.8148e-01,  5.3391e-01],\n",
            "          [ 2.1411e-02,  4.1531e-01,  1.4167e+00,  ...,  4.3659e-02,\n",
            "            1.0048e+00,  2.6344e-01],\n",
            "          [-4.0706e-01,  8.7109e-01,  1.6017e+00,  ...,  5.8694e-01,\n",
            "            4.1030e-01, -9.0657e-02],\n",
            "          ...,\n",
            "          [-1.2918e+00,  4.7197e-01, -4.2772e-01,  ..., -1.1456e+00,\n",
            "            5.8365e-01, -1.9063e+00],\n",
            "          [-8.0876e-01,  1.0091e+00, -6.8161e-01,  ..., -1.7698e+00,\n",
            "            1.6271e+00, -4.0496e-01],\n",
            "          [ 7.3336e-01, -3.2352e-01,  1.7843e-01,  ...,  1.8694e-02,\n",
            "           -5.9591e-02,  3.9913e-01]],\n",
            "\n",
            "         [[ 4.3765e-03,  8.5539e-03,  7.5949e-03,  ..., -1.4472e-01,\n",
            "            1.6555e+00,  1.5745e-01],\n",
            "          [ 6.2984e-01,  1.3221e+00, -1.4284e+00,  ..., -4.9380e-01,\n",
            "            1.6673e+00, -1.0435e+00],\n",
            "          [ 3.9759e-01,  2.6831e+00, -1.7168e+00,  ..., -4.1678e-01,\n",
            "            1.2203e+00, -1.0777e+00],\n",
            "          ...,\n",
            "          [-4.4681e-01, -1.2383e+00,  4.6649e-01,  ...,  7.1160e-01,\n",
            "            3.7054e+00, -6.4656e-01],\n",
            "          [-1.0425e+00, -4.7891e-01,  5.6133e-01,  ...,  3.8147e-01,\n",
            "            4.4941e+00,  8.7387e-01],\n",
            "          [-2.2150e-01, -7.3390e-01, -1.1202e+00,  ..., -1.4788e+00,\n",
            "            3.8703e+00, -3.4548e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.9670e-03,  5.7842e-03,  1.1253e-04,  ..., -1.7509e-02,\n",
            "            2.8066e-02,  5.5177e-02],\n",
            "          [ 6.9010e-01,  1.7623e+00, -1.7953e+00,  ..., -9.7881e-02,\n",
            "            5.8455e-03, -1.8069e-02],\n",
            "          [-9.1269e-01,  1.2078e+00, -2.5821e+00,  ..., -5.7846e-01,\n",
            "            7.5107e-01, -1.4928e-01],\n",
            "          ...,\n",
            "          [-1.7370e+00, -3.6855e+00, -4.3444e+00,  ...,  2.3827e-01,\n",
            "           -7.0952e-01,  1.7542e-01],\n",
            "          [-2.7140e+00, -2.9628e+00, -4.5969e+00,  ...,  6.5780e-01,\n",
            "           -1.1404e+00,  1.2193e+00],\n",
            "          [-4.7135e-01, -2.5769e+00, -5.1657e+00,  ...,  1.0885e-01,\n",
            "           -3.5629e-01, -9.9040e-02]],\n",
            "\n",
            "         [[-4.8047e-04, -2.6472e-03, -2.7082e-03,  ...,  1.2055e-02,\n",
            "            2.3430e-01, -1.0044e-02],\n",
            "          [ 8.7715e-01,  1.5972e+00,  1.3596e+00,  ...,  1.2431e+00,\n",
            "           -1.5839e+00, -1.4053e+00],\n",
            "          [ 2.3013e+00,  1.8714e+00,  1.9610e+00,  ...,  5.2866e-01,\n",
            "           -1.2440e+00,  2.0371e-01],\n",
            "          ...,\n",
            "          [ 5.4699e-01, -1.3337e+00,  1.7711e+00,  ...,  4.0814e-01,\n",
            "            6.7835e-01, -3.3054e-01],\n",
            "          [-5.9372e-01,  1.0159e-01,  7.6503e-01,  ...,  2.1590e-01,\n",
            "            2.5219e-01,  2.5868e-01],\n",
            "          [-3.6679e-01, -2.0161e-01,  1.2800e+00,  ...,  4.3774e-01,\n",
            "            1.4275e-01,  8.7215e-01]],\n",
            "\n",
            "         [[-6.2342e-03, -3.8025e-03,  8.3174e-03,  ..., -2.8419e-02,\n",
            "           -5.0927e-01, -3.5989e-01],\n",
            "          [ 1.3702e-01,  2.6421e-01,  1.9295e+00,  ...,  1.2367e+00,\n",
            "           -5.6710e-01, -4.6169e-01],\n",
            "          [-4.6081e-01,  1.3808e-01,  1.6244e+00,  ...,  1.5144e+00,\n",
            "           -7.2297e-01, -2.4531e-01],\n",
            "          ...,\n",
            "          [ 1.2132e-01,  1.2588e-01,  1.7103e+00,  ..., -1.7491e+00,\n",
            "           -1.8526e+00,  5.4491e-01],\n",
            "          [ 1.0003e-01,  7.7347e-01,  1.5259e+00,  ..., -1.4311e+00,\n",
            "           -2.1422e+00, -6.5664e-01],\n",
            "          [ 1.0255e-01,  3.5085e-01,  1.4166e+00,  ..., -5.4385e-01,\n",
            "           -8.7713e-01, -3.4386e-01]]]]), tensor([[[[ 2.3856e-01,  1.5003e-02,  6.4392e-03,  ...,  4.9947e-03,\n",
            "            1.7040e-02,  3.7461e-03],\n",
            "          [-4.4626e-01, -4.2923e-01,  3.9888e-01,  ...,  9.1966e-01,\n",
            "           -4.4998e-02, -2.3372e-01],\n",
            "          [-7.0328e-01, -5.9218e-02,  1.1130e-01,  ...,  6.7202e-01,\n",
            "           -4.5361e-03, -2.7323e-01],\n",
            "          ...,\n",
            "          [-1.9548e-01,  1.8426e-02, -3.0099e-01,  ...,  8.4441e-01,\n",
            "           -4.1229e-01,  2.5294e-01],\n",
            "          [-5.6773e-01, -7.8035e-02,  1.5253e-01,  ...,  1.1280e+00,\n",
            "            5.4920e-01,  2.8564e-01],\n",
            "          [-2.6303e-01, -1.4953e-01,  2.2521e-01,  ...,  4.8245e-01,\n",
            "           -7.3258e-01, -7.1164e-01]],\n",
            "\n",
            "         [[ 1.7143e-03,  5.2502e-03,  8.4338e-03,  ...,  9.2047e-03,\n",
            "           -4.4456e-03, -1.1594e-02],\n",
            "          [-3.3974e-02,  2.7248e-01, -3.4262e-01,  ...,  3.9928e-01,\n",
            "           -4.4507e-02, -1.1196e-01],\n",
            "          [ 1.1452e+00,  2.3141e-01, -2.1127e-01,  ...,  1.1040e+00,\n",
            "            3.9765e-01,  5.4806e-01],\n",
            "          ...,\n",
            "          [-3.8012e-01, -7.6062e-01,  1.8840e-02,  ...,  3.2535e-01,\n",
            "            1.6465e-01,  2.8042e-02],\n",
            "          [-5.9468e-01, -1.1172e-01, -6.3205e-01,  ...,  1.7348e-02,\n",
            "           -3.4218e-01, -6.6961e-01],\n",
            "          [-1.1363e+00,  3.9590e-02, -3.9338e-02,  ..., -3.4930e-01,\n",
            "            1.2689e-01,  2.8952e-01]],\n",
            "\n",
            "         [[-1.8334e-02, -9.5330e-03, -1.0567e-02,  ...,  4.6330e-03,\n",
            "            1.5827e-01, -1.3078e-02],\n",
            "          [ 2.6005e-01,  1.1183e-01, -2.3890e-01,  ...,  3.7132e-01,\n",
            "           -1.9651e-01,  1.8932e-01],\n",
            "          [ 1.0870e-01,  1.7569e-02, -3.5189e-01,  ..., -8.9295e-02,\n",
            "           -5.8586e-01,  4.9892e-01],\n",
            "          ...,\n",
            "          [ 8.1219e-01,  8.7522e-01,  7.5751e-01,  ...,  1.1934e-01,\n",
            "           -3.1067e-01,  5.6788e-01],\n",
            "          [ 2.9594e-01,  5.3342e-01,  2.0846e-01,  ..., -4.6061e-01,\n",
            "            8.7580e-02,  6.6852e-02],\n",
            "          [ 1.2860e+00,  1.7672e-01, -5.5138e-01,  ...,  1.2331e-01,\n",
            "            1.8394e-01, -1.5371e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.5222e-02, -8.3377e-03, -2.5169e-02,  ...,  9.1423e-03,\n",
            "            2.7239e-02,  3.8790e-02],\n",
            "          [ 1.0367e+00, -3.4006e-01,  4.1729e-01,  ...,  4.1513e-02,\n",
            "           -4.4777e-02,  1.4043e-01],\n",
            "          [ 1.8091e+00, -3.2472e-01, -6.2144e-01,  ..., -2.2466e-01,\n",
            "           -3.6210e-01, -1.7250e-01],\n",
            "          ...,\n",
            "          [-5.3674e-02, -9.2359e-02, -6.9878e-01,  ..., -8.6329e-01,\n",
            "           -2.7798e-01, -8.9186e-01],\n",
            "          [-7.8546e-01,  4.3368e-01,  1.0808e-01,  ..., -1.0545e+00,\n",
            "            3.2253e-01, -1.5623e-01],\n",
            "          [-4.6378e-01, -1.6682e-01, -9.9403e-01,  ..., -5.2537e-01,\n",
            "            6.6953e-01,  1.3165e+00]],\n",
            "\n",
            "         [[ 5.3234e-03,  4.3054e-03,  9.6839e-03,  ..., -4.4689e-04,\n",
            "           -2.2272e-03, -2.4006e-02],\n",
            "          [ 1.8267e-01,  2.8699e-01, -1.0603e-01,  ..., -7.0947e-01,\n",
            "            1.6392e-01, -3.6565e-02],\n",
            "          [ 2.5029e-01,  2.3636e-01,  2.9991e-01,  ..., -6.2693e-01,\n",
            "            3.2496e-01, -4.0643e-01],\n",
            "          ...,\n",
            "          [ 2.4833e-01,  1.5116e-01, -2.2782e+00,  ...,  4.9187e-01,\n",
            "           -3.9293e-02,  3.9184e-01],\n",
            "          [ 8.4611e-01, -3.5682e-01, -1.8561e+00,  ...,  9.2796e-01,\n",
            "           -1.7067e-01, -6.6125e-01],\n",
            "          [-7.8837e-02, -2.3763e-01, -1.4237e-03,  ...,  1.5534e+00,\n",
            "           -3.9543e-01,  3.7571e-01]],\n",
            "\n",
            "         [[-5.0790e-03,  2.7174e-03, -7.9322e-03,  ..., -1.0118e-02,\n",
            "           -3.1806e-02, -7.7156e-02],\n",
            "          [-2.6217e-01,  3.0455e-01, -1.5847e-01,  ...,  1.0718e-01,\n",
            "            5.1089e-01, -5.5923e-01],\n",
            "          [-2.9926e-01,  4.9200e-01, -3.8935e-01,  ...,  2.9004e-01,\n",
            "            7.0188e-01, -1.4829e-01],\n",
            "          ...,\n",
            "          [-5.5207e-01, -4.6461e-01,  1.4858e+00,  ...,  6.3796e-01,\n",
            "            6.6805e-01,  3.3565e-01],\n",
            "          [ 1.2383e-01, -6.1570e-01,  1.3278e-01,  ...,  4.1385e-01,\n",
            "            4.3056e-01, -5.8162e-01],\n",
            "          [-1.5239e-01,  3.1225e-01,  2.3899e-01,  ...,  1.7584e-01,\n",
            "            8.5961e-01, -2.2462e-01]]]])), (tensor([[[[-5.0888e-03,  4.7314e-03, -1.3977e-02,  ...,  1.8256e-01,\n",
            "            9.6251e-02, -6.0120e-01],\n",
            "          [-1.2779e+00,  8.0782e-01, -1.3364e+00,  ..., -6.1402e-02,\n",
            "           -8.1015e-01, -8.7775e-01],\n",
            "          [-2.2624e-01,  1.6135e+00, -1.9926e+00,  ..., -4.0877e-01,\n",
            "           -7.5509e-01, -1.3878e-01],\n",
            "          ...,\n",
            "          [ 1.1219e+00, -1.4288e+00, -2.4124e+00,  ...,  1.0198e-01,\n",
            "            2.4033e-01, -8.0336e-01],\n",
            "          [ 1.2139e+00, -8.7753e-01, -7.1777e-01,  ..., -3.6827e-01,\n",
            "           -1.0392e+00, -4.5581e-01],\n",
            "          [ 1.5618e-01, -1.4202e-01, -2.2262e+00,  ..., -8.0660e-01,\n",
            "           -5.2637e-01, -9.4804e-01]],\n",
            "\n",
            "         [[-2.2129e-03, -1.3949e-02,  1.7542e-02,  ...,  2.7092e-01,\n",
            "            4.3013e-01, -1.9362e-02],\n",
            "          [ 1.9525e-01, -1.3272e-01, -5.0034e-01,  ...,  5.4344e-01,\n",
            "           -1.4777e+00,  6.7505e-02],\n",
            "          [ 5.1797e-01,  1.1184e-01, -4.9261e-01,  ...,  9.3457e-01,\n",
            "           -8.0085e-01,  5.6709e-02],\n",
            "          ...,\n",
            "          [-1.3786e-01, -2.3682e-01, -5.0823e-02,  ..., -2.2772e-03,\n",
            "            3.7424e-01,  1.4427e-01],\n",
            "          [-6.3981e-02, -5.6315e-01,  4.0872e-01,  ...,  1.8697e-01,\n",
            "           -1.3211e+00, -3.3131e-01],\n",
            "          [ 2.3347e-01, -5.3984e-01,  7.9973e-02,  ..., -1.4701e+00,\n",
            "           -1.3071e-02,  2.0041e-02]],\n",
            "\n",
            "         [[ 2.9212e-04, -6.2404e-03, -6.6700e-03,  ..., -1.5128e-01,\n",
            "           -2.6318e-01, -5.4179e-01],\n",
            "          [ 1.6530e+00, -4.5719e+00, -4.9422e+00,  ..., -6.9314e-01,\n",
            "           -3.7871e-04, -2.5847e+00],\n",
            "          [ 1.3423e+00, -4.2177e+00, -5.3771e+00,  ..., -1.0898e+00,\n",
            "            5.1094e-01, -1.5023e+00],\n",
            "          ...,\n",
            "          [ 1.3600e-01,  3.0973e+00, -4.3383e+00,  ...,  7.9927e-01,\n",
            "            4.0339e-01, -1.0511e+00],\n",
            "          [-2.0059e+00,  4.7366e+00, -4.0631e+00,  ..., -7.2496e-01,\n",
            "            2.5973e-01,  1.3045e-01],\n",
            "          [-1.5074e+00,  3.7224e+00, -3.4297e+00,  ..., -7.4383e-01,\n",
            "            6.1402e-01,  6.0630e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.6391e-04, -2.6870e-03, -5.5156e-03,  ...,  5.3128e-01,\n",
            "           -1.3083e+00, -1.5685e+01],\n",
            "          [ 1.1422e-01, -4.3378e-01,  6.1457e-02,  ...,  1.9316e-01,\n",
            "           -1.3014e+00, -1.2058e+01],\n",
            "          [ 1.3873e-01, -8.1232e-01,  1.0257e-01,  ...,  9.7692e-01,\n",
            "           -7.6818e-01, -1.1640e+01],\n",
            "          ...,\n",
            "          [-1.2210e+00, -1.4316e-01,  1.8010e+00,  ...,  1.6083e-01,\n",
            "           -3.2262e+00, -9.8067e+00],\n",
            "          [ 6.9735e-02,  3.4499e-01,  1.2245e+00,  ...,  1.7781e+00,\n",
            "           -4.4464e+00, -1.0970e+01],\n",
            "          [ 5.0900e-01,  1.3971e-01, -3.8102e-01,  ..., -2.2737e-01,\n",
            "           -1.8298e+00, -1.2195e+01]],\n",
            "\n",
            "         [[ 3.6678e-03,  7.6491e-04,  1.6282e-02,  ...,  1.9192e-01,\n",
            "           -1.0481e+00,  7.8035e-01],\n",
            "          [ 9.0969e-01,  1.4794e+00,  2.3302e+00,  ...,  1.1285e+00,\n",
            "            8.7877e-02, -4.8239e-02],\n",
            "          [ 1.0127e+00,  1.6390e+00,  4.8409e+00,  ...,  1.0039e+00,\n",
            "            7.3904e-01, -4.5037e-01],\n",
            "          ...,\n",
            "          [-1.3560e+00, -8.7291e-01, -9.3326e-01,  ...,  2.1141e+00,\n",
            "            1.2696e+00,  1.8838e+00],\n",
            "          [-4.0385e-01, -2.6420e-01, -6.7968e-01,  ...,  1.7950e+00,\n",
            "            2.5588e+00,  2.7274e+00],\n",
            "          [ 3.3469e-01,  3.7723e-02, -6.7752e-01,  ...,  2.1245e+00,\n",
            "           -2.6614e+00,  1.5055e+00]],\n",
            "\n",
            "         [[-1.2078e-02,  9.9275e-04, -3.8549e-03,  ..., -3.8036e+00,\n",
            "            9.7891e-02, -4.1226e-01],\n",
            "          [-7.4861e-02, -2.7839e-02,  2.1398e+00,  ..., -4.1747e+00,\n",
            "           -9.1267e-01, -9.9431e-01],\n",
            "          [-9.8786e-01, -2.7094e-01,  3.5843e+00,  ..., -3.3407e+00,\n",
            "           -1.1623e+00, -7.7828e-01],\n",
            "          ...,\n",
            "          [-2.7161e-01,  1.0239e+00, -1.9865e-01,  ..., -2.6052e+00,\n",
            "           -9.3551e-01, -5.5189e-01],\n",
            "          [ 6.3369e-01,  4.6631e-01,  7.6263e-01,  ..., -2.7268e+00,\n",
            "           -4.1263e-01, -5.8816e-01],\n",
            "          [ 4.9211e-01,  5.5814e-01, -3.0605e-01,  ..., -5.3322e+00,\n",
            "           -4.2195e-02, -9.7687e-01]]]]), tensor([[[[ 2.6406e-02,  1.5247e-03, -4.0522e-02,  ..., -1.5377e-02,\n",
            "           -1.1136e-02, -4.1089e-03],\n",
            "          [-3.0693e-01,  7.8530e-01,  2.6502e-01,  ...,  3.8501e-01,\n",
            "           -1.1102e-01,  2.9033e-01],\n",
            "          [ 4.2611e-01,  1.9947e-01,  1.3256e-01,  ...,  5.8500e-01,\n",
            "            5.6872e-03,  7.6080e-01],\n",
            "          ...,\n",
            "          [-6.7643e-01, -7.0783e-02,  1.0257e+00,  ...,  4.5016e-01,\n",
            "            6.2602e-01,  5.0807e-02],\n",
            "          [-1.1691e-01, -1.4071e-02,  4.4212e-01,  ..., -1.1119e-01,\n",
            "            4.7296e-01,  2.2051e-01],\n",
            "          [-2.5902e-01,  7.4456e-02,  1.1464e-01,  ...,  1.3192e-03,\n",
            "            1.5570e-02, -9.8426e-02]],\n",
            "\n",
            "         [[ 1.3995e-02, -4.0171e-03,  3.7976e-03,  ..., -8.9353e-03,\n",
            "            6.8712e-04,  3.8692e-03],\n",
            "          [ 1.2024e-01, -2.6517e-01,  1.1334e-01,  ...,  4.9523e-01,\n",
            "            7.4114e-01,  9.3302e-02],\n",
            "          [ 1.1663e-01, -3.3100e-01,  2.6955e-01,  ...,  1.1326e+00,\n",
            "            9.8244e-01, -3.9350e-01],\n",
            "          ...,\n",
            "          [-9.0818e-01,  5.9181e-01,  3.9780e-02,  ...,  2.1928e-01,\n",
            "            1.1160e+00, -9.6416e-02],\n",
            "          [-2.3511e-01,  2.4096e-01, -3.4347e-01,  ...,  2.2558e-01,\n",
            "            5.3077e-01, -2.1939e-01],\n",
            "          [-7.8875e-02, -7.5368e-01,  1.1627e+00,  ...,  4.9461e-01,\n",
            "           -1.8499e-01,  7.8732e-01]],\n",
            "\n",
            "         [[-5.2037e-02, -2.1909e-02, -1.8145e-02,  ...,  1.1860e-02,\n",
            "            1.2866e-02, -2.9116e-02],\n",
            "          [ 5.7141e-01,  3.6254e-02,  1.0401e+00,  ..., -4.3540e-01,\n",
            "            1.7621e-01, -1.5348e+00],\n",
            "          [ 1.5563e+00,  3.1804e-02,  1.3087e+00,  ..., -2.0123e-02,\n",
            "           -1.1006e-01, -9.1655e-01],\n",
            "          ...,\n",
            "          [-1.3782e-01,  6.8978e-01,  3.9268e-01,  ...,  1.7512e-01,\n",
            "           -6.0703e-01, -2.5225e-01],\n",
            "          [-4.7961e-01,  8.6369e-01, -2.4264e-02,  ...,  5.9025e-01,\n",
            "            6.1921e-01, -5.3376e-01],\n",
            "          [ 7.8432e-02, -7.3020e-01,  1.0311e-01,  ...,  6.1043e-01,\n",
            "           -2.6713e-01,  1.4008e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0839e-02,  8.3419e-04,  1.2255e-02,  ..., -1.3084e-02,\n",
            "           -9.3448e-02, -1.9375e-03],\n",
            "          [ 2.7296e-01, -1.3727e-02, -3.2266e-02,  ...,  1.4886e-01,\n",
            "            4.3553e-01,  3.1532e-01],\n",
            "          [-2.1855e-01,  2.2538e-01,  1.3644e-01,  ..., -2.6903e-01,\n",
            "           -2.0733e-01,  3.6954e-02],\n",
            "          ...,\n",
            "          [ 2.9177e-01,  1.1973e-01, -4.6286e-01,  ...,  4.4098e-01,\n",
            "            4.6970e-01,  2.3049e-01],\n",
            "          [ 4.8426e-01,  4.0572e-01, -6.1519e-01,  ...,  1.0736e-01,\n",
            "            1.1085e+00, -3.1982e-01],\n",
            "          [ 6.0464e-01, -6.6900e-01, -1.7920e-01,  ..., -1.7942e-01,\n",
            "            4.7799e-01,  2.7647e-01]],\n",
            "\n",
            "         [[-6.5314e-02,  8.1715e-03, -2.7971e-03,  ...,  1.1680e-02,\n",
            "           -4.5561e-02,  9.6182e-03],\n",
            "          [ 2.4119e-01,  2.9608e-01, -1.7038e-01,  ...,  8.0249e-02,\n",
            "           -2.0885e-01, -9.1977e-02],\n",
            "          [ 5.0221e-01,  2.0648e-01, -7.0674e-01,  ...,  1.2561e-01,\n",
            "            3.7748e-02, -1.1879e-01],\n",
            "          ...,\n",
            "          [ 7.4189e-02,  5.3777e-01, -4.8836e-01,  ..., -2.9340e-01,\n",
            "            3.3447e-02,  2.3348e-01],\n",
            "          [ 2.4899e-01,  2.0255e-01,  7.7370e-02,  ..., -4.6969e-01,\n",
            "           -6.0640e-01, -9.4703e-02],\n",
            "          [-6.7490e-01,  9.1980e-01,  2.0404e-02,  ...,  5.2955e-01,\n",
            "            3.2337e-01,  1.6037e-01]],\n",
            "\n",
            "         [[ 5.8327e-03, -3.8996e-02, -1.7057e-02,  ..., -1.1298e+00,\n",
            "            1.0582e-02,  1.0405e-02],\n",
            "          [ 6.0035e-02, -1.0569e-01,  1.6253e-01,  ..., -5.3869e-01,\n",
            "           -1.6314e-01, -4.2703e-02],\n",
            "          [-1.2807e-02,  1.2684e-01, -1.6462e-01,  ..., -1.1636e-01,\n",
            "           -2.9679e-01,  3.5461e-01],\n",
            "          ...,\n",
            "          [ 9.8685e-01,  3.0512e-01,  4.5058e-02,  ..., -4.5299e-01,\n",
            "            9.2326e-02,  8.0034e-02],\n",
            "          [ 1.0776e-01,  1.9016e-01,  2.7713e-01,  ..., -1.0402e+00,\n",
            "            2.8410e-01, -9.4931e-01],\n",
            "          [ 1.9190e-01,  3.4637e-01,  1.6496e-01,  ...,  5.5435e-01,\n",
            "           -6.8451e-01,  7.0188e-01]]]])), (tensor([[[[ 1.8266e-02, -6.7249e-03,  1.8034e-02,  ..., -2.1072e-01,\n",
            "            2.8506e-01,  1.2756e+00],\n",
            "          [-3.9127e-01,  1.6335e-01,  4.4433e-01,  ...,  1.4770e+00,\n",
            "           -2.1225e+00,  8.0154e-01],\n",
            "          [-5.1041e-01,  8.7205e-02,  3.5561e-01,  ...,  1.0075e+00,\n",
            "           -2.5312e+00,  3.0886e-01],\n",
            "          ...,\n",
            "          [-8.6452e-01,  5.2152e-01,  7.0457e-03,  ...,  9.7777e-01,\n",
            "            1.1615e+00,  2.1386e+00],\n",
            "          [-3.2264e-01,  8.5463e-01,  2.5094e-01,  ...,  1.8796e+00,\n",
            "            2.0547e+00,  1.6645e+00],\n",
            "          [-5.9039e-01,  4.1518e-01,  1.2219e+00,  ...,  1.8285e+00,\n",
            "            2.0790e-01,  1.2311e+00]],\n",
            "\n",
            "         [[-5.7909e-04, -1.7827e-03,  1.6302e-03,  ...,  4.4480e-01,\n",
            "           -1.2455e-01,  6.9193e-01],\n",
            "          [ 8.9485e-01, -1.6941e+00,  1.9581e+00,  ...,  1.3478e-01,\n",
            "           -4.1746e-01,  8.0111e-01],\n",
            "          [ 1.8012e+00, -2.6524e+00,  1.5505e+00,  ..., -4.2179e-02,\n",
            "            1.3198e-01,  2.8178e-01],\n",
            "          ...,\n",
            "          [-9.0764e-02,  1.8036e+00,  2.5772e+00,  ...,  5.2880e-01,\n",
            "            6.5324e-01,  1.1158e+00],\n",
            "          [-1.1331e+00,  5.8200e-01,  9.5577e-01,  ...,  1.3357e+00,\n",
            "            3.7235e-01,  1.2215e+00],\n",
            "          [-1.0350e+00,  6.7852e-01,  8.2246e-01,  ...,  1.9521e-01,\n",
            "            2.1332e-01, -4.3149e-01]],\n",
            "\n",
            "         [[-5.7582e-03, -2.0485e-03,  4.1127e-03,  ...,  3.8921e-01,\n",
            "            2.5357e-02,  2.6445e-02],\n",
            "          [-1.3779e-01, -4.1415e-01,  8.4694e-01,  ..., -1.2200e+00,\n",
            "           -2.0522e-01,  5.3844e-01],\n",
            "          [ 1.0891e+00, -7.9936e-01,  1.5088e+00,  ..., -9.6598e-01,\n",
            "           -5.4669e-01, -5.5189e-01],\n",
            "          ...,\n",
            "          [-7.1902e-01,  1.2174e+00,  1.2847e+00,  ..., -4.5594e-01,\n",
            "           -9.1102e-01,  7.6537e-01],\n",
            "          [ 2.5208e-01,  9.9049e-01,  1.1396e+00,  ..., -5.2212e-01,\n",
            "           -4.8753e-01,  1.4817e+00],\n",
            "          [ 2.2744e-01,  2.3243e-01,  1.7787e-01,  ..., -4.6743e-02,\n",
            "           -1.5012e+00,  9.2037e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.2808e-03, -5.8972e-03, -3.7109e-03,  ...,  2.1150e-02,\n",
            "            3.2311e-01, -7.7595e-01],\n",
            "          [-2.3121e-01,  4.5306e-01,  2.0392e+00,  ...,  1.7582e-01,\n",
            "           -2.1078e-01, -7.3139e-01],\n",
            "          [-9.0278e-01, -5.4096e-01,  1.9420e+00,  ..., -1.1615e+00,\n",
            "           -2.5953e-01, -1.1877e+00],\n",
            "          ...,\n",
            "          [-1.6797e-01, -2.3741e+00, -2.0427e-01,  ...,  4.3988e-01,\n",
            "           -4.2038e-01, -7.6205e-01],\n",
            "          [-1.3964e+00, -1.6694e+00, -3.8054e-01,  ..., -5.2695e-02,\n",
            "           -5.4583e-01, -1.3598e+00],\n",
            "          [ 3.9467e-01,  2.0566e-01, -3.2671e-01,  ..., -4.1014e-01,\n",
            "           -8.9479e-01, -6.6097e-01]],\n",
            "\n",
            "         [[ 1.3419e-02, -1.2791e-02,  8.7127e-03,  ...,  4.3141e-01,\n",
            "           -1.2847e-01,  6.5892e-01],\n",
            "          [ 9.1443e-01,  5.3351e-01, -9.7683e-01,  ..., -3.8803e-01,\n",
            "           -2.1547e-01,  8.3549e-01],\n",
            "          [ 1.3830e+00,  1.2868e+00, -2.0459e+00,  ..., -4.8909e-01,\n",
            "           -7.6317e-01,  1.2577e+00],\n",
            "          ...,\n",
            "          [ 5.0340e-01, -8.9636e-01, -5.6473e-01,  ...,  1.1357e+00,\n",
            "           -1.4339e-01,  8.8587e-02],\n",
            "          [-4.7287e-01, -9.8368e-01, -7.7051e-01,  ...,  8.1378e-01,\n",
            "            6.1293e-01, -2.8916e-01],\n",
            "          [ 2.8482e-01,  3.2337e-01,  9.0865e-01,  ...,  3.6335e-01,\n",
            "            6.4855e-01,  1.4456e-01]],\n",
            "\n",
            "         [[-1.1442e-02, -4.8870e-03, -1.6335e-03,  ..., -3.2656e-01,\n",
            "           -6.8214e-02, -3.1344e-01],\n",
            "          [ 5.9841e-01, -1.1287e+00,  3.6797e-01,  ...,  1.2669e+00,\n",
            "            7.7786e-02,  4.5759e-01],\n",
            "          [ 1.2977e+00, -1.6961e+00,  1.7619e+00,  ...,  1.4679e+00,\n",
            "           -1.0132e+00,  3.8954e-01],\n",
            "          ...,\n",
            "          [ 6.4702e-01,  9.3558e-01,  2.2489e+00,  ..., -1.1694e+00,\n",
            "            8.8550e-01, -7.7461e-01],\n",
            "          [ 1.1814e+00,  7.3665e-01,  3.8311e-01,  ..., -1.0707e+00,\n",
            "            5.7294e-01, -6.7390e-01],\n",
            "          [ 4.9644e-01,  3.6093e-01, -1.3939e-02,  ..., -6.8749e-01,\n",
            "           -2.2701e-01,  8.1192e-01]]]]), tensor([[[[ 5.9808e-03, -1.7434e-02, -5.7100e-03,  ..., -7.2837e-04,\n",
            "           -9.4467e-03, -1.1466e-03],\n",
            "          [ 6.6766e-02, -4.5348e-01,  4.9215e-01,  ..., -1.4179e-01,\n",
            "           -7.9071e-02,  6.6673e-02],\n",
            "          [-4.2061e-01, -5.1347e-01,  5.1461e-01,  ...,  4.5743e-01,\n",
            "           -2.2093e-02,  1.5844e-01],\n",
            "          ...,\n",
            "          [ 1.5178e-01,  7.0231e-01,  9.8340e-01,  ..., -3.9374e-02,\n",
            "            1.4307e-01, -1.6866e-01],\n",
            "          [ 6.8468e-02, -4.1710e-01,  1.0628e+00,  ...,  4.9974e-01,\n",
            "           -5.9899e-01, -1.4269e-01],\n",
            "          [-5.3584e-01, -5.5997e-02, -1.0189e-01,  ..., -9.0374e-01,\n",
            "           -4.6692e-01, -2.9557e-01]],\n",
            "\n",
            "         [[-2.9001e-02, -2.5625e-03,  7.9494e-01,  ..., -4.7567e-02,\n",
            "            4.3798e-02, -9.7441e-02],\n",
            "          [-5.0361e-01,  1.8015e-01, -4.5905e-01,  ...,  2.5622e-01,\n",
            "           -5.5810e-01,  1.3015e-01],\n",
            "          [-3.5491e-01,  2.9811e-01, -6.6611e-01,  ..., -3.1175e-01,\n",
            "            5.1179e-02,  5.9493e-01],\n",
            "          ...,\n",
            "          [ 5.7579e-01,  3.3995e-01,  7.2790e-01,  ..., -7.7910e-02,\n",
            "           -3.8546e-02, -2.1892e-01],\n",
            "          [ 9.0626e-01,  1.3990e-01, -8.7578e-01,  ..., -6.8677e-02,\n",
            "            7.7528e-02,  5.6402e-01],\n",
            "          [ 2.8154e-01,  1.2259e-01, -9.3423e-01,  ..., -7.3586e-01,\n",
            "            5.1022e-02, -5.0809e-01]],\n",
            "\n",
            "         [[ 4.0195e-03, -4.7705e-03,  1.2494e-02,  ..., -1.2351e-02,\n",
            "            1.3729e-02,  3.7716e-02],\n",
            "          [-4.1043e-01,  5.3732e-02,  7.1532e-01,  ...,  9.6000e-01,\n",
            "            6.1130e-01, -2.3912e-01],\n",
            "          [-3.4902e-01,  2.6673e-02, -1.9574e-01,  ...,  1.9245e-01,\n",
            "            2.5367e-01, -1.6658e-01],\n",
            "          ...,\n",
            "          [-4.0837e-01,  5.1568e-02,  8.5760e-01,  ...,  4.3900e-02,\n",
            "           -1.2059e+00, -8.4958e-02],\n",
            "          [-4.7226e-02, -5.9816e-01, -1.0995e-01,  ...,  3.3262e-01,\n",
            "           -2.2200e-02,  1.2864e+00],\n",
            "          [ 1.2679e-01,  1.1851e+00,  3.0848e-01,  ..., -7.4263e-01,\n",
            "            6.0772e-01, -4.2432e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.2238e-03, -2.4932e-01, -7.6398e-03,  ...,  7.7652e-03,\n",
            "            6.3911e-03, -3.0079e-03],\n",
            "          [-2.4373e-01,  3.0723e+00, -3.0661e-01,  ..., -9.1322e-02,\n",
            "           -2.6376e-01,  1.8946e-01],\n",
            "          [-1.0490e+00,  2.6659e+00, -9.0388e-02,  ..., -6.9066e-01,\n",
            "           -1.3952e-01,  3.5761e-01],\n",
            "          ...,\n",
            "          [ 8.2452e-01,  1.1178e+00,  8.5923e-02,  ..., -1.6232e-01,\n",
            "           -2.0516e-01,  1.3640e+00],\n",
            "          [ 3.9468e-01,  1.1211e+00,  3.5309e-01,  ..., -3.2969e-01,\n",
            "            6.8783e-01,  1.1541e+00],\n",
            "          [-7.5584e-01,  4.0686e+00, -2.6064e-01,  ..., -8.1648e-01,\n",
            "            3.5658e-01,  3.7835e-01]],\n",
            "\n",
            "         [[ 3.3645e-02,  1.3158e-02,  1.7117e-02,  ..., -2.9865e-03,\n",
            "           -1.9142e-02,  1.9306e-01],\n",
            "          [-6.9652e-02, -7.3236e-01, -9.0289e-01,  ...,  1.2691e-02,\n",
            "            9.2347e-02, -9.8174e-01],\n",
            "          [ 3.1294e-01, -1.4752e+00, -1.3165e+00,  ..., -7.8216e-01,\n",
            "            4.1874e-01, -1.1853e+00],\n",
            "          ...,\n",
            "          [-5.0238e-01, -5.8368e-01,  1.8505e-01,  ..., -2.5266e-01,\n",
            "            2.9268e-01,  2.9825e-01],\n",
            "          [ 2.5738e-02, -9.9210e-01, -5.4086e-01,  ..., -1.6454e-01,\n",
            "            1.7595e-01, -2.6740e-01],\n",
            "          [-9.9662e-02,  1.1542e-03, -6.2197e-01,  ..., -9.0711e-01,\n",
            "            4.5939e-01, -6.8418e-01]],\n",
            "\n",
            "         [[-1.3204e-01, -2.1045e-01, -1.5918e-01,  ...,  2.3852e-02,\n",
            "           -6.7485e-03,  4.8296e-03],\n",
            "          [ 4.8450e-01,  1.1105e+00,  4.2631e-01,  ..., -5.1881e-01,\n",
            "           -1.4751e-02, -1.9151e-01],\n",
            "          [ 5.4945e-02,  6.9489e-01, -2.3501e-01,  ..., -4.4542e-01,\n",
            "            1.0847e-01,  3.8346e-01],\n",
            "          ...,\n",
            "          [ 1.8164e-01,  4.5473e-01, -2.8748e-01,  ...,  3.0105e-01,\n",
            "           -1.5545e-01,  3.1582e-01],\n",
            "          [ 1.5571e-01,  1.2414e+00, -2.3427e-01,  ...,  4.8731e-02,\n",
            "           -3.4442e-01, -3.9000e-01],\n",
            "          [ 5.5183e-02,  1.1489e+00,  9.1093e-01,  ..., -2.0194e-01,\n",
            "            7.3731e-02, -3.3089e-01]]]])), (tensor([[[[-2.4988e-02, -8.3378e-03,  1.3867e-02,  ...,  2.7679e-01,\n",
            "            7.0756e-01, -2.5761e-02],\n",
            "          [ 5.9952e-01, -1.1669e+00,  1.4275e+00,  ...,  1.1375e+00,\n",
            "           -3.4240e-01, -7.6826e-01],\n",
            "          [ 4.0325e-01, -1.0156e+00,  1.9393e-01,  ...,  3.3474e+00,\n",
            "           -1.2370e+00, -1.1353e+00],\n",
            "          ...,\n",
            "          [-3.4827e-01,  1.2951e+00, -9.0280e-01,  ...,  1.9310e-01,\n",
            "            5.3581e-01,  2.3870e-01],\n",
            "          [-6.2532e-01,  1.6313e+00, -1.5831e-01,  ..., -2.4536e-01,\n",
            "            1.4481e+00,  5.9541e-01],\n",
            "          [-2.5152e-01,  7.4167e-02,  1.5437e-01,  ...,  7.1300e-01,\n",
            "           -1.9750e-01,  2.2545e-01]],\n",
            "\n",
            "         [[ 3.4211e-03, -1.0093e-02,  6.9020e-03,  ...,  6.7939e-02,\n",
            "           -4.1988e-01, -3.2308e-01],\n",
            "          [ 6.0932e-01, -1.0670e+00,  1.2759e+00,  ...,  2.7687e-02,\n",
            "           -1.4397e+00, -1.1616e-01],\n",
            "          [ 7.4480e-01, -9.1825e-01,  2.0481e+00,  ..., -5.4658e-01,\n",
            "           -9.0478e-01,  7.9440e-01],\n",
            "          ...,\n",
            "          [-3.5159e-01,  1.3901e+00,  2.1157e+00,  ..., -7.7734e-02,\n",
            "            7.1153e-01,  2.0012e-01],\n",
            "          [-6.2362e-01,  5.5427e-01,  5.9233e-01,  ..., -1.3117e+00,\n",
            "            5.7589e-01, -9.9119e-01],\n",
            "          [ 3.2966e-01,  7.0606e-01,  1.0222e+00,  ...,  4.5187e-01,\n",
            "            8.3804e-01, -5.3818e-01]],\n",
            "\n",
            "         [[ 1.0533e-03, -1.1641e-03, -4.4302e-03,  ..., -9.2160e-01,\n",
            "           -9.2306e-01,  9.6767e-02],\n",
            "          [ 4.4190e-01,  8.7018e-01, -2.7636e+00,  ..., -1.4078e+00,\n",
            "           -3.9423e-01, -2.5717e-01],\n",
            "          [ 1.7867e+00,  3.2912e+00, -2.1178e+00,  ...,  1.5787e-01,\n",
            "           -4.6570e-01, -6.7312e-01],\n",
            "          ...,\n",
            "          [ 5.0529e-01, -5.3144e-01, -1.2169e+00,  ..., -1.0954e+00,\n",
            "           -1.0563e-01, -2.2014e+00],\n",
            "          [-7.7377e-01, -8.9153e-01, -1.4534e+00,  ..., -7.8338e-01,\n",
            "           -2.7333e-02, -1.9538e+00],\n",
            "          [-7.6799e-01, -5.5612e-01, -6.9687e-01,  ..., -2.0869e+00,\n",
            "            2.2314e-01, -1.2251e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1544e-02,  5.9653e-03, -1.5342e-02,  ...,  1.1278e-01,\n",
            "           -1.7295e-01,  2.8645e+00],\n",
            "          [-1.1755e-01, -5.9489e-01,  7.8573e-01,  ...,  3.4184e-01,\n",
            "            8.8233e-01,  2.0850e+00],\n",
            "          [ 6.0597e-02, -3.2944e-01,  6.2679e-01,  ..., -3.2443e-01,\n",
            "            1.6565e-01,  2.8979e+00],\n",
            "          ...,\n",
            "          [ 3.6659e-01,  6.0564e-01,  8.1849e-01,  ..., -2.7811e-02,\n",
            "            8.3011e-01,  2.7150e+00],\n",
            "          [ 7.0470e-01,  8.6045e-01,  3.6222e-01,  ..., -2.2096e-01,\n",
            "            1.1375e+00,  2.9050e+00],\n",
            "          [ 5.5661e-01,  2.2727e-01,  1.2826e+00,  ..., -3.0566e-01,\n",
            "            7.0025e-01,  1.8744e+00]],\n",
            "\n",
            "         [[-7.8480e-03,  1.7931e-02, -1.4539e-04,  ..., -2.3989e-01,\n",
            "            8.4039e-01, -7.5580e-01],\n",
            "          [-2.3509e-01, -7.2615e-02, -4.0238e-01,  ...,  2.0219e-01,\n",
            "           -1.4904e+00, -4.0113e-01],\n",
            "          [-4.4054e-01, -1.3497e-01, -6.7503e-01,  ...,  3.1206e-01,\n",
            "           -2.0076e+00, -1.0061e+00],\n",
            "          ...,\n",
            "          [ 9.3624e-01, -3.9091e-01, -2.1739e-01,  ..., -3.1251e+00,\n",
            "            2.3947e+00, -1.4651e+00],\n",
            "          [ 9.3961e-01,  1.6635e-01, -4.7400e-01,  ..., -1.2914e+00,\n",
            "            1.5639e+00, -1.7340e+00],\n",
            "          [-1.8381e-01, -3.6337e-01, -4.6131e-02,  ...,  5.6280e-01,\n",
            "           -3.1415e-01, -2.1800e-01]],\n",
            "\n",
            "         [[-3.1917e-03, -9.0220e-03, -4.5010e-04,  ...,  1.6602e-01,\n",
            "            8.4399e-01, -4.2952e-01],\n",
            "          [ 2.3922e-02, -4.9437e-01, -9.3090e-01,  ...,  1.7048e+00,\n",
            "            8.2750e-01,  1.9462e+00],\n",
            "          [-4.6162e-01, -3.2502e-01, -9.5956e-01,  ...,  2.2321e+00,\n",
            "           -5.0765e-01,  2.4272e+00],\n",
            "          ...,\n",
            "          [-4.5943e-01, -1.0851e-01,  4.3288e-01,  ..., -1.3527e+00,\n",
            "            1.9019e+00,  9.2530e-01],\n",
            "          [-3.8237e-01, -4.9805e-01,  1.0423e+00,  ...,  3.8509e-01,\n",
            "            1.7359e+00,  1.9691e+00],\n",
            "          [ 4.5001e-02, -3.6312e-01,  8.1436e-01,  ...,  1.5747e-01,\n",
            "            8.0090e-01,  1.5135e+00]]]]), tensor([[[[ 8.3718e-03, -1.0184e-02, -1.0077e-02,  ..., -1.7428e-02,\n",
            "           -9.9058e-03,  2.1077e-01],\n",
            "          [-2.8101e-01,  9.4027e-01, -2.5123e-01,  ...,  6.4656e-01,\n",
            "            8.9054e-02, -1.8553e+00],\n",
            "          [ 5.2533e-02,  6.3824e-01,  2.9080e-01,  ...,  2.5322e-01,\n",
            "           -3.7807e-01, -2.1739e+00],\n",
            "          ...,\n",
            "          [ 3.8270e-01, -4.8140e-01, -1.3288e-01,  ..., -2.6297e-01,\n",
            "           -3.5642e-01, -1.8373e+00],\n",
            "          [-6.7717e-01,  7.0460e-01,  3.9270e-01,  ..., -3.2257e-01,\n",
            "           -5.3311e-02, -6.9515e-01],\n",
            "          [-8.0857e-01,  1.2813e+00,  4.4293e-01,  ...,  3.2760e-01,\n",
            "           -9.1883e-01,  3.0456e-01]],\n",
            "\n",
            "         [[ 4.0766e-02,  6.1009e-03,  5.4971e-03,  ..., -2.1271e-03,\n",
            "           -2.8373e-03, -1.2149e-02],\n",
            "          [-4.0056e-01, -2.0791e-01,  1.2521e-01,  ...,  3.4430e-01,\n",
            "            3.4429e-01, -5.0787e-01],\n",
            "          [ 3.5902e-01, -1.8471e-02,  7.6370e-02,  ...,  8.9405e-02,\n",
            "           -4.6711e-02,  2.6040e-01],\n",
            "          ...,\n",
            "          [ 1.4105e+00, -9.6045e-02,  4.4505e-02,  ..., -9.7331e-01,\n",
            "           -2.9435e-01,  4.1882e-01],\n",
            "          [-7.7901e-02,  4.1321e-02,  5.1515e-01,  ..., -6.0299e-01,\n",
            "           -4.0063e-01, -6.3853e-01],\n",
            "          [-6.6096e-01, -4.5795e-02, -8.0766e-01,  ...,  6.7437e-01,\n",
            "            6.9492e-01,  2.8747e-01]],\n",
            "\n",
            "         [[ 3.0460e-02,  1.6216e-02,  9.2933e-03,  ..., -2.5438e-02,\n",
            "           -1.7947e-02,  5.4098e-03],\n",
            "          [-1.4393e-01,  1.5555e-01,  2.0529e-01,  ..., -3.1884e-01,\n",
            "           -7.3835e-02, -1.7291e-01],\n",
            "          [ 1.1800e+00,  1.4105e-01, -3.3898e-01,  ..., -7.1203e-01,\n",
            "           -6.4437e-01, -1.2048e-01],\n",
            "          ...,\n",
            "          [ 8.9999e-01,  2.7102e-02, -1.0305e+00,  ...,  1.1422e+00,\n",
            "            3.1484e-01,  9.3718e-01],\n",
            "          [ 5.7367e-01, -6.0806e-01, -1.5057e-01,  ...,  1.9395e-01,\n",
            "            6.3060e-02,  1.6600e-01],\n",
            "          [ 7.6559e-01,  6.4709e-01,  4.1186e-01,  ..., -1.7947e-01,\n",
            "           -6.8273e-02,  6.2034e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.4829e-03, -3.2776e-03, -5.8163e-03,  ..., -1.0110e-02,\n",
            "           -5.7083e-03, -1.8107e-03],\n",
            "          [-2.4279e-01,  9.8039e-01,  9.7611e-01,  ..., -1.6754e+00,\n",
            "           -5.9204e-01, -1.1960e-01],\n",
            "          [-1.8892e-01, -3.6167e-01,  2.8834e-01,  ..., -1.2451e+00,\n",
            "           -2.2394e-01,  1.2225e+00],\n",
            "          ...,\n",
            "          [ 1.0259e-01,  7.4712e-01, -1.5694e-01,  ...,  3.7861e-01,\n",
            "            1.2156e-01,  1.5875e-01],\n",
            "          [ 3.9197e-01, -4.3526e-01,  2.3796e-01,  ..., -1.7233e-02,\n",
            "           -3.7737e-01,  2.3503e-01],\n",
            "          [ 2.5886e-01,  1.6863e-01,  5.7326e-01,  ..., -9.2414e-03,\n",
            "           -1.2243e+00,  2.6353e-01]],\n",
            "\n",
            "         [[-9.1474e-03, -1.2310e-02, -5.9510e-03,  ...,  6.8882e-03,\n",
            "           -1.0164e-02,  8.4293e-03],\n",
            "          [ 6.3124e-01,  6.2046e-01, -4.9988e-01,  ...,  2.8191e-01,\n",
            "            9.3542e-02, -1.6749e-01],\n",
            "          [-1.2537e-01,  2.7830e-01,  1.5340e-02,  ...,  2.1005e-01,\n",
            "            3.7392e-01, -5.9719e-01],\n",
            "          ...,\n",
            "          [-1.4595e-01,  9.8185e-01,  1.9309e-01,  ..., -9.9380e-01,\n",
            "           -2.8241e-01, -1.6091e-01],\n",
            "          [ 7.4747e-02,  9.4908e-01, -7.3785e-02,  ..., -1.4103e-01,\n",
            "            4.9045e-01, -3.3259e-01],\n",
            "          [ 2.3653e-01,  5.4532e-01,  3.7321e-01,  ...,  1.0128e+00,\n",
            "           -7.5412e-01, -4.1012e-01]],\n",
            "\n",
            "         [[-1.3372e-02,  4.6653e-03,  6.6132e-04,  ...,  1.1957e-03,\n",
            "            4.2386e-03,  1.4761e-02],\n",
            "          [-1.7633e-01,  1.2074e+00,  2.8015e-01,  ..., -3.1544e-01,\n",
            "            6.1214e-01,  1.3995e-01],\n",
            "          [ 3.6299e-01,  1.1068e-02, -3.5882e-01,  ..., -3.6097e-01,\n",
            "            5.9186e-01, -8.9345e-01],\n",
            "          ...,\n",
            "          [ 4.6130e-01, -1.0556e+00,  4.3159e-02,  ..., -8.6540e-01,\n",
            "           -2.2209e-01, -4.2425e-01],\n",
            "          [-4.5132e-01,  4.2099e-01,  1.0518e+00,  ..., -5.1153e-01,\n",
            "           -1.1709e+00, -5.9420e-01],\n",
            "          [ 1.9884e-01, -2.9568e-01, -1.0976e+00,  ...,  4.4449e-01,\n",
            "            3.0268e-01, -7.0244e-01]]]])), (tensor([[[[ 1.8862e-03,  1.7078e-04, -7.0854e-03,  ..., -1.4715e+01,\n",
            "           -7.7221e-02,  2.7739e-01],\n",
            "          [-2.7710e-01, -3.5515e-02,  6.3066e-01,  ..., -7.7047e+00,\n",
            "           -1.9897e-01,  2.5490e-01],\n",
            "          [-3.7287e-01,  6.6530e-01,  1.1385e+00,  ..., -7.1432e+00,\n",
            "           -1.1377e+00, -6.5884e-01],\n",
            "          ...,\n",
            "          [-3.2289e-01,  2.4337e-01, -8.3898e-02,  ..., -7.7404e+00,\n",
            "           -6.1624e-01,  1.2987e+00],\n",
            "          [ 4.8610e-01, -4.8436e-03, -2.9468e-01,  ..., -8.5150e+00,\n",
            "           -6.9619e-01,  6.3855e-01],\n",
            "          [-9.2110e-03, -4.6097e-01,  3.0759e-01,  ..., -7.0089e+00,\n",
            "            1.6038e+00,  9.8698e-01]],\n",
            "\n",
            "         [[-6.0791e-03,  1.3495e-02, -1.2354e-03,  ...,  4.0665e-02,\n",
            "           -2.1209e-01,  2.2313e-01],\n",
            "          [ 9.6612e-01,  4.5758e+00,  1.5320e-01,  ...,  1.4602e+00,\n",
            "           -2.6795e-01, -4.0164e-01],\n",
            "          [ 2.3410e+00,  4.6779e+00,  4.0873e-01,  ...,  1.2608e+00,\n",
            "           -1.0126e+00, -7.0834e-01],\n",
            "          ...,\n",
            "          [ 1.9317e+00, -3.5009e+00,  2.4895e+00,  ...,  1.0376e+00,\n",
            "           -4.5623e-01,  6.6906e-01],\n",
            "          [-1.2115e+00, -4.2584e+00,  3.3541e+00,  ...,  2.5243e-01,\n",
            "           -5.4965e-01,  1.0062e-01],\n",
            "          [-1.3179e+00, -2.9095e+00,  3.5617e+00,  ...,  6.2776e-01,\n",
            "           -1.4673e-02, -5.5806e-01]],\n",
            "\n",
            "         [[ 2.7133e-03,  4.9070e-03, -1.4589e-02,  ..., -1.6520e-01,\n",
            "           -2.4321e-01, -2.0978e-01],\n",
            "          [ 2.0846e-02,  3.1052e-01, -1.3848e+00,  ...,  6.0724e-01,\n",
            "           -1.4975e+00, -1.0315e+00],\n",
            "          [-1.7237e+00, -2.4579e-01, -2.0715e+00,  ...,  8.7056e-01,\n",
            "           -1.6861e+00, -2.0441e+00],\n",
            "          ...,\n",
            "          [-4.5490e-01,  3.2761e-01, -2.9464e-01,  ...,  3.8981e-01,\n",
            "           -1.3111e+00, -5.0845e-01],\n",
            "          [ 4.4981e-01, -2.3540e-02, -9.3159e-01,  ..., -2.3206e-01,\n",
            "           -2.1577e+00,  8.9960e-03],\n",
            "          [ 3.4372e-01,  3.5416e-02, -7.0795e-01,  ...,  9.7790e-02,\n",
            "           -2.9814e+00, -1.0763e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0216e-03, -4.5702e-03, -1.1079e-03,  ...,  2.5726e-01,\n",
            "            1.4082e-01,  8.9697e-01],\n",
            "          [-6.2809e-01, -1.7691e+00, -7.6335e-01,  ...,  1.2908e+00,\n",
            "           -5.6155e-01,  9.1033e-01],\n",
            "          [-5.7880e-02, -1.3463e+00, -7.8187e-01,  ...,  4.8594e-01,\n",
            "            4.0782e-01, -2.1194e-01],\n",
            "          ...,\n",
            "          [ 7.0178e-01,  1.5049e+00,  1.3809e+00,  ...,  5.8612e-01,\n",
            "           -7.2761e-01,  8.7902e-01],\n",
            "          [ 4.2125e-01,  1.0053e+00,  3.5854e-01,  ...,  1.0252e+00,\n",
            "           -6.4054e-01,  7.5125e-01],\n",
            "          [ 4.8972e-01,  1.1892e+00,  1.4778e+00,  ...,  2.2003e+00,\n",
            "           -2.0026e+00,  1.4901e+00]],\n",
            "\n",
            "         [[ 3.6356e-03, -3.3283e-03, -2.9808e-03,  ...,  4.0012e-01,\n",
            "            6.1816e-01,  4.4285e-02],\n",
            "          [ 1.5469e+00, -2.0658e+00, -6.9406e-01,  ...,  5.1794e-01,\n",
            "            2.4347e+00, -3.7853e-01],\n",
            "          [ 2.0910e+00, -3.3097e+00, -1.0764e+00,  ..., -6.3868e-02,\n",
            "            1.8774e+00, -9.4905e-01],\n",
            "          ...,\n",
            "          [-8.2112e-01,  7.5524e-01,  3.1646e-01,  ...,  1.0467e+00,\n",
            "           -8.3169e-01,  8.5014e-01],\n",
            "          [ 2.3609e-01, -2.0486e-02,  2.3916e-01,  ..., -3.7466e-01,\n",
            "           -5.4867e-01,  7.5597e-01],\n",
            "          [ 3.9455e-01,  1.6050e-02,  2.7345e-01,  ...,  1.4545e+00,\n",
            "            1.6013e+00,  2.6059e-01]],\n",
            "\n",
            "         [[-1.7848e-03,  6.5836e-03, -8.6173e-03,  ..., -8.6179e-03,\n",
            "            1.1727e+00, -9.9050e-01],\n",
            "          [-9.4711e-01, -1.3788e+00,  1.2242e+00,  ...,  4.7640e-01,\n",
            "            6.7657e-01, -1.8865e+00],\n",
            "          [-1.5530e+00, -1.0001e+00,  1.4616e+00,  ...,  5.9317e-01,\n",
            "            5.3057e-01, -1.3808e+00],\n",
            "          ...,\n",
            "          [-1.8630e-01, -8.9897e-01,  1.2966e+00,  ..., -1.0816e+00,\n",
            "            1.1622e+00, -2.4225e+00],\n",
            "          [ 1.0102e-01,  5.1824e-01,  6.4822e-01,  ..., -5.0578e-01,\n",
            "            1.2634e+00, -2.1999e+00],\n",
            "          [ 3.9234e-01,  8.9858e-01,  5.5479e-01,  ..., -8.2205e-01,\n",
            "            1.1423e+00, -1.7928e+00]]]]), tensor([[[[-2.7757e-03,  1.2667e-02,  1.7305e-02,  ..., -7.1646e-04,\n",
            "           -5.8665e-03,  7.0465e-03],\n",
            "          [-6.6563e-01,  5.5690e-01,  3.5500e-02,  ...,  1.8495e-01,\n",
            "            1.8182e-01,  5.1206e-01],\n",
            "          [-1.9635e-01, -3.6868e-01, -8.1835e-01,  ...,  4.8124e-02,\n",
            "           -1.6149e-01,  1.0347e+00],\n",
            "          ...,\n",
            "          [ 1.5175e-01,  5.0667e-01,  2.5135e-01,  ..., -4.1646e-01,\n",
            "            3.4566e-01,  1.5584e-01],\n",
            "          [ 2.8562e-01, -4.0659e-01,  3.2233e-01,  ...,  1.6079e-01,\n",
            "            3.6820e-01, -2.7652e-02],\n",
            "          [ 4.3815e-02,  4.1785e-01,  4.0997e-01,  ..., -6.6547e-01,\n",
            "           -1.1382e+00, -5.7353e-01]],\n",
            "\n",
            "         [[-8.1659e-03,  2.0689e-02, -3.6330e-02,  ..., -1.4602e-02,\n",
            "            4.9546e-02,  3.2112e-02],\n",
            "          [-1.0351e-01,  1.4481e-01, -3.2485e-01,  ..., -8.5000e-02,\n",
            "            2.0251e-01,  1.5409e-01],\n",
            "          [ 1.5087e-01,  4.3186e-01,  4.9126e-01,  ..., -5.1649e-01,\n",
            "            3.6963e-01,  2.3918e-01],\n",
            "          ...,\n",
            "          [ 4.0798e-01,  1.1665e+00, -1.5027e-02,  ..., -8.4095e-01,\n",
            "            7.8029e-01, -1.2431e-04],\n",
            "          [-1.1844e-01, -4.3113e-01, -4.0447e-01,  ..., -1.0636e-01,\n",
            "            3.2235e-01, -6.1753e-01],\n",
            "          [-5.9484e-01, -8.3608e-01,  3.3205e-01,  ...,  4.0968e-01,\n",
            "           -2.2988e-01,  1.7876e-01]],\n",
            "\n",
            "         [[-5.8137e-03,  1.1385e-04, -4.0669e-03,  ..., -1.0547e-02,\n",
            "            4.2358e-03,  1.9870e-03],\n",
            "          [ 3.4125e-01,  1.0841e-01, -9.0429e-02,  ..., -5.2017e-01,\n",
            "           -7.3554e-02, -7.8749e-01],\n",
            "          [ 8.2608e-01,  8.5928e-02, -2.1672e-01,  ..., -3.5751e-01,\n",
            "           -1.5627e-01, -9.7529e-01],\n",
            "          ...,\n",
            "          [-1.1698e+00,  2.7604e-01, -3.5238e-01,  ..., -5.3343e-01,\n",
            "            2.9505e-02,  4.2948e-02],\n",
            "          [-9.4153e-01,  4.1090e-01, -7.4306e-01,  ...,  3.4801e-02,\n",
            "           -4.3910e-02,  4.2713e-01],\n",
            "          [-1.1829e+00,  1.2114e-01, -3.0788e-01,  ..., -4.7675e-01,\n",
            "            1.0558e+00,  2.4507e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.2895e-01, -1.0364e-02, -6.1233e-02,  ...,  4.3510e-03,\n",
            "           -1.3119e-02,  1.1456e-01],\n",
            "          [-5.8011e-01, -3.4818e-01,  4.6741e-02,  ...,  4.8927e-01,\n",
            "           -1.4689e-01,  1.0967e-01],\n",
            "          [-7.7127e-01, -5.5538e-02,  5.3641e-01,  ...,  1.1397e+00,\n",
            "            4.3396e-01,  7.2143e-01],\n",
            "          ...,\n",
            "          [ 1.9427e+00, -2.9740e-01,  2.5664e-01,  ...,  1.5412e-01,\n",
            "            7.3003e-01, -1.1499e-01],\n",
            "          [ 1.8770e+00, -7.3335e-01,  6.1537e-01,  ..., -2.2068e-01,\n",
            "           -2.1389e-01,  2.3906e-01],\n",
            "          [ 1.3941e+00, -5.4308e-01,  1.3038e-01,  ..., -1.9055e-01,\n",
            "           -9.7904e-02, -3.5567e-01]],\n",
            "\n",
            "         [[-1.1876e-02, -1.1256e-02,  1.5502e-02,  ...,  3.2267e-01,\n",
            "            6.6719e-03,  1.5609e-02],\n",
            "          [ 6.4262e-01, -3.2804e-01, -3.5229e-01,  ...,  1.6569e+00,\n",
            "            3.4439e-01,  7.0397e-01],\n",
            "          [ 1.0191e+00, -5.2664e-01, -5.0136e-01,  ...,  1.2728e+00,\n",
            "           -5.1712e-02,  4.0769e-01],\n",
            "          ...,\n",
            "          [ 1.8661e-01, -6.5631e-01,  7.2922e-02,  ...,  1.3759e+00,\n",
            "            1.7824e+00, -4.5159e-02],\n",
            "          [ 6.7240e-02, -6.9379e-01, -3.7013e-01,  ...,  1.5010e+00,\n",
            "            3.8114e-01,  9.7831e-01],\n",
            "          [-7.2743e-01,  9.8751e-01,  2.1568e-01,  ...,  7.5644e-01,\n",
            "           -4.9495e-01, -5.1341e-01]],\n",
            "\n",
            "         [[ 2.6359e-02, -1.7430e-01, -1.3227e-02,  ..., -5.7080e-02,\n",
            "            2.3303e-03, -9.3365e-02],\n",
            "          [-7.9088e-02,  3.5899e-01,  1.0624e-03,  ...,  2.3654e-01,\n",
            "            7.0672e-01,  1.4963e+00],\n",
            "          [-9.8768e-01, -1.5193e-01, -1.1555e-01,  ...,  5.1255e-01,\n",
            "            7.8587e-01,  1.4184e+00],\n",
            "          ...,\n",
            "          [-1.4560e-01, -1.7948e-01,  8.9930e-01,  ...,  3.2965e-01,\n",
            "            6.9253e-01, -5.5722e-01],\n",
            "          [-9.9491e-02, -1.1142e-02,  3.0012e-01,  ...,  7.8334e-02,\n",
            "            1.2276e-01,  1.2870e-01],\n",
            "          [-1.2420e+00,  3.7142e-01,  9.4857e-02,  ...,  9.7458e-02,\n",
            "            5.3306e-02,  4.3160e-02]]]])), (tensor([[[[-1.7497e-04,  3.1836e-03, -1.1873e-02,  ...,  1.7445e+00,\n",
            "            2.2544e-01,  7.4496e-01],\n",
            "          [-1.4241e+00,  1.5700e+00, -9.1004e-01,  ...,  2.1850e+00,\n",
            "           -6.8702e-01, -6.4260e-01],\n",
            "          [-2.0213e+00,  3.5717e+00, -2.2498e+00,  ...,  1.7300e+00,\n",
            "           -4.9203e-01, -6.4656e-01],\n",
            "          ...,\n",
            "          [-7.6477e-01, -1.4104e+00, -1.4917e+00,  ...,  4.4013e+00,\n",
            "           -8.9758e-01,  1.6011e+00],\n",
            "          [ 6.9875e-01, -2.8647e-01, -1.1569e+00,  ...,  4.5426e+00,\n",
            "           -3.8760e-01,  1.2830e+00],\n",
            "          [ 1.1174e-01, -1.3830e-01, -5.9384e-01,  ...,  1.4615e+00,\n",
            "           -8.1564e-02,  1.1352e+00]],\n",
            "\n",
            "         [[-4.0621e-03,  4.1250e-03, -7.0605e-03,  ...,  3.6911e-01,\n",
            "            5.3469e-01, -9.2322e-02],\n",
            "          [ 1.1530e+00,  2.3696e-01, -2.1782e+00,  ...,  2.5139e-01,\n",
            "            4.5937e-01,  1.2687e+00],\n",
            "          [ 1.0056e+00,  9.6141e-01, -2.1987e+00,  ...,  1.7205e-01,\n",
            "           -9.1929e-01, -4.8753e-01],\n",
            "          ...,\n",
            "          [ 2.2102e-01,  7.3459e-01,  2.3840e-02,  ...,  1.3069e+00,\n",
            "            5.2882e-01, -5.9016e-02],\n",
            "          [-1.5423e+00,  2.7665e-01,  4.1169e-01,  ...,  4.2714e-02,\n",
            "            1.0615e+00, -2.2984e-01],\n",
            "          [-8.0025e-01, -9.2029e-01,  1.0109e+00,  ...,  3.6691e-01,\n",
            "            2.7566e-01,  6.1567e-02]],\n",
            "\n",
            "         [[ 2.8655e-03,  3.5532e-03,  1.3809e-03,  ...,  9.6867e-02,\n",
            "           -1.6507e-01,  3.1232e-01],\n",
            "          [-1.7320e+00,  2.9745e+00,  6.3412e-01,  ...,  2.9523e-01,\n",
            "           -6.6262e-01,  8.1926e-01],\n",
            "          [-3.1504e+00,  4.3965e+00,  1.3177e+00,  ..., -2.1450e-01,\n",
            "            6.8804e-01,  8.6993e-01],\n",
            "          ...,\n",
            "          [-7.9576e-01, -1.5083e-01,  3.9362e+00,  ..., -6.7869e-01,\n",
            "            5.4860e-01, -4.7361e-01],\n",
            "          [ 1.7725e+00, -1.8948e+00,  3.1356e+00,  ..., -1.7828e-01,\n",
            "           -1.1248e+00,  8.7823e-01],\n",
            "          [ 2.1231e+00, -2.8164e+00,  2.5915e+00,  ...,  1.5871e-01,\n",
            "           -3.2011e-01,  1.7180e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.2883e-03,  8.7237e-04,  9.6774e-03,  ...,  7.5268e-02,\n",
            "           -6.1592e-01, -1.6765e-01],\n",
            "          [-5.6260e-01,  1.0920e+00,  3.8267e+00,  ..., -1.7829e-01,\n",
            "           -2.9546e-01, -1.1597e+00],\n",
            "          [-1.3795e+00, -4.9130e-01,  2.8752e+00,  ..., -1.9938e+00,\n",
            "           -2.6546e-01, -9.8303e-01],\n",
            "          ...,\n",
            "          [-2.7703e-01, -2.2809e+00, -1.9044e-01,  ..., -8.5506e-01,\n",
            "           -1.2433e+00,  4.5050e-01],\n",
            "          [ 9.7792e-01, -2.1559e+00,  1.8137e-01,  ..., -2.4761e-01,\n",
            "            2.1833e-01,  1.2410e+00],\n",
            "          [ 3.1851e-01, -1.0016e+00,  9.0271e-02,  ...,  8.0200e-01,\n",
            "           -4.7125e-01,  7.4194e-01]],\n",
            "\n",
            "         [[ 1.1481e-02,  4.5818e-04, -4.8661e-03,  ..., -2.2081e-02,\n",
            "           -7.2229e-01, -4.0498e-01],\n",
            "          [ 2.8660e-02, -2.1874e-01, -2.2657e+00,  ...,  2.3919e+00,\n",
            "            3.9630e-01, -6.6047e-01],\n",
            "          [ 6.6170e-01, -3.9966e-02, -2.1211e+00,  ...,  1.2390e+00,\n",
            "           -1.3638e-01, -1.1851e+00],\n",
            "          ...,\n",
            "          [ 7.0159e-01,  9.0963e-01, -2.9605e+00,  ..., -3.7738e-01,\n",
            "            1.2124e+00, -1.3063e+00],\n",
            "          [-7.7747e-01,  6.7872e-01, -2.0004e+00,  ..., -6.1776e-01,\n",
            "            1.8900e+00, -2.2492e+00],\n",
            "          [-1.5122e-01, -2.7475e-01, -1.2404e+00,  ...,  3.8726e+00,\n",
            "            2.0678e-01, -1.5472e+00]],\n",
            "\n",
            "         [[ 5.9049e-03, -6.3617e-03, -1.4387e-02,  ..., -1.1804e-01,\n",
            "            4.4650e-01, -1.0890e-01],\n",
            "          [ 2.0949e-01, -3.0868e-01, -2.0814e+00,  ...,  4.7146e-01,\n",
            "            6.4901e-01,  1.6871e-01],\n",
            "          [-6.6452e-02,  8.4321e-01, -2.0944e+00,  ...,  1.8493e-03,\n",
            "            1.2516e+00, -1.3670e+00],\n",
            "          ...,\n",
            "          [ 5.9047e-01, -1.2114e+00, -3.1384e+00,  ...,  1.6957e+00,\n",
            "           -1.2208e-01, -1.2140e+00],\n",
            "          [ 8.2943e-01, -9.1391e-01, -2.8358e+00,  ...,  2.1884e+00,\n",
            "            1.1377e+00,  4.1756e-01],\n",
            "          [-3.0949e-01,  5.1149e-02, -1.1358e+00,  ...,  7.0762e-01,\n",
            "            8.5231e-01, -9.2005e-01]]]]), tensor([[[[ 2.3694e-03, -2.0037e-03, -4.5199e-03,  ...,  1.2563e-02,\n",
            "           -3.4025e-03, -1.4322e-02],\n",
            "          [ 1.2524e-01, -1.0804e-01, -7.9959e-01,  ...,  5.9432e-01,\n",
            "           -4.9662e-01,  2.6873e-01],\n",
            "          [ 3.1772e-01, -8.2311e-01,  2.6693e-01,  ...,  1.0011e+00,\n",
            "           -5.5723e-01,  1.1314e+00],\n",
            "          ...,\n",
            "          [-2.4734e-01, -8.3250e-02,  2.5834e-01,  ..., -7.7838e-02,\n",
            "           -1.1470e+00,  8.8276e-01],\n",
            "          [ 1.8243e-01, -6.0080e-01,  6.8180e-01,  ...,  1.5534e+00,\n",
            "           -9.0759e-01,  5.9206e-01],\n",
            "          [ 4.9130e-01,  2.3534e-01, -1.2213e-01,  ...,  3.6593e-01,\n",
            "           -1.3799e-01, -3.2695e-01]],\n",
            "\n",
            "         [[-2.5011e-02, -5.7827e-03, -3.6851e-02,  ...,  2.4575e-02,\n",
            "           -1.6009e-02,  3.7312e-02],\n",
            "          [ 9.8231e-01,  2.2358e-01,  5.6949e-01,  ...,  5.7334e-01,\n",
            "           -2.1788e+00,  8.6986e-01],\n",
            "          [ 9.0465e-01,  1.9364e-01,  4.8326e-01,  ...,  7.2716e-02,\n",
            "           -1.0645e+00,  5.9752e-01],\n",
            "          ...,\n",
            "          [ 6.0823e-01, -2.6580e-02,  5.8186e-01,  ...,  4.1747e-01,\n",
            "           -3.0725e-01,  2.6478e-01],\n",
            "          [-3.3221e-01, -4.1527e-01, -4.8559e-02,  ...,  7.5105e-02,\n",
            "            1.9051e-01, -2.5115e-01],\n",
            "          [ 7.7689e-01,  4.0261e-02, -1.9965e-01,  ...,  2.9675e-01,\n",
            "            4.2359e-02, -8.7961e-01]],\n",
            "\n",
            "         [[-1.9055e-02,  4.5499e-02, -1.7145e-02,  ..., -1.6758e-01,\n",
            "           -9.7433e-03,  2.8496e-02],\n",
            "          [ 6.2057e-01, -9.4108e-01,  5.5028e-01,  ...,  1.4665e+00,\n",
            "           -8.5044e-01,  3.9308e-01],\n",
            "          [ 6.8900e-01, -1.3405e+00, -1.6477e-01,  ...,  2.9994e-01,\n",
            "           -5.0228e-01,  2.3281e-02],\n",
            "          ...,\n",
            "          [ 4.8205e-02, -5.3628e-02, -3.0394e-01,  ..., -4.5017e-01,\n",
            "           -8.6276e-01,  1.8356e-01],\n",
            "          [-3.2263e-01,  4.6761e-01,  4.3560e-01,  ..., -1.9115e-01,\n",
            "            6.9863e-02,  5.7033e-02],\n",
            "          [ 6.4220e-01, -1.1682e+00,  1.1947e+00,  ...,  1.8022e-01,\n",
            "           -1.1001e+00, -1.3389e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.2702e-02,  2.9250e-02,  1.4065e-02,  ...,  2.8626e-03,\n",
            "            4.2803e-02,  4.2425e-02],\n",
            "          [ 2.5491e-01,  9.4674e-01, -2.2260e-01,  ..., -1.4342e-01,\n",
            "            3.6121e-01,  1.8967e-01],\n",
            "          [-5.9524e-01,  4.5394e-01,  3.1239e-01,  ...,  1.4126e+00,\n",
            "            2.3408e+00,  1.4151e+00],\n",
            "          ...,\n",
            "          [-8.3745e-01, -3.0065e-01, -7.2658e-01,  ...,  1.0466e+00,\n",
            "            2.0500e-01, -5.4196e-02],\n",
            "          [-2.9328e-01, -1.4663e-01, -3.7226e-01,  ...,  1.1771e+00,\n",
            "            2.5525e-01, -3.0274e-01],\n",
            "          [-1.0775e+00,  1.0362e+00,  8.8554e-01,  ...,  4.3557e-01,\n",
            "            3.2498e-01, -2.2954e-01]],\n",
            "\n",
            "         [[-1.5105e-02, -8.4232e-03, -7.0608e-04,  ...,  5.5946e-03,\n",
            "           -1.4630e-02, -1.2805e-02],\n",
            "          [-6.4860e-01,  1.2520e+00,  1.0122e+00,  ...,  1.5449e-01,\n",
            "            8.4095e-01, -4.3820e-01],\n",
            "          [-1.0592e+00,  2.0578e+00,  1.2603e+00,  ..., -2.8825e-01,\n",
            "            7.2932e-01, -1.3952e+00],\n",
            "          ...,\n",
            "          [ 1.0835e+00, -9.5175e-01,  7.4397e-01,  ..., -7.0465e-01,\n",
            "            4.4942e-02,  6.6689e-01],\n",
            "          [ 1.0663e+00, -7.6300e-01,  4.9942e-01,  ...,  9.0272e-01,\n",
            "            3.7812e-01,  6.2311e-01],\n",
            "          [-1.1073e+00,  8.2528e-01,  5.2484e-01,  ..., -1.5333e-01,\n",
            "            4.5774e-02, -6.0256e-01]],\n",
            "\n",
            "         [[-2.4152e-03,  8.7456e-04,  7.6198e-04,  ..., -2.1069e-02,\n",
            "            1.4329e-02, -1.5592e-02],\n",
            "          [ 1.8889e-02, -1.1598e+00, -5.5368e-01,  ..., -2.6149e-01,\n",
            "           -9.2241e-02, -8.6601e-01],\n",
            "          [-5.4460e-01, -1.0195e+00, -9.2693e-01,  ..., -3.2579e-01,\n",
            "           -5.3599e-01, -5.1749e-01],\n",
            "          ...,\n",
            "          [-1.3773e+00, -2.5544e-01, -3.4616e-02,  ...,  7.6750e-01,\n",
            "           -1.0966e+00,  1.2722e+00],\n",
            "          [-3.8956e-03,  1.6101e-01, -3.8535e-01,  ...,  6.6261e-01,\n",
            "           -8.3832e-02,  4.7299e-01],\n",
            "          [-2.4014e-01,  7.1960e-02, -1.2300e+00,  ...,  4.5880e-01,\n",
            "           -3.6960e-01, -1.8878e+00]]]])), (tensor([[[[-7.9870e-06, -2.4597e-03, -6.5207e-03,  ..., -5.3168e-01,\n",
            "            1.2444e-01, -2.2677e-01],\n",
            "          [ 2.7570e-01,  3.2437e-01,  5.9037e-02,  ..., -2.5855e+00,\n",
            "            1.0235e+00,  4.0079e-01],\n",
            "          [-8.4146e-01,  7.9242e-01, -8.7020e-01,  ..., -2.2607e+00,\n",
            "            6.5355e-01,  6.4245e-01],\n",
            "          ...,\n",
            "          [-1.6767e+00, -3.0670e-01, -4.5660e-01,  ..., -3.3203e-01,\n",
            "           -3.0718e-01, -6.7179e-01],\n",
            "          [-3.6806e-01, -2.4643e-01, -2.2018e-01,  ...,  1.3453e-02,\n",
            "           -6.5566e-01,  2.2620e-01],\n",
            "          [ 1.8014e-01, -5.3351e-02, -1.6441e-02,  ..., -2.9271e+00,\n",
            "            3.6247e-01,  8.1379e-01]],\n",
            "\n",
            "         [[ 2.8853e-03, -9.4756e-03,  2.1384e-03,  ..., -2.4364e-01,\n",
            "            3.0938e-01,  2.2295e-01],\n",
            "          [-2.7370e-03, -4.9971e-02, -5.7991e-01,  ...,  1.6175e+00,\n",
            "           -1.0371e+00,  3.6623e-01],\n",
            "          [ 3.5699e-01, -3.2090e-01, -1.3553e+00,  ...,  3.8909e-01,\n",
            "           -1.2771e+00,  8.4966e-01],\n",
            "          ...,\n",
            "          [-2.4119e-01,  1.0601e+00,  6.1865e-01,  ...,  2.1957e+00,\n",
            "            1.7276e+00, -1.0078e+00],\n",
            "          [ 1.5340e-01,  5.5877e-01, -2.4013e-01,  ..., -1.2890e-01,\n",
            "            1.3175e+00,  1.2745e+00],\n",
            "          [ 5.3801e-01,  1.7423e-01,  3.3652e-02,  ...,  1.8509e+00,\n",
            "           -1.2195e+00,  9.1096e-01]],\n",
            "\n",
            "         [[-4.3339e-03,  9.5997e-03, -5.0381e-03,  ..., -1.0641e+00,\n",
            "            4.0504e+00,  1.5348e+00],\n",
            "          [ 1.5240e-01,  5.9566e+00, -2.0243e+00,  ..., -1.3942e+00,\n",
            "            4.0950e+00,  1.9800e+00],\n",
            "          [ 3.6597e+00,  6.1612e+00, -1.2481e+00,  ..., -1.8958e-03,\n",
            "            3.6737e+00,  2.0016e+00],\n",
            "          ...,\n",
            "          [ 3.7921e+00, -5.0995e+00,  3.3865e+00,  ..., -6.7441e-01,\n",
            "            1.2983e+00,  1.5066e+00],\n",
            "          [ 8.1382e-01, -7.2436e+00,  4.2166e+00,  ..., -7.2994e-01,\n",
            "            8.4124e-01,  1.5538e+00],\n",
            "          [-2.8474e+00, -5.8333e+00,  4.2911e+00,  ..., -7.2586e-01,\n",
            "            3.1768e+00,  8.7367e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.0732e-04,  6.0202e-03,  1.1500e-02,  ..., -4.3594e-01,\n",
            "           -4.1780e-02,  7.1824e-01],\n",
            "          [ 2.7812e-01,  1.2819e+00,  2.7000e+00,  ..., -1.1300e-01,\n",
            "           -8.5287e-01,  1.9741e+00],\n",
            "          [ 5.7019e-02,  1.0567e+00,  3.4982e+00,  ...,  6.4791e-02,\n",
            "           -4.4707e-01,  2.4345e+00],\n",
            "          ...,\n",
            "          [-1.0454e+00, -2.3929e+00,  5.6850e+00,  ..., -1.4517e+00,\n",
            "           -1.4275e+00,  1.7409e+00],\n",
            "          [-1.7245e-01, -1.7158e+00,  5.7597e+00,  ..., -3.0187e-01,\n",
            "           -1.4034e-02,  5.6622e-01],\n",
            "          [ 7.2819e-01, -8.8859e-01,  3.7925e+00,  ..., -7.7692e-01,\n",
            "           -7.3506e-01,  2.2195e+00]],\n",
            "\n",
            "         [[ 9.7554e-03,  4.8763e-03, -9.5000e-03,  ..., -7.8521e-01,\n",
            "            1.0010e+00,  9.0260e-02],\n",
            "          [ 4.7887e-01, -1.9792e-02, -1.3699e-01,  ..., -3.4742e-01,\n",
            "           -9.5245e-01,  9.2256e-02],\n",
            "          [-1.8246e-01, -1.5583e-01, -3.5725e-02,  ..., -1.8270e-01,\n",
            "           -1.9703e+00, -9.8712e-01],\n",
            "          ...,\n",
            "          [-2.3692e+00, -4.7055e-01, -5.2476e-01,  ..., -6.8343e-01,\n",
            "            6.2739e-01, -9.8069e-01],\n",
            "          [ 2.1209e-01,  7.1547e-02, -3.1420e-02,  ..., -2.1429e+00,\n",
            "           -5.1518e-01, -4.7800e-01],\n",
            "          [ 2.3125e-02, -3.6025e-01, -5.1179e-01,  ..., -2.4318e-01,\n",
            "           -2.2453e+00, -5.1010e-02]],\n",
            "\n",
            "         [[ 5.2145e-03, -9.0371e-04, -5.2568e-03,  ...,  8.5825e-02,\n",
            "            3.0519e-01,  5.3957e-01],\n",
            "          [ 2.1051e+00, -1.2746e-01, -1.9527e+00,  ..., -5.6101e-01,\n",
            "           -4.3100e-01, -2.1717e-01],\n",
            "          [ 7.5302e-01,  1.3797e+00, -9.8732e-01,  ..., -5.6641e-01,\n",
            "            6.5279e-01,  8.3942e-01],\n",
            "          ...,\n",
            "          [-6.8314e-01, -1.4304e-01, -1.2956e+00,  ..., -4.0846e-01,\n",
            "           -2.9258e-01, -6.9443e-01],\n",
            "          [-5.0804e-01,  4.8469e-02, -6.1173e-01,  ..., -1.1118e+00,\n",
            "           -1.9356e-01, -9.4851e-01],\n",
            "          [-2.4692e-01,  5.7606e-02, -1.5086e+00,  ...,  4.1749e-01,\n",
            "           -1.7397e-01, -5.7434e-01]]]]), tensor([[[[ 3.5750e-03,  3.1825e-02, -4.6999e-03,  ...,  9.1161e-03,\n",
            "           -7.5185e-01, -4.9786e-02],\n",
            "          [-2.3645e-01, -1.9457e+00, -2.9527e-01,  ..., -1.6356e-01,\n",
            "            1.1867e+00,  6.0382e-02],\n",
            "          [-5.4728e-01, -1.1081e+00, -9.6930e-01,  ..., -1.1271e-02,\n",
            "            4.5526e-01, -2.6364e-01],\n",
            "          ...,\n",
            "          [ 4.7335e-01, -4.9903e-01, -1.3071e+00,  ...,  1.0475e+00,\n",
            "            1.7993e+00, -3.6286e-01],\n",
            "          [-1.0992e+00,  4.5578e-01, -3.9170e-01,  ...,  9.6266e-01,\n",
            "            2.6379e+00, -3.9883e-01],\n",
            "          [ 6.2006e-01,  4.8211e-01,  9.8150e-01,  ..., -6.1348e-01,\n",
            "            2.9256e+00,  1.1580e+00]],\n",
            "\n",
            "         [[-1.0486e-02, -1.5505e-02,  2.0335e-03,  ..., -2.6911e-02,\n",
            "           -5.6155e-03, -1.0909e-02],\n",
            "          [-8.4835e-01,  2.8831e-01, -4.8156e-01,  ...,  4.3653e-01,\n",
            "            4.5955e-01,  1.1375e-01],\n",
            "          [ 9.2202e-02,  1.8357e-01, -1.5121e-01,  ...,  2.2586e-01,\n",
            "           -4.4576e-01, -3.7738e-01],\n",
            "          ...,\n",
            "          [ 2.7741e-01,  1.9361e+00,  9.5242e-01,  ..., -5.1466e-01,\n",
            "            2.9656e-01, -6.1360e-01],\n",
            "          [ 1.9114e-01,  1.6509e+00,  8.6938e-01,  ..., -5.4445e-01,\n",
            "            1.2367e+00, -7.9810e-01],\n",
            "          [ 3.3186e-01,  1.5405e-01,  3.4413e-01,  ...,  5.4114e-01,\n",
            "           -4.4768e-01,  6.8973e-02]],\n",
            "\n",
            "         [[ 1.5776e-02, -2.2654e-01,  3.1442e-02,  ..., -5.2083e-02,\n",
            "            6.6403e-02, -3.6228e-02],\n",
            "          [ 6.9994e-01,  2.0193e-01, -1.4559e+00,  ..., -5.7621e-01,\n",
            "            4.1468e-01,  1.4720e+00],\n",
            "          [ 7.5696e-01, -2.9948e-01, -6.2665e-01,  ...,  2.7817e-01,\n",
            "            1.2387e+00, -5.9118e-01],\n",
            "          ...,\n",
            "          [ 3.7532e-01,  5.7091e-01,  8.5988e-01,  ...,  1.0332e-01,\n",
            "           -4.7795e-01, -2.7209e-01],\n",
            "          [ 8.4858e-01,  3.6971e-01, -4.8656e-01,  ...,  6.5255e-01,\n",
            "            1.4404e-01,  1.8351e-01],\n",
            "          [ 3.6597e-01, -1.2670e-01, -8.9218e-01,  ..., -4.5834e-01,\n",
            "            4.5548e-01,  8.1163e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0030e-02,  1.3608e-02, -2.9288e-03,  ...,  2.1213e-02,\n",
            "           -7.5089e-03,  2.2707e-02],\n",
            "          [-1.4338e+00,  1.1726e+00,  9.7710e-01,  ...,  2.8892e-01,\n",
            "            3.8092e-01,  7.5164e-01],\n",
            "          [-2.8997e-01,  1.2663e+00,  6.4659e-02,  ...,  1.1497e+00,\n",
            "            7.7681e-01,  3.8637e-01],\n",
            "          ...,\n",
            "          [ 4.9372e-02, -1.6972e+00,  1.0761e-01,  ...,  9.5376e-01,\n",
            "            2.9048e-01, -1.7423e+00],\n",
            "          [ 3.8888e-01, -1.1827e+00, -3.9774e-01,  ..., -4.4072e-02,\n",
            "           -8.1130e-01, -3.9783e-02],\n",
            "          [-3.3916e-01,  7.5790e-01,  1.0007e+00,  ..., -2.1731e-01,\n",
            "           -3.7268e-01, -4.0999e-01]],\n",
            "\n",
            "         [[-6.3805e-03,  1.3533e-02,  2.8625e-03,  ...,  1.6512e-02,\n",
            "           -2.3679e-02, -4.7194e-02],\n",
            "          [-4.2710e-02, -3.3085e-01,  2.9869e-02,  ...,  6.1460e-01,\n",
            "           -9.4981e-02, -4.3045e-01],\n",
            "          [-1.3974e+00, -1.1228e+00,  1.5184e-01,  ...,  9.7557e-01,\n",
            "           -9.5757e-02, -1.7407e-01],\n",
            "          ...,\n",
            "          [-7.2972e-01,  4.5991e-01, -5.9095e-01,  ..., -3.5323e-01,\n",
            "           -1.1868e+00, -9.3047e-01],\n",
            "          [ 2.4895e-01,  1.0083e+00,  6.3657e-02,  ..., -5.9094e-01,\n",
            "           -3.0183e-01, -1.1998e+00],\n",
            "          [ 5.1742e-01, -7.0184e-01, -1.8891e-01,  ..., -4.0249e-01,\n",
            "           -6.4339e-01,  2.9528e-01]],\n",
            "\n",
            "         [[-2.5956e-03, -5.3777e-03,  2.4042e-02,  ..., -1.0883e-03,\n",
            "           -2.2932e-04,  9.6333e-03],\n",
            "          [ 1.4401e-01,  4.6070e-02, -5.4561e-02,  ..., -1.3421e-01,\n",
            "           -4.1427e-01, -4.1840e-01],\n",
            "          [-2.1324e-01,  9.6026e-02, -3.6358e-01,  ..., -9.6625e-01,\n",
            "            1.9663e-01,  2.7881e-01],\n",
            "          ...,\n",
            "          [-5.5559e-01,  6.5174e-01,  1.5450e-01,  ...,  6.9235e-01,\n",
            "            8.9484e-01,  5.7846e-01],\n",
            "          [ 9.7698e-01, -2.3395e-01,  1.1367e+00,  ..., -4.7551e-01,\n",
            "            7.2884e-01, -4.0880e-01],\n",
            "          [ 3.4137e-01, -3.6294e-01, -1.0190e+00,  ..., -2.7811e-01,\n",
            "            6.6446e-03, -4.6361e-01]]]])), (tensor([[[[-4.3355e-03,  7.7282e-03,  5.6895e-03,  ...,  7.0302e-01,\n",
            "            2.8010e-01, -8.5836e-01],\n",
            "          [-9.9790e-01,  1.5477e+00,  1.0126e+00,  ...,  6.4083e-01,\n",
            "            4.2159e-01, -3.9477e-01],\n",
            "          [ 1.7747e+00, -2.0157e-01, -1.4168e-01,  ...,  3.1115e-01,\n",
            "            5.2945e-01, -2.2999e-01],\n",
            "          ...,\n",
            "          [ 2.2583e+00, -3.2292e+00, -2.2137e+00,  ...,  1.4110e+00,\n",
            "            4.4322e-01, -1.4619e+00],\n",
            "          [ 8.8211e-01, -9.2895e-01, -5.2154e-01,  ..., -7.4168e-01,\n",
            "            1.9759e+00, -1.5739e+00],\n",
            "          [ 2.8039e-01, -1.3506e+00, -1.2962e+00,  ...,  4.2219e-01,\n",
            "            6.6062e-01, -3.8960e-01]],\n",
            "\n",
            "         [[-3.2512e-03, -1.8168e-03, -3.4495e-03,  ...,  6.8663e-01,\n",
            "            8.5931e-02, -9.9529e-03],\n",
            "          [ 2.8062e-01, -1.0457e-01,  3.8963e-01,  ...,  1.3751e+00,\n",
            "           -1.7179e+00,  3.3256e-01],\n",
            "          [-6.5885e-01, -1.2651e+00, -1.4439e-01,  ...,  1.3036e+00,\n",
            "           -4.0856e-01, -1.1592e+00],\n",
            "          ...,\n",
            "          [ 1.2157e-01, -3.0528e-02,  2.2016e-01,  ...,  4.0043e-01,\n",
            "           -5.0469e-01, -9.3455e-01],\n",
            "          [ 1.2519e-01,  2.2591e-01, -5.8083e-02,  ...,  1.4189e+00,\n",
            "           -1.8182e-01,  1.5715e-01],\n",
            "          [ 4.1741e-01, -4.0413e-01, -9.1434e-01,  ...,  2.4504e+00,\n",
            "            1.0123e+00, -6.3740e-01]],\n",
            "\n",
            "         [[-2.2066e-03, -2.4377e-03, -3.0396e-03,  ...,  5.8064e-01,\n",
            "            2.4573e-01, -6.0368e-01],\n",
            "          [-3.3808e+00, -1.2703e+00, -2.1543e+00,  ...,  1.3234e+00,\n",
            "            5.0349e-01,  9.1282e-01],\n",
            "          [ 2.1979e-01,  3.9992e-01, -9.7243e-01,  ...,  2.7227e+00,\n",
            "            5.4707e-01, -2.4674e-01],\n",
            "          ...,\n",
            "          [ 1.4521e+00,  3.8789e+00,  1.5612e+00,  ...,  1.8115e+00,\n",
            "            3.5675e-01, -2.9837e-01],\n",
            "          [ 2.3962e+00,  1.9910e+00,  1.8140e+00,  ...,  1.6387e-01,\n",
            "            2.9895e-01,  5.2446e-01],\n",
            "          [ 1.1581e+00,  1.7466e+00,  2.0722e+00,  ...,  1.2300e-01,\n",
            "            1.5941e+00,  4.7353e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.2921e-02,  9.5357e-03, -1.4564e-02,  ..., -5.8244e-01,\n",
            "            6.8873e-02, -2.8892e-01],\n",
            "          [-4.9489e-01, -5.0066e-01, -2.2439e+00,  ..., -1.9329e+00,\n",
            "           -2.7777e+00, -5.0688e-01],\n",
            "          [-1.8258e+00, -1.7505e+00, -2.8302e+00,  ..., -6.7201e-01,\n",
            "           -3.3341e+00,  4.7155e-01],\n",
            "          ...,\n",
            "          [-1.6380e+00, -1.9711e+00,  1.8419e-01,  ..., -2.1354e+00,\n",
            "            2.7262e-01, -7.7587e-01],\n",
            "          [ 8.9927e-01, -1.5598e+00,  7.2381e-01,  ..., -1.2197e+00,\n",
            "            7.1106e-01, -9.2023e-01],\n",
            "          [ 6.6177e-01, -5.1924e-02,  5.5672e-01,  ..., -1.9996e+00,\n",
            "           -1.8366e-01, -1.2691e+00]],\n",
            "\n",
            "         [[-7.9533e-03,  1.9019e-02,  6.7267e-03,  ..., -5.2032e-02,\n",
            "           -2.2747e-01,  1.0235e-01],\n",
            "          [-8.9058e-01,  1.3351e-01,  1.4244e+00,  ..., -1.3109e+00,\n",
            "           -1.3489e-01, -1.6537e+00],\n",
            "          [-6.5204e-01,  8.6725e-01,  2.0482e+00,  ..., -3.6292e-01,\n",
            "           -8.7565e-01, -8.6973e-01],\n",
            "          ...,\n",
            "          [ 7.6756e-01, -2.6273e-01,  1.9504e+00,  ...,  3.4755e-01,\n",
            "           -7.5023e-01, -8.2996e-01],\n",
            "          [ 3.8985e-01, -8.4673e-02,  1.4617e+00,  ...,  2.5597e-01,\n",
            "           -1.2126e+00, -8.7093e-01],\n",
            "          [-1.9742e-01, -2.2630e-01,  7.2076e-01,  ...,  2.6453e-01,\n",
            "            4.1700e-01, -3.2031e-01]],\n",
            "\n",
            "         [[-5.9521e-03,  1.0376e-02, -7.5561e-04,  ...,  3.1159e-01,\n",
            "           -1.1696e-01, -1.6064e-01],\n",
            "          [-9.4370e-01,  4.1652e+00, -2.0335e+00,  ..., -1.9286e-01,\n",
            "           -1.8601e+00,  2.1135e-02],\n",
            "          [ 2.8686e+00,  3.3939e+00, -2.9759e+00,  ..., -1.8186e+00,\n",
            "           -1.0548e+00, -1.9158e-01],\n",
            "          ...,\n",
            "          [ 1.4742e+00, -1.0546e+00, -2.9872e+00,  ..., -1.5658e-01,\n",
            "            7.4993e-01,  4.4377e-01],\n",
            "          [-2.6624e-01, -2.4337e-01, -1.8541e+00,  ...,  4.1016e-01,\n",
            "            1.0250e+00,  7.0781e-01],\n",
            "          [-1.3057e-01, -7.3296e-01, -2.0500e+00,  ..., -2.9059e-01,\n",
            "            1.2969e+00, -3.6147e-01]]]]), tensor([[[[ 4.0783e-02,  6.7613e-03,  1.7115e-04,  ..., -3.9433e-03,\n",
            "           -3.2272e-02, -3.9519e-03],\n",
            "          [-1.5894e-01,  5.5349e-01, -1.9731e-01,  ..., -5.2332e-01,\n",
            "           -7.1668e-01, -5.9213e-01],\n",
            "          [ 1.2174e+00,  1.4720e+00, -1.2000e+00,  ..., -6.8189e-02,\n",
            "           -2.4459e-02, -4.7446e-01],\n",
            "          ...,\n",
            "          [ 6.4320e-01, -3.3781e-01, -9.8903e-02,  ...,  4.5874e-01,\n",
            "            2.5455e-01,  9.1688e-01],\n",
            "          [-1.4021e-01, -9.7384e-02,  8.9645e-01,  ..., -6.3527e-01,\n",
            "           -1.9662e-01,  1.0690e+00],\n",
            "          [-8.8323e-01, -3.5692e-01,  8.9608e-01,  ..., -1.6108e-01,\n",
            "           -1.3393e+00, -2.1444e-01]],\n",
            "\n",
            "         [[ 4.9078e-03,  7.1927e-03,  6.1872e-03,  ..., -1.3555e-02,\n",
            "           -1.1723e-02,  1.1825e-02],\n",
            "          [ 2.1071e+00,  1.4253e-01,  1.7301e+00,  ...,  2.9806e+00,\n",
            "           -8.1333e-01,  1.2919e+00],\n",
            "          [-2.0843e-01,  1.9297e+00,  1.8473e+00,  ...,  2.6058e+00,\n",
            "            1.2295e+00,  5.3459e-01],\n",
            "          ...,\n",
            "          [-5.7958e-01,  1.3986e+00, -1.7410e-01,  ...,  4.8417e-01,\n",
            "            7.4658e-01, -1.3098e+00],\n",
            "          [ 1.6785e-01,  3.8780e-02,  3.5150e-01,  ..., -7.7572e-01,\n",
            "            1.0804e+00, -1.8117e+00],\n",
            "          [ 3.1153e-01,  7.3329e-01,  5.2591e-01,  ...,  1.5896e+00,\n",
            "            9.8940e-01, -1.7542e-01]],\n",
            "\n",
            "         [[-1.1155e-02,  3.2292e-02, -2.3644e-02,  ..., -2.1332e-03,\n",
            "            6.2877e-02,  1.4496e-02],\n",
            "          [-5.9139e-02, -7.1561e-03,  7.6887e-01,  ...,  5.5567e-01,\n",
            "            2.7652e-02, -1.2114e+00],\n",
            "          [-9.7017e-01, -2.7831e-01,  5.8097e-01,  ...,  9.3668e-01,\n",
            "            7.3358e-01, -3.0224e-01],\n",
            "          ...,\n",
            "          [-5.5933e-01, -1.6462e-01, -5.9065e-01,  ...,  7.3668e-01,\n",
            "            1.4589e+00,  4.5813e-01],\n",
            "          [-2.6707e-01, -1.1192e+00,  3.3397e-02,  ...,  8.2270e-01,\n",
            "            7.0455e-01, -1.2210e+00],\n",
            "          [-1.0363e+00, -8.1738e-01, -1.1603e-01,  ...,  1.8446e-01,\n",
            "            5.7543e-01, -7.1304e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5117e-02, -3.6552e-02, -1.4777e-02,  ..., -6.4422e-03,\n",
            "            1.3913e-02, -6.5537e-03],\n",
            "          [-5.1724e-01,  7.0221e-01,  6.2121e-01,  ...,  1.6530e+00,\n",
            "            7.9505e-01,  3.0993e-01],\n",
            "          [-2.5184e-01,  5.1659e-01, -3.8130e-01,  ...,  4.3096e-01,\n",
            "            7.8617e-01,  4.3740e-01],\n",
            "          ...,\n",
            "          [-3.2144e-01, -5.6024e-02,  3.1282e-01,  ..., -2.2146e-01,\n",
            "            2.9965e-01,  3.9707e-01],\n",
            "          [-2.1494e-01,  3.3823e-01,  1.1517e-01,  ..., -2.7635e-01,\n",
            "            3.8974e-01, -4.0016e-01],\n",
            "          [-8.9630e-02, -4.9339e-01,  6.9893e-01,  ..., -1.7083e-01,\n",
            "           -5.1475e-01,  8.9240e-01]],\n",
            "\n",
            "         [[-1.8743e-02, -6.0592e-02, -1.2893e-02,  ..., -1.4248e-01,\n",
            "            1.4567e-02, -6.3177e-03],\n",
            "          [ 4.4530e-01, -1.6335e-02, -3.0135e-01,  ...,  6.9837e-01,\n",
            "            1.0660e+00, -1.4528e-01],\n",
            "          [-1.2542e+00, -5.7668e-01, -5.6020e-02,  ...,  1.2792e+00,\n",
            "            2.1099e+00,  2.2800e-02],\n",
            "          ...,\n",
            "          [ 1.1037e+00,  1.0897e-01,  4.1268e-01,  ...,  9.8448e-01,\n",
            "           -6.2833e-01,  1.8109e-01],\n",
            "          [ 5.5934e-01, -4.8229e-01,  1.6829e-01,  ...,  1.7068e+00,\n",
            "            6.7011e-02,  6.2327e-01],\n",
            "          [ 8.4862e-01,  1.5842e+00, -5.6859e-01,  ...,  1.4485e+00,\n",
            "            2.6608e-01,  1.6001e+00]],\n",
            "\n",
            "         [[ 2.3403e-02, -7.0186e-03, -1.1959e-03,  ..., -1.0015e-02,\n",
            "           -2.0702e-02,  9.9485e-03],\n",
            "          [ 1.5923e-01, -6.9879e-03,  4.8745e-01,  ...,  4.7307e-01,\n",
            "           -9.9089e-01, -1.8968e-01],\n",
            "          [ 9.6516e-02,  6.1683e-02,  5.2820e-02,  ...,  8.7914e-02,\n",
            "           -4.0485e-01,  2.2162e-01],\n",
            "          ...,\n",
            "          [ 3.1164e-02,  3.3530e-02,  7.0100e-01,  ...,  2.2256e-02,\n",
            "           -1.4666e-01,  9.1354e-01],\n",
            "          [-1.5264e-01,  5.7399e-01,  1.2792e-01,  ..., -1.3487e-01,\n",
            "           -7.2123e-01,  2.7920e-01],\n",
            "          [-7.7116e-01, -2.7190e-01,  7.2908e-01,  ...,  1.3487e-01,\n",
            "            3.5590e-01,  1.2212e-01]]]])), (tensor([[[[-3.2176e-03, -1.3211e-02, -1.1589e-02,  ..., -1.8347e-01,\n",
            "           -2.1908e-01, -8.8671e-01],\n",
            "          [-1.0373e+00, -9.9688e-01, -9.3934e-01,  ...,  5.0647e-01,\n",
            "           -8.0908e-01, -1.6529e+00],\n",
            "          [ 6.8223e-01,  4.7508e-01,  9.9919e-01,  ...,  3.5116e-01,\n",
            "           -1.4551e+00, -9.0681e-01],\n",
            "          ...,\n",
            "          [ 1.2006e-01, -9.2326e-02, -4.0124e-01,  ..., -1.0962e+00,\n",
            "           -1.5315e+00, -2.2677e+00],\n",
            "          [ 2.6083e-01, -1.8141e-01, -1.5953e-01,  ..., -1.2064e+00,\n",
            "           -5.7967e-01, -3.1602e+00],\n",
            "          [ 9.5922e-01, -8.0832e-01, -1.4492e-01,  ..., -1.0411e+00,\n",
            "            3.1052e-01, -1.6783e+00]],\n",
            "\n",
            "         [[-1.9504e-03,  5.0844e-03, -2.5104e-03,  ...,  9.7797e-02,\n",
            "           -4.1417e-01,  5.1940e-01],\n",
            "          [ 1.0130e+00, -1.4900e+00,  1.3296e+00,  ..., -8.4648e-01,\n",
            "           -1.6455e+00, -6.2094e-01],\n",
            "          [ 1.3242e+00,  2.0855e+00,  1.0796e+00,  ...,  4.1293e-01,\n",
            "           -3.4046e+00,  5.9608e-01],\n",
            "          ...,\n",
            "          [-1.8048e-01,  8.2640e-01, -9.4502e-01,  ..., -2.2742e-01,\n",
            "           -1.6763e+00,  4.1875e+00],\n",
            "          [ 2.3255e-01,  7.4709e-01, -1.3055e-01,  ...,  2.5254e-03,\n",
            "           -2.6249e+00,  3.4236e+00],\n",
            "          [ 2.6580e-01, -3.0681e-02, -7.6514e-01,  ..., -3.7882e-01,\n",
            "            1.3341e-01, -5.9481e-01]],\n",
            "\n",
            "         [[ 6.0713e-04,  7.7492e-04,  5.7799e-03,  ...,  2.9707e-01,\n",
            "            5.5583e-01,  6.7370e-01],\n",
            "          [ 1.1921e+00,  3.6071e-01,  2.0061e+00,  ...,  5.6598e-01,\n",
            "           -2.4494e-01, -6.3486e-01],\n",
            "          [ 1.0284e+00,  2.4641e+00,  1.8033e+00,  ...,  1.4990e-01,\n",
            "            4.0875e-01,  7.9549e-01],\n",
            "          ...,\n",
            "          [-7.2447e-01,  2.0559e-01, -5.0960e-02,  ...,  2.9433e-01,\n",
            "            9.1688e-01,  2.2935e+00],\n",
            "          [-4.4588e-02,  1.1624e-01, -3.6034e-01,  ..., -3.2684e-01,\n",
            "            2.9843e-01,  1.6737e+00],\n",
            "          [ 6.7692e-01,  1.5584e-01, -6.5407e-01,  ..., -1.0051e+00,\n",
            "            1.0266e-01,  6.1835e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.9010e-03,  9.7272e-04, -7.3529e-03,  ...,  6.4156e-01,\n",
            "           -4.3203e-01, -5.7763e-03],\n",
            "          [-1.8352e-01, -2.3787e-01,  6.5031e-01,  ...,  4.3989e-01,\n",
            "            1.1141e+00,  1.0366e+00],\n",
            "          [-1.1061e+00, -6.9527e-01,  1.1318e+00,  ...,  1.6181e+00,\n",
            "            9.8817e-01,  1.0873e+00],\n",
            "          ...,\n",
            "          [-3.8298e-01,  8.6495e-02, -3.3403e-02,  ...,  5.9189e-01,\n",
            "            9.5422e-01,  2.5789e+00],\n",
            "          [-1.2682e+00,  1.7181e-01,  3.6105e-01,  ..., -2.3249e-01,\n",
            "            1.3348e+00,  6.0190e-01],\n",
            "          [ 3.9071e-01,  8.8761e-02, -1.3298e-01,  ...,  1.8084e-01,\n",
            "           -3.0909e-01,  3.5457e-01]],\n",
            "\n",
            "         [[ 2.3263e-03,  3.2308e-03,  1.3187e-02,  ...,  1.7223e-01,\n",
            "            2.7673e-02, -2.7537e-01],\n",
            "          [ 5.3371e-02,  1.3648e+00, -9.6298e-01,  ..., -3.7613e-01,\n",
            "           -8.8711e-01, -2.3931e+00],\n",
            "          [ 1.3465e+00,  1.6055e+00,  5.4472e-01,  ...,  1.4870e+00,\n",
            "            1.2952e+00, -7.7140e-01],\n",
            "          ...,\n",
            "          [ 1.0323e-01,  3.4429e-01, -2.6731e-02,  ...,  5.8742e-01,\n",
            "            1.2105e-01, -6.4895e-01],\n",
            "          [ 4.1083e-01,  2.2486e-01, -7.2350e-01,  ...,  4.3558e-01,\n",
            "            1.2453e+00, -5.2696e-01],\n",
            "          [ 3.1109e-01,  4.1342e-02,  6.6089e-01,  ...,  2.2739e-01,\n",
            "           -1.2985e-01, -3.8485e-01]],\n",
            "\n",
            "         [[-5.6291e-03,  5.1902e-03, -4.3866e-03,  ...,  3.2944e-01,\n",
            "           -8.1732e-01,  3.6896e-01],\n",
            "          [ 2.5970e-01, -5.1191e-01,  5.4261e-01,  ..., -2.2910e-01,\n",
            "           -2.1741e+00, -6.9295e-01],\n",
            "          [ 9.9011e-01, -2.1220e-01,  6.0528e-01,  ..., -8.2798e-01,\n",
            "           -2.8311e+00, -2.2904e-03],\n",
            "          ...,\n",
            "          [-3.9633e-01, -1.3544e+00, -3.1493e-01,  ...,  5.1946e-01,\n",
            "           -3.4872e-01,  2.9335e-01],\n",
            "          [-1.1673e+00, -1.3019e+00,  6.0060e-02,  ...,  1.2268e+00,\n",
            "            3.4140e-01,  1.6554e-01],\n",
            "          [ 6.2964e-01,  3.6397e-01, -2.2931e-01,  ...,  1.2800e+00,\n",
            "           -1.9417e+00,  1.8733e-01]]]]), tensor([[[[ 4.9380e-03, -3.9705e-01, -6.4560e-03,  ..., -1.4960e-02,\n",
            "            3.7967e-02, -6.0249e-02],\n",
            "          [ 3.1791e+00, -2.3160e+00, -1.8686e+00,  ...,  2.5492e+00,\n",
            "           -3.3924e-01,  1.0798e+00],\n",
            "          [ 9.1915e-01, -6.3613e-01,  1.9189e-01,  ..., -3.0870e-01,\n",
            "           -8.7698e-01,  6.1120e-01],\n",
            "          ...,\n",
            "          [ 6.6814e-01,  1.3584e+00,  2.5819e-01,  ..., -5.9019e-01,\n",
            "            5.5973e-01,  1.7750e-01],\n",
            "          [ 1.0365e+00,  1.5019e+00,  9.3751e-01,  ..., -4.0053e-01,\n",
            "            6.9012e-01,  9.6703e-02],\n",
            "          [ 5.4506e-01, -5.6160e-01,  5.3896e-01,  ..., -1.0282e-01,\n",
            "            5.8274e-01, -6.1197e-01]],\n",
            "\n",
            "         [[ 2.6602e-02,  3.9595e-03,  2.4028e-02,  ...,  1.3493e-02,\n",
            "            5.8044e-02,  2.7309e-02],\n",
            "          [-4.5691e-01,  9.1123e-01, -6.4978e-01,  ...,  6.0620e-02,\n",
            "            1.0184e+00,  1.5004e-02],\n",
            "          [-7.3043e-01,  6.2342e-01, -9.6285e-01,  ...,  2.7232e-03,\n",
            "           -3.6746e-01, -4.5143e-01],\n",
            "          ...,\n",
            "          [ 1.1497e+00,  4.4480e-01, -5.0954e-01,  ...,  7.1156e-03,\n",
            "           -1.4849e-01, -7.3214e-01],\n",
            "          [-7.3872e-02, -5.9924e-02,  3.0142e-01,  ...,  2.2476e-01,\n",
            "           -1.2974e-01, -3.9181e-01],\n",
            "          [-2.6170e-01,  2.4923e-01,  4.3183e-01,  ..., -4.2502e-01,\n",
            "           -3.0764e-01,  1.0646e-01]],\n",
            "\n",
            "         [[-8.3089e-03, -5.3804e-02, -7.3846e-03,  ..., -1.0525e-04,\n",
            "           -3.4001e-02,  1.1880e-03],\n",
            "          [ 7.8795e-01,  1.3814e-01, -4.1389e-01,  ...,  1.8691e-01,\n",
            "            1.6254e-01, -3.1623e-01],\n",
            "          [-9.0412e-01, -1.7357e-01, -3.1230e-01,  ...,  6.1080e-01,\n",
            "            6.6071e-01,  1.0036e+00],\n",
            "          ...,\n",
            "          [-6.6281e-01, -3.8273e-01,  4.8962e-01,  ..., -4.3127e-01,\n",
            "           -1.3126e-01,  9.7185e-01],\n",
            "          [ 2.5921e-03, -8.1362e-01,  9.0559e-01,  ..., -8.0808e-01,\n",
            "           -8.5519e-02,  1.3631e+00],\n",
            "          [ 6.1347e-02,  7.2451e-01, -7.9914e-01,  ..., -7.5478e-01,\n",
            "            1.5140e-01, -2.4866e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.4541e-03, -1.3198e-02, -3.9135e-03,  ..., -9.3553e-03,\n",
            "           -9.7122e-03,  2.4923e-02],\n",
            "          [ 1.1484e+00,  1.8359e-01, -1.0498e+00,  ...,  8.3394e-01,\n",
            "           -1.1601e-01,  3.4219e-01],\n",
            "          [ 3.8607e-01, -1.3243e+00, -6.8673e-01,  ...,  1.5639e-01,\n",
            "            6.1940e-01,  7.1461e-01],\n",
            "          ...,\n",
            "          [-6.6664e-01, -6.7023e-01, -9.5708e-02,  ...,  2.8478e-01,\n",
            "            1.9623e-01, -5.4198e-01],\n",
            "          [ 2.2905e+00, -2.5143e-01,  2.5802e-01,  ..., -1.3984e+00,\n",
            "           -3.3704e-01, -2.2330e-01],\n",
            "          [-4.2441e-01, -2.7935e-02,  2.7082e-01,  ...,  3.0619e-01,\n",
            "            2.6035e-01,  2.9002e-01]],\n",
            "\n",
            "         [[ 9.0255e-01, -3.1007e-02,  1.0185e-03,  ...,  2.5525e-03,\n",
            "           -9.5336e-02, -7.7508e-03],\n",
            "          [ 2.7547e+00, -1.5324e-01,  5.8823e-01,  ..., -4.7423e-01,\n",
            "            4.3695e-01,  5.1293e-01],\n",
            "          [ 2.7583e+00,  6.0827e-01,  2.7388e-01,  ..., -6.6581e-02,\n",
            "            9.4876e-03, -5.4700e-01],\n",
            "          ...,\n",
            "          [ 3.4165e+00,  5.6586e-01,  5.7906e-01,  ...,  4.1499e-01,\n",
            "            1.0576e-01,  4.6387e-01],\n",
            "          [ 2.3177e+00,  8.1334e-01,  1.6891e-01,  ...,  8.3209e-01,\n",
            "            3.4996e-01,  9.9281e-01],\n",
            "          [ 1.7635e+00,  9.9079e-01, -5.1936e-01,  ...,  1.9493e-01,\n",
            "            1.5287e-01,  1.0219e+00]],\n",
            "\n",
            "         [[-4.1251e-02, -3.8067e-02, -2.4486e-02,  ..., -6.1342e-02,\n",
            "           -3.4945e-02,  3.0181e-02],\n",
            "          [ 1.1805e+00,  5.6337e-01,  7.7704e-01,  ...,  9.3522e-01,\n",
            "           -5.4361e-01, -9.3866e-01],\n",
            "          [ 2.2418e-01,  5.8128e-01,  1.5210e+00,  ...,  2.4061e+00,\n",
            "            2.2694e+00, -1.5824e+00],\n",
            "          ...,\n",
            "          [ 3.2822e-01, -5.4402e-01,  1.7855e+00,  ...,  4.5680e-01,\n",
            "           -1.8880e+00,  2.3219e-01],\n",
            "          [ 9.9001e-01,  2.3956e+00,  6.0255e-01,  ..., -1.3658e+00,\n",
            "           -4.8958e-01,  8.7119e-02],\n",
            "          [-6.3110e-01,  1.2312e+00,  1.6068e+00,  ...,  8.5783e-01,\n",
            "            8.8358e-01, -6.6930e-01]]]])), (tensor([[[[-9.1059e-03, -1.8932e-02, -2.4141e-02,  ..., -3.5236e-01,\n",
            "            6.9341e-01,  6.8604e-01],\n",
            "          [-1.2992e-02, -2.0155e-02,  3.5162e-02,  ..., -4.1599e-01,\n",
            "            7.2249e-01,  7.1425e-01],\n",
            "          [ 2.6881e+00,  1.9101e+00, -3.9720e+00,  ..., -1.4458e+00,\n",
            "            1.4635e+00,  2.8167e-01],\n",
            "          ...,\n",
            "          [ 2.1603e+00,  2.0328e+00, -2.4537e+00,  ..., -4.8243e-01,\n",
            "            1.5572e-01,  1.0365e+00],\n",
            "          [-2.0270e-01,  1.9756e-01, -1.9241e+00,  ..., -5.5366e-01,\n",
            "            1.0780e+00,  1.0863e-01],\n",
            "          [-1.1356e+00, -7.4188e-01, -1.0448e+00,  ..., -3.6316e-01,\n",
            "            1.7744e+00,  5.8474e-01]],\n",
            "\n",
            "         [[-1.4394e-02, -7.2709e-02,  1.3880e-02,  ...,  6.2517e-01,\n",
            "           -1.7507e-01, -6.8321e-01],\n",
            "          [ 5.2418e-03,  2.6108e-02, -9.2440e-03,  ...,  5.8767e-01,\n",
            "           -2.6692e-01, -5.8787e-01],\n",
            "          [-2.1245e+00, -2.7411e+00,  1.7098e+00,  ...,  7.6696e-01,\n",
            "            1.5514e+00, -2.0164e+00],\n",
            "          ...,\n",
            "          [-5.5188e-01,  3.6500e+00,  2.4184e+00,  ..., -3.4357e-01,\n",
            "            1.0396e-01, -2.5239e-01],\n",
            "          [ 1.6354e+00,  2.5697e+00,  1.5814e+00,  ...,  5.6336e-01,\n",
            "           -2.0374e+00, -7.2812e-02],\n",
            "          [ 2.4170e-01,  1.8929e+00,  2.0671e+00,  ...,  1.8125e+00,\n",
            "            2.4938e-01,  5.8814e-01]],\n",
            "\n",
            "         [[-4.2247e-02, -1.0083e-01,  2.4164e-01,  ...,  1.1220e+00,\n",
            "            3.2172e-01,  9.1352e-01],\n",
            "          [ 2.0817e-04,  5.2804e-03, -3.6097e-02,  ...,  8.4839e-01,\n",
            "            6.8497e-01,  4.1992e-01],\n",
            "          [-9.6835e-01, -1.9560e+00,  1.9610e+00,  ...,  4.0122e-01,\n",
            "           -2.5723e-01,  2.3184e+00],\n",
            "          ...,\n",
            "          [ 5.2797e-01, -6.8796e-01,  2.8114e+00,  ...,  3.7563e-01,\n",
            "            1.1007e+00, -4.2977e-01],\n",
            "          [ 1.0495e+00, -1.4426e+00,  2.5629e+00,  ...,  5.9397e-01,\n",
            "            1.0676e+00, -1.5642e+00],\n",
            "          [ 7.2410e-01,  2.9364e-02,  8.1907e-01,  ...,  9.4043e-01,\n",
            "           -6.9239e-02, -9.3667e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.8774e-02, -1.8513e-01, -4.5401e-01,  ..., -5.9480e-01,\n",
            "            3.0233e-01,  4.9886e-01],\n",
            "          [ 2.1813e-02,  3.4846e-02,  6.5396e-02,  ..., -5.8461e-01,\n",
            "           -2.3759e-01,  1.5633e-01],\n",
            "          [-1.1832e+00, -1.2565e+00, -2.4345e+00,  ..., -2.4589e+00,\n",
            "            9.8895e-02,  2.4312e+00],\n",
            "          ...,\n",
            "          [-6.0261e-01,  9.9405e-01, -1.9984e+00,  ..., -1.9754e+00,\n",
            "           -4.1923e-01, -1.0566e-01],\n",
            "          [ 1.1148e-01, -2.7384e-01, -1.1737e+00,  ..., -2.0007e+00,\n",
            "            7.3669e-01,  8.0412e-01],\n",
            "          [ 3.3639e-01, -6.2083e-02, -4.8597e-01,  ..., -1.6915e+00,\n",
            "           -1.3200e-01,  7.0743e-01]],\n",
            "\n",
            "         [[-3.5486e-04,  1.9558e-01, -4.2044e-01,  ..., -5.4455e-01,\n",
            "           -3.5907e-02,  7.1557e-01],\n",
            "          [ 1.2740e-02, -6.8704e-03,  3.4835e-02,  ..., -1.3142e-01,\n",
            "            4.6042e-01, -7.2790e-01],\n",
            "          [-8.4033e-01, -9.4913e-01,  1.3724e+00,  ..., -1.0757e+00,\n",
            "            1.0769e+00, -3.2567e-01],\n",
            "          ...,\n",
            "          [-4.6391e-01,  3.2608e-01,  6.6241e-02,  ...,  6.7995e-01,\n",
            "           -2.0670e-02,  4.5749e-02],\n",
            "          [ 1.2278e+00, -6.5058e-01, -1.3261e+00,  ..., -6.9324e-01,\n",
            "            8.1243e-02, -1.8423e+00],\n",
            "          [-3.2095e-01,  7.9192e-02,  3.3884e-01,  ...,  1.8427e-01,\n",
            "           -2.5546e-03, -2.4050e-01]],\n",
            "\n",
            "         [[ 5.7702e-02, -3.8263e-02,  6.9600e-02,  ..., -2.5703e-01,\n",
            "           -1.4532e-01,  1.4383e+01],\n",
            "          [-2.1641e-03,  1.7181e-04, -3.7033e-02,  ..., -3.7392e-01,\n",
            "            1.2613e-01,  1.4811e+01],\n",
            "          [ 2.7019e+00,  8.3705e-01, -5.6149e-01,  ..., -5.6309e-01,\n",
            "           -1.9716e+00,  7.9810e+00],\n",
            "          ...,\n",
            "          [ 1.9849e-01, -1.3465e+00,  1.7695e+00,  ...,  1.0113e+00,\n",
            "           -9.2729e-02,  8.5952e+00],\n",
            "          [ 5.6140e-01, -4.2939e-02, -1.3249e-01,  ...,  1.5359e-01,\n",
            "            4.3650e-01,  9.7068e+00],\n",
            "          [-7.0135e-02,  6.9648e-02,  8.8922e-01,  ...,  4.8412e-01,\n",
            "           -9.3719e-01,  8.6502e+00]]]]), tensor([[[[-1.6450e-01, -3.3644e-02,  1.0206e-01,  ..., -7.2968e-01,\n",
            "           -4.0400e-02, -3.2855e-02],\n",
            "          [-1.3872e-03,  4.6995e-03, -1.9887e-02,  ...,  1.8935e-01,\n",
            "           -3.9655e-02, -2.4740e-02],\n",
            "          [-1.0428e+00, -9.3917e-02,  5.2073e-01,  ...,  5.8856e-01,\n",
            "            8.4148e-01,  3.6486e-02],\n",
            "          ...,\n",
            "          [-6.1960e-01,  1.5467e-01, -1.1217e+00,  ...,  3.2970e-01,\n",
            "           -1.2521e+00,  5.4703e-01],\n",
            "          [-2.9607e-01, -5.6654e-01, -1.3882e-01,  ..., -1.1371e+00,\n",
            "           -3.3896e-01,  7.3162e-01],\n",
            "          [ 7.9155e-01, -2.2969e-01,  1.0606e+00,  ..., -1.3751e+00,\n",
            "            1.6873e-01, -6.3112e-02]],\n",
            "\n",
            "         [[ 1.6017e-03,  8.2670e-02,  1.9168e-02,  ...,  3.6711e-02,\n",
            "            9.9718e-02, -8.3136e-03],\n",
            "          [ 1.1404e-02,  2.0010e-02,  6.9730e-03,  ...,  3.3261e-02,\n",
            "            1.2692e-01,  2.8794e-02],\n",
            "          [-1.8979e-01, -2.8631e-01, -5.5333e-02,  ...,  8.6670e-01,\n",
            "            5.8140e-01,  9.0404e-01],\n",
            "          ...,\n",
            "          [ 4.1813e-01,  1.1198e-01, -9.9061e-01,  ..., -2.8059e-01,\n",
            "            4.5686e-01, -2.7850e-02],\n",
            "          [-8.0684e-02, -1.8071e-01, -1.2601e-01,  ...,  2.4265e-01,\n",
            "            7.2466e-01,  7.4637e-01],\n",
            "          [-2.2628e-02, -1.4605e-01,  3.9683e-01,  ..., -3.3506e-01,\n",
            "           -9.6086e-01,  7.6355e-01]],\n",
            "\n",
            "         [[-1.3242e-01,  1.4265e-01, -1.5680e-01,  ...,  1.0098e-02,\n",
            "            7.4089e-02,  3.4016e-02],\n",
            "          [-3.8634e-02,  1.0232e-02,  4.4043e-04,  ...,  3.4625e-02,\n",
            "           -5.3474e-02, -6.2380e-02],\n",
            "          [ 1.5869e-01, -2.5373e-01,  6.0350e-01,  ...,  4.1369e-03,\n",
            "            2.4002e-02, -9.1370e-03],\n",
            "          ...,\n",
            "          [-1.3480e-01, -6.2417e-01, -3.4914e-01,  ...,  2.7109e-01,\n",
            "           -8.4065e-01, -1.4473e+00],\n",
            "          [ 9.3711e-02, -9.1545e-02, -7.6413e-01,  ...,  4.5081e-01,\n",
            "           -5.2676e-01, -1.7337e-01],\n",
            "          [ 3.1957e-01,  2.8917e-01, -2.8287e-01,  ...,  3.1892e-01,\n",
            "            5.6343e-01, -4.9801e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.5656e-02,  1.7250e-01,  1.1120e-02,  ...,  5.1830e-02,\n",
            "           -6.2041e-02, -1.5846e-02],\n",
            "          [ 5.4342e-02,  2.7153e-02,  8.5705e-03,  ...,  2.4273e-02,\n",
            "           -3.0197e-02, -2.2265e-01],\n",
            "          [-8.6484e-01, -6.9256e-01,  2.7324e-01,  ..., -5.9657e-01,\n",
            "            6.5233e-01,  1.3419e-01],\n",
            "          ...,\n",
            "          [-9.6472e-01,  3.6439e-01, -2.6675e-03,  ..., -1.5726e+00,\n",
            "            9.4496e-01,  4.0703e-01],\n",
            "          [-7.9404e-01,  1.0575e-01,  6.5272e-01,  ..., -1.7592e+00,\n",
            "            6.0085e-02,  1.3605e+00],\n",
            "          [-5.1131e-01, -1.7726e-01, -1.4217e-01,  ...,  2.6697e-03,\n",
            "            7.8683e-01,  3.2666e-01]],\n",
            "\n",
            "         [[-1.1493e-02, -1.6992e-01, -1.0227e-01,  ..., -2.3617e-02,\n",
            "           -1.4941e-01,  2.6275e-01],\n",
            "          [-5.4820e-02,  6.3658e-03,  1.4602e-02,  ..., -1.9343e-02,\n",
            "            3.2376e-02, -1.9064e-02],\n",
            "          [-4.1133e-02, -4.8783e-02, -8.0235e-02,  ..., -4.6350e-01,\n",
            "           -5.9605e-01,  2.6696e-01],\n",
            "          ...,\n",
            "          [ 3.5228e-01, -8.9881e-02,  2.3778e-01,  ...,  1.5899e+00,\n",
            "            6.1095e-01, -9.4892e-01],\n",
            "          [ 1.6584e-01, -2.0732e+00, -6.6351e-01,  ..., -2.5965e-02,\n",
            "           -9.7782e-01, -9.5160e-02],\n",
            "          [ 3.8615e-03, -2.2195e+00, -2.1694e-01,  ..., -5.5389e-01,\n",
            "           -1.8167e+00,  1.5846e+00]],\n",
            "\n",
            "         [[ 8.1706e-02, -3.0307e-03,  1.1188e-01,  ...,  1.1595e-01,\n",
            "            1.7664e-01,  1.9085e-02],\n",
            "          [-1.1293e-03,  1.0117e-01,  2.6234e-03,  ...,  2.0797e-02,\n",
            "           -6.8570e-02, -5.6999e-02],\n",
            "          [ 4.4910e-01, -6.3908e-01, -6.8657e-01,  ...,  2.4975e-01,\n",
            "            9.5888e-01, -1.3310e-01],\n",
            "          ...,\n",
            "          [-9.1857e-02, -6.8803e-01, -1.6760e+00,  ...,  1.7656e+00,\n",
            "           -1.3125e+00, -1.2126e-01],\n",
            "          [-8.5669e-01, -1.3015e-01, -8.4563e-01,  ...,  1.9874e+00,\n",
            "           -1.1442e+00,  5.0761e-01],\n",
            "          [ 1.4383e+00, -8.5377e-01,  3.6474e-01,  ...,  2.4319e-01,\n",
            "            6.1869e-01, -4.9844e-01]]]])), (tensor([[[[-5.5663e-02, -3.9977e-01,  8.4190e-01,  ...,  4.9467e-01,\n",
            "            8.2579e-01,  1.6587e-01],\n",
            "          [-8.8219e-03,  2.1689e-03, -2.1487e-02,  ...,  1.7335e-01,\n",
            "            1.0091e+00,  2.1475e-01],\n",
            "          [-5.1153e-02, -7.5751e-01,  1.8525e+00,  ..., -5.3435e-01,\n",
            "            1.4041e+00,  1.5008e+00],\n",
            "          ...,\n",
            "          [-3.2792e-01,  4.2945e-01,  2.1483e+00,  ..., -1.4588e-01,\n",
            "            1.0049e+00,  1.1946e+00],\n",
            "          [ 6.1414e-01,  4.2771e-01,  1.7723e+00,  ...,  1.3587e-01,\n",
            "            1.3487e+00,  1.3167e+00],\n",
            "          [ 3.0292e-01,  1.7176e-01,  2.4938e-01,  ..., -5.6373e-01,\n",
            "            2.6430e-01, -4.5046e-01]],\n",
            "\n",
            "         [[ 3.7097e-02, -1.3441e-01, -1.4374e-01,  ...,  3.4421e-01,\n",
            "           -1.8648e+00, -1.4056e-01],\n",
            "          [ 6.4657e-03, -3.0553e-03, -3.1876e-03,  ...,  9.0631e-02,\n",
            "           -5.1302e-01, -2.6765e-01],\n",
            "          [-1.0476e+00, -5.0327e-01, -1.6855e+00,  ...,  3.4015e-01,\n",
            "           -8.4631e-01,  1.1294e+00],\n",
            "          ...,\n",
            "          [ 2.5484e-01,  1.9499e+00, -1.5967e+00,  ...,  7.9476e-01,\n",
            "           -7.3555e-01, -4.1995e-01],\n",
            "          [ 8.5940e-01,  1.6403e+00, -4.6703e-01,  ...,  7.0155e-01,\n",
            "           -5.9907e-01, -2.8007e-01],\n",
            "          [-1.4539e-01, -1.5180e-01, -8.2831e-01,  ...,  8.8615e-02,\n",
            "           -1.5177e+00, -2.4500e-01]],\n",
            "\n",
            "         [[ 1.7707e-01, -3.8569e-01, -5.4322e-01,  ...,  6.4134e-01,\n",
            "            9.4213e+00,  4.6461e-02],\n",
            "          [ 9.3087e-03, -1.5570e-02,  1.8370e-02,  ...,  2.5707e-01,\n",
            "            1.1714e+01,  1.4209e-01],\n",
            "          [ 3.6791e-02, -1.5048e+00, -2.4263e+00,  ...,  5.2369e-02,\n",
            "            5.0857e+00,  1.0700e+00],\n",
            "          ...,\n",
            "          [ 1.9923e-01,  1.4875e+00, -1.7257e+00,  ...,  1.0743e+00,\n",
            "            7.0778e+00,  1.9832e+00],\n",
            "          [-1.1395e-01,  3.4872e-01, -1.0985e+00,  ...,  6.8498e-01,\n",
            "            8.7894e+00,  1.1144e+00],\n",
            "          [ 1.2935e-01,  9.7607e-01, -1.3190e+00,  ...,  2.3435e-01,\n",
            "            5.8542e+00,  5.7293e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.3582e-01, -8.5531e-01,  1.4129e+00,  ..., -1.9806e-01,\n",
            "            5.1030e-01, -4.8182e-01],\n",
            "          [ 4.0784e-03,  9.9886e-03, -8.3697e-03,  ...,  2.8772e-02,\n",
            "            5.5035e-02, -3.4222e-01],\n",
            "          [-1.5417e+00, -2.4018e+00,  3.9374e+00,  ..., -7.8335e-01,\n",
            "            7.5591e-01, -9.8265e-01],\n",
            "          ...,\n",
            "          [-7.5997e-01,  4.1468e+00,  2.9000e+00,  ...,  1.2295e+00,\n",
            "            6.6369e-01, -1.1872e+00],\n",
            "          [ 1.7934e+00,  3.1838e+00,  1.8338e+00,  ..., -4.8759e-02,\n",
            "            1.5999e-01, -1.2637e+00],\n",
            "          [ 1.2934e+00,  2.6102e+00,  1.7885e+00,  ..., -1.9763e-01,\n",
            "            1.3159e+00, -1.3416e-01]],\n",
            "\n",
            "         [[-3.4022e-01,  6.8387e-01,  2.0866e+00,  ..., -7.0176e-02,\n",
            "           -2.3505e-01,  2.9907e-01],\n",
            "          [ 3.5490e-04, -1.0197e-02, -2.2963e-02,  ..., -5.3660e-02,\n",
            "           -2.1079e-01, -1.7153e-01],\n",
            "          [ 3.9498e-02,  2.1595e+00,  4.0570e+00,  ...,  3.8067e-01,\n",
            "            2.5263e-01,  6.8661e-01],\n",
            "          ...,\n",
            "          [ 9.1178e-01, -1.2580e+00,  3.4131e+00,  ..., -2.6827e-02,\n",
            "            6.9836e-01,  1.2642e+00],\n",
            "          [ 1.0234e+00, -1.5792e+00,  3.3567e+00,  ...,  6.7849e-01,\n",
            "            2.5468e-01,  4.5082e-01],\n",
            "          [ 3.9799e-01, -1.0797e+00,  3.9690e+00,  ...,  1.3903e-01,\n",
            "            2.7972e-01,  1.1844e-01]],\n",
            "\n",
            "         [[ 1.0309e-01, -1.1822e-01,  7.7952e-02,  ..., -1.1489e-01,\n",
            "            1.4919e+00,  4.7634e-01],\n",
            "          [-7.3065e-03,  1.9177e-02,  1.3529e-02,  ...,  2.7674e-01,\n",
            "            1.2278e+00, -1.3841e-01],\n",
            "          [ 1.7442e+00, -1.7299e-01,  1.9410e+00,  ..., -1.8675e-01,\n",
            "            9.2968e-01, -7.2482e-01],\n",
            "          ...,\n",
            "          [ 9.4472e-01, -1.4914e+00, -9.2451e-02,  ...,  1.6577e+00,\n",
            "            2.2233e+00,  3.5140e-01],\n",
            "          [-1.0465e+00,  9.4941e-02,  2.7404e-01,  ..., -4.7528e-01,\n",
            "            1.7346e+00, -1.8828e-02],\n",
            "          [-3.7713e-01,  3.6874e-01, -2.7063e-01,  ...,  1.7082e+00,\n",
            "            1.7997e-01,  9.6726e-01]]]]), tensor([[[[ 1.3392e-01,  9.4121e-02,  9.1790e-02,  ..., -5.4490e-01,\n",
            "            1.8953e-02, -1.3767e-01],\n",
            "          [-9.3358e-02, -9.1870e-02,  7.8893e-02,  ...,  5.9536e-02,\n",
            "           -1.7260e-02, -7.1643e-02],\n",
            "          [-2.2625e-01,  7.4706e-01,  5.6677e-01,  ...,  2.7511e-01,\n",
            "           -1.5733e+00, -3.2345e-01],\n",
            "          ...,\n",
            "          [ 7.5609e-01,  6.9621e-01, -1.1969e+00,  ...,  3.1933e-01,\n",
            "           -3.2049e-01, -2.5436e-02],\n",
            "          [ 1.9905e+00,  3.7719e-01, -1.2582e+00,  ..., -7.8961e-01,\n",
            "            1.6384e-01,  7.6585e-01],\n",
            "          [-1.1527e-01, -1.4560e-01,  5.0198e-01,  ...,  6.6668e-01,\n",
            "           -4.7051e-01,  3.8651e-01]],\n",
            "\n",
            "         [[-1.6679e+00,  3.5039e+00, -2.7682e+00,  ...,  1.7782e+00,\n",
            "           -2.8523e+00, -5.6260e-01],\n",
            "          [ 8.1518e-02, -2.0221e-01,  1.7498e-01,  ..., -7.8192e-02,\n",
            "            1.2068e-01,  7.3225e-01],\n",
            "          [ 2.3613e-01, -1.9162e-01, -1.9649e-01,  ...,  5.2532e-01,\n",
            "           -1.1797e+00, -4.7329e-01],\n",
            "          ...,\n",
            "          [ 3.7894e-01, -6.0655e-01, -7.5375e-01,  ..., -2.9026e-01,\n",
            "           -2.4714e-01, -1.2931e-01],\n",
            "          [-1.7840e-01,  3.0858e-01, -8.8821e-03,  ..., -9.9493e-02,\n",
            "            6.5633e-01,  2.4774e-01],\n",
            "          [-7.1632e-01, -1.3417e-01,  3.7047e-02,  ..., -1.0816e-01,\n",
            "           -4.9895e-01, -9.7679e-01]],\n",
            "\n",
            "         [[-2.2639e-01,  1.8917e-01,  1.4281e-01,  ..., -5.5104e-02,\n",
            "            1.8882e-01,  4.8529e-02],\n",
            "          [ 3.9739e-03,  1.8364e-02, -1.2257e-03,  ...,  2.1492e-02,\n",
            "           -3.6262e-03,  7.1122e-02],\n",
            "          [ 5.5951e-02, -4.3850e-01, -7.8950e-01,  ..., -8.5352e-01,\n",
            "            9.8399e-01,  9.3279e-01],\n",
            "          ...,\n",
            "          [-1.8022e+00,  8.3000e-01, -4.0010e-03,  ...,  1.4759e+00,\n",
            "           -3.0133e-01,  1.8164e+00],\n",
            "          [-6.0133e-01,  1.9994e+00,  7.7506e-01,  ...,  2.3901e-02,\n",
            "           -4.2369e-01,  1.9808e+00],\n",
            "          [-7.3338e-01,  5.7118e-01,  5.9863e-01,  ..., -2.0779e-01,\n",
            "           -7.8480e-01,  9.1014e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.7012e-02,  5.3032e-01, -1.0164e-01,  ...,  5.6034e-02,\n",
            "           -1.0334e-01,  1.1677e-01],\n",
            "          [ 3.4572e-02,  5.3033e-02,  3.9032e-02,  ..., -1.6515e-01,\n",
            "           -7.2160e-02,  2.1054e-02],\n",
            "          [ 1.4611e+00, -6.1750e-01, -7.7605e-02,  ..., -3.3951e-02,\n",
            "            5.6627e-01,  1.7729e-01],\n",
            "          ...,\n",
            "          [-1.2541e+00,  5.5309e-01, -7.9852e-01,  ...,  7.7322e-01,\n",
            "           -1.3011e+00, -5.5262e-01],\n",
            "          [-4.7727e-01,  6.2301e-01,  6.4962e-01,  ...,  9.0209e-01,\n",
            "           -8.0919e-01,  7.9668e-01],\n",
            "          [ 9.1895e-01,  6.5613e-01,  7.0893e-01,  ...,  7.1816e-01,\n",
            "           -6.1972e-01, -8.8801e-01]],\n",
            "\n",
            "         [[-7.4374e-01,  2.9631e-01, -2.0541e-01,  ...,  2.8724e-01,\n",
            "            3.1332e-01,  2.7070e-01],\n",
            "          [ 4.5728e-02,  4.8710e-02,  2.5241e-02,  ..., -1.3150e-02,\n",
            "            1.9911e-03, -2.7088e-02],\n",
            "          [ 1.1304e-01,  2.2502e-01,  3.0991e-01,  ..., -5.4548e-01,\n",
            "            1.0371e+00,  7.8084e-01],\n",
            "          ...,\n",
            "          [ 1.1287e-02, -8.2456e-01, -5.2833e-01,  ..., -4.0035e-02,\n",
            "            4.2793e-01, -3.5500e-02],\n",
            "          [ 2.6112e-01, -1.2536e+00, -3.6196e-01,  ..., -4.7019e-01,\n",
            "           -9.2432e-01,  1.1412e+00],\n",
            "          [-7.3246e-01,  1.6444e-01, -8.0368e-01,  ..., -3.7653e-01,\n",
            "           -2.5907e-01, -7.6957e-01]],\n",
            "\n",
            "         [[-3.7894e-02, -1.0091e-01, -3.4375e-02,  ..., -8.4678e-02,\n",
            "            2.9745e-02,  2.4395e-01],\n",
            "          [ 7.2854e-03,  6.0865e-02, -7.0053e-02,  ...,  1.8174e-02,\n",
            "            4.5700e-02,  4.5694e-03],\n",
            "          [-6.3236e-01, -9.5640e-01, -2.2450e-01,  ...,  6.6438e-01,\n",
            "            2.2612e-01,  3.7566e-02],\n",
            "          ...,\n",
            "          [-1.1427e+00, -2.2254e-01,  2.6123e-02,  ...,  6.5881e-01,\n",
            "           -1.3925e-01,  4.6825e-02],\n",
            "          [-9.7821e-01, -1.0645e-01,  3.5538e-01,  ...,  7.3080e-01,\n",
            "            4.1056e-01,  1.4201e+00],\n",
            "          [-7.5687e-01, -6.3511e-02, -3.1669e-01,  ...,  2.9082e-01,\n",
            "            2.9686e-01,  3.6960e-02]]]])), (tensor([[[[ 4.1796e-03,  2.8584e-01,  5.4751e-02,  ..., -4.2967e-01,\n",
            "           -6.6344e-01,  3.6940e-02],\n",
            "          [-8.3992e-03,  8.9365e-04,  3.4867e-04,  ..., -9.5954e-02,\n",
            "           -1.7629e-01,  4.7622e-01],\n",
            "          [-3.9934e-01, -7.6318e-01, -2.9817e-01,  ...,  1.3635e+00,\n",
            "           -4.4126e-01,  1.3726e+00],\n",
            "          ...,\n",
            "          [-4.3427e-01, -1.5503e-01,  3.9941e-01,  ..., -1.1609e-01,\n",
            "           -2.0211e+00,  9.1819e-01],\n",
            "          [ 2.6146e-01,  5.1400e-02,  8.1344e-01,  ...,  6.4318e-01,\n",
            "           -3.6632e-01,  7.0216e-01],\n",
            "          [ 6.1820e-01, -1.2793e-01,  9.3808e-01,  ..., -2.5155e-01,\n",
            "           -3.3281e-01,  3.0605e-01]],\n",
            "\n",
            "         [[-2.7024e-01, -6.0354e-02, -7.2557e-01,  ..., -3.5327e-01,\n",
            "            4.4008e-02, -1.3698e+00],\n",
            "          [-1.3751e-02, -1.1720e-02,  1.0436e-02,  ...,  2.2333e-01,\n",
            "            2.2388e-01, -2.8226e-01],\n",
            "          [ 8.2164e-01,  6.7168e-01, -5.7623e-01,  ..., -8.1414e-01,\n",
            "           -1.1068e+00, -6.6018e-01],\n",
            "          ...,\n",
            "          [ 6.6349e-01, -4.8772e-01, -1.3804e+00,  ..., -1.2071e+00,\n",
            "           -1.3686e+00, -7.0966e-01],\n",
            "          [-3.0579e-01, -2.0236e+00, -2.7022e+00,  ..., -3.4277e-01,\n",
            "            9.4070e-01,  1.4699e+00],\n",
            "          [-2.4958e-01, -2.0556e-01, -6.8766e-01,  ..., -6.2332e-01,\n",
            "            3.6972e-01, -9.6701e-01]],\n",
            "\n",
            "         [[ 2.0074e-01,  2.4044e-02,  8.0902e-01,  ...,  4.0627e-01,\n",
            "            2.2227e-01,  9.4721e-01],\n",
            "          [ 1.3631e-02, -4.9082e-03, -1.2216e-02,  ..., -4.7260e-02,\n",
            "            3.0525e-01,  1.3490e-02],\n",
            "          [-7.4424e-01, -3.6899e+00,  1.5189e+00,  ...,  1.5248e+00,\n",
            "            2.9095e-01,  6.4583e-01],\n",
            "          ...,\n",
            "          [-9.9363e-01, -1.1564e-01, -9.9890e-02,  ..., -7.2196e-01,\n",
            "            1.4233e+00,  5.1007e-01],\n",
            "          [-6.0429e-01,  2.0920e-01, -3.5127e-01,  ...,  6.4641e-01,\n",
            "            1.0289e-01, -5.4231e-01],\n",
            "          [ 1.6655e-01,  5.1262e-01, -7.4732e-01,  ..., -1.3745e+00,\n",
            "            2.2552e+00, -6.8709e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.9552e-02, -2.0437e-01, -2.4440e-01,  ..., -3.4282e-01,\n",
            "           -1.8046e+00,  1.8035e-01],\n",
            "          [ 1.1127e-02, -9.9145e-03,  9.4021e-03,  ..., -5.1574e-01,\n",
            "           -6.8783e-01, -2.1414e-01],\n",
            "          [-2.1941e-01, -6.0548e-01,  4.9277e-01,  ...,  1.0079e+00,\n",
            "           -1.7257e+00, -2.8473e-01],\n",
            "          ...,\n",
            "          [-3.0213e-01, -5.2118e-01,  3.3645e-01,  ..., -7.2906e-01,\n",
            "            3.6121e-02, -9.5086e-01],\n",
            "          [-3.6735e-01, -7.1910e-02, -1.6067e-01,  ...,  1.6383e-01,\n",
            "           -1.5326e+00,  1.3042e-01],\n",
            "          [ 3.7466e-01, -4.6082e-02,  2.6392e-01,  ...,  3.0527e-01,\n",
            "           -2.0933e+00, -1.6322e+00]],\n",
            "\n",
            "         [[-3.4994e-01, -4.4484e-02,  1.6238e-01,  ..., -5.0242e-01,\n",
            "           -7.8888e-01, -2.7486e-01],\n",
            "          [-2.4091e-03, -8.6828e-03,  6.8719e-03,  ..., -2.1090e-01,\n",
            "           -1.4788e-01, -4.2155e-01],\n",
            "          [ 7.6258e-01,  2.2678e+00,  2.1502e+00,  ..., -1.4696e+00,\n",
            "           -1.3031e-01,  5.1546e-01],\n",
            "          ...,\n",
            "          [ 1.1806e+00,  1.9634e-01,  1.3967e+00,  ..., -1.2989e+00,\n",
            "            1.9856e+00,  1.0385e+00],\n",
            "          [ 7.0225e-01,  2.3784e-02,  7.8325e-01,  ..., -1.7945e+00,\n",
            "            1.3206e+00,  1.1713e+00],\n",
            "          [-4.0109e-01, -6.0036e-01,  6.1858e-01,  ...,  8.2541e-01,\n",
            "            3.6037e-01, -1.4372e-01]],\n",
            "\n",
            "         [[ 2.8361e-03, -3.1716e-01,  5.7167e-02,  ...,  1.2177e+00,\n",
            "           -5.7350e-02, -2.5943e-01],\n",
            "          [ 8.8797e-04,  6.3527e-03,  7.2970e-03,  ...,  4.6665e-02,\n",
            "           -2.4447e-01, -2.2994e-02],\n",
            "          [ 4.5850e-01,  5.1769e-01, -5.9179e-01,  ...,  1.3798e+00,\n",
            "           -5.5234e-01, -5.0878e-01],\n",
            "          ...,\n",
            "          [ 1.6142e-01,  4.6399e-01, -4.4014e-01,  ...,  7.0153e-01,\n",
            "           -1.0698e+00, -1.2114e+00],\n",
            "          [-4.3631e-01,  9.3384e-01, -4.4917e-01,  ...,  1.4818e+00,\n",
            "            7.5505e-01, -1.0836e+00],\n",
            "          [-6.6253e-01,  9.8918e-02, -7.5916e-01,  ...,  3.0560e-01,\n",
            "           -1.5169e+00, -5.0874e-02]]]]), tensor([[[[-1.5080e-01,  6.2786e-02,  2.0629e-01,  ..., -6.1780e-02,\n",
            "           -4.4213e-01,  4.9777e-02],\n",
            "          [ 3.0294e-02, -2.3282e-03,  1.9242e-02,  ...,  3.0173e-02,\n",
            "           -7.1043e-03, -1.3423e-02],\n",
            "          [-1.7120e-01,  9.7236e-01, -1.0343e+00,  ..., -4.0882e-01,\n",
            "            1.7664e-01,  3.9577e-02],\n",
            "          ...,\n",
            "          [-1.7302e+00,  1.0242e+00, -1.0722e-01,  ..., -4.5260e-01,\n",
            "           -4.2007e-01, -2.3624e-01],\n",
            "          [-4.7682e-01, -1.5496e+00, -1.1086e+00,  ...,  1.4022e+00,\n",
            "            7.8313e-01, -1.0571e+00],\n",
            "          [ 5.9938e-02,  7.7951e-01, -6.2696e-01,  ...,  5.8843e-01,\n",
            "            9.4690e-02, -5.5781e-02]],\n",
            "\n",
            "         [[ 1.0056e-01, -3.0294e-01,  2.1430e-01,  ..., -5.2642e-01,\n",
            "           -1.1071e-02, -7.5312e-01],\n",
            "          [-3.1738e-02, -5.4791e-02, -4.5304e-02,  ...,  1.2479e-03,\n",
            "           -3.2508e-02,  1.6846e-02],\n",
            "          [-4.2591e-01,  5.5550e-02,  6.4225e-02,  ..., -2.0802e+00,\n",
            "            1.6727e-01, -4.9570e-01],\n",
            "          ...,\n",
            "          [ 2.1316e-01,  2.1027e+00,  1.1273e+00,  ..., -6.9612e-01,\n",
            "           -3.3327e-01, -6.6494e-01],\n",
            "          [-4.6649e-01,  9.2562e-01,  2.1725e+00,  ...,  1.5702e+00,\n",
            "            1.5157e+00, -6.2921e-01],\n",
            "          [ 1.9282e-01,  6.3637e-02,  6.0212e-01,  ..., -2.9395e-01,\n",
            "            3.5577e-02, -9.4109e-01]],\n",
            "\n",
            "         [[-2.2243e-01, -4.5745e-02,  1.2762e-01,  ...,  6.3730e-02,\n",
            "           -1.3547e-02,  2.7153e-01],\n",
            "          [ 3.4004e-02,  3.5645e-02, -3.4432e-02,  ..., -3.2198e-02,\n",
            "            1.1932e-02, -4.8423e-02],\n",
            "          [ 5.2661e-01,  1.2885e-02, -6.8929e-02,  ..., -5.0080e-01,\n",
            "            8.1443e-02, -3.0133e-01],\n",
            "          ...,\n",
            "          [-6.2964e-01, -1.2865e+00, -3.5896e-01,  ..., -3.2419e-01,\n",
            "            3.8568e-01,  1.0364e+00],\n",
            "          [-2.3635e+00,  1.0959e-01,  6.2462e-01,  ..., -7.5276e-01,\n",
            "           -1.5682e+00,  4.5663e-02],\n",
            "          [ 1.0356e-02,  3.0808e-01, -7.5441e-01,  ..., -2.5154e-01,\n",
            "            1.0401e+00,  6.6289e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.9556e-01, -4.3933e-01,  1.4794e-01,  ...,  1.5175e-01,\n",
            "            1.1085e-01,  2.0466e-01],\n",
            "          [-2.5966e-03,  2.6226e-02, -4.3645e-02,  ...,  5.2891e-02,\n",
            "            2.8483e-02, -4.4918e-02],\n",
            "          [-1.4652e-01,  4.9287e-01,  1.0274e+00,  ...,  7.3439e-02,\n",
            "           -2.6708e-02,  1.3686e-01],\n",
            "          ...,\n",
            "          [-3.2492e-01, -1.5512e+00, -9.2738e-01,  ...,  7.7201e-02,\n",
            "           -3.9559e-01,  3.0321e-03],\n",
            "          [ 1.8587e+00, -1.5347e+00, -1.8713e+00,  ..., -1.7266e+00,\n",
            "           -5.1591e-02, -1.7285e+00],\n",
            "          [ 2.5216e-02,  1.6960e-01, -5.1074e-01,  ..., -6.2407e-01,\n",
            "            6.4024e-01, -2.6848e-01]],\n",
            "\n",
            "         [[ 2.7179e-01,  1.1765e-01,  6.4458e-02,  ...,  1.4085e-01,\n",
            "           -1.3346e-01,  6.7502e-02],\n",
            "          [-2.3303e-02,  2.4876e-02,  1.9758e-02,  ...,  4.1779e-02,\n",
            "            4.1947e-02,  8.3969e-02],\n",
            "          [ 4.2647e-01,  3.6634e-01,  7.5597e-01,  ...,  2.3031e-01,\n",
            "           -3.8270e-01,  8.1113e-01],\n",
            "          ...,\n",
            "          [ 1.3777e+00,  8.9266e-01, -6.7941e-02,  ...,  1.0767e+00,\n",
            "           -6.9343e-01, -1.0278e+00],\n",
            "          [ 1.9999e+00, -9.4652e-01,  4.5471e-01,  ...,  2.6961e-01,\n",
            "           -1.9371e+00, -1.6341e+00],\n",
            "          [ 5.6193e-01, -1.5167e-01, -1.6805e-01,  ...,  5.7424e-01,\n",
            "           -2.3557e-01,  3.7488e-01]],\n",
            "\n",
            "         [[-2.6106e-01,  1.8391e-01,  1.5177e-01,  ..., -4.8627e-03,\n",
            "           -5.1780e-02,  5.4936e-02],\n",
            "          [-5.5175e-03, -1.4031e-02,  1.3307e-02,  ..., -1.8790e-02,\n",
            "           -2.7378e-02, -9.0790e-03],\n",
            "          [-4.6759e-01, -1.4841e-02,  6.3389e-01,  ..., -4.6535e-01,\n",
            "            2.5749e-01, -5.7377e-01],\n",
            "          ...,\n",
            "          [-3.2298e-01,  9.1977e-01,  3.3796e-01,  ...,  1.7167e+00,\n",
            "           -1.0327e-01, -4.6343e-01],\n",
            "          [-4.6051e-01,  2.2785e-01,  7.8280e-01,  ..., -3.5425e-01,\n",
            "           -2.9513e-01,  1.5383e+00],\n",
            "          [-8.9960e-01,  5.8796e-01, -4.2660e-01,  ..., -7.2312e-01,\n",
            "           -6.9795e-02,  5.9727e-01]]]])), (tensor([[[[-7.7636e-02,  7.1486e-02,  2.8457e-01,  ..., -4.1635e-01,\n",
            "           -2.8777e-01, -7.2011e-01],\n",
            "          [-4.5691e-03,  1.6248e-02, -8.4306e-03,  ..., -2.3216e-02,\n",
            "           -5.8259e-02,  2.5833e-01],\n",
            "          [-1.7220e+00,  1.6824e+00, -5.4079e-01,  ...,  8.2542e-01,\n",
            "           -8.9756e-01,  1.1842e-01],\n",
            "          ...,\n",
            "          [-4.6485e-01, -2.1308e-01, -1.8928e+00,  ...,  9.0549e-02,\n",
            "           -1.5946e-01, -5.3072e-01],\n",
            "          [-6.1954e-01, -5.4592e-01, -2.0247e+00,  ..., -3.6637e-01,\n",
            "           -1.1065e+00, -1.6179e-02],\n",
            "          [-3.7753e-02, -5.6836e-02, -6.9959e-01,  ...,  4.2561e-01,\n",
            "            3.6864e-01, -2.8031e-01]],\n",
            "\n",
            "         [[-1.7032e-01,  6.1516e-02, -4.0576e-01,  ..., -4.8211e-01,\n",
            "            4.6637e-02,  3.9633e-01],\n",
            "          [-8.4844e-03, -8.8648e-03,  3.2443e-02,  ..., -3.2902e-01,\n",
            "           -1.8838e-01,  3.3814e-01],\n",
            "          [ 1.2296e+00, -4.2018e-01, -1.5632e+00,  ..., -1.1139e+00,\n",
            "            1.4719e+00,  7.2244e-01],\n",
            "          ...,\n",
            "          [ 1.5054e+00, -1.0873e+00, -1.7633e+00,  ..., -4.4573e-01,\n",
            "            1.6845e-01,  1.0644e+00],\n",
            "          [ 1.5132e+00, -2.5566e-01, -2.3418e+00,  ...,  1.8407e-01,\n",
            "            7.3469e-01, -7.4011e-01],\n",
            "          [ 4.0857e-02, -1.2173e-01,  2.1782e-01,  ...,  1.8167e-01,\n",
            "            6.1290e-01, -7.7311e-01]],\n",
            "\n",
            "         [[ 6.0119e-01, -6.5632e-01,  3.8879e-01,  ..., -5.4725e-01,\n",
            "           -1.0372e+00,  2.0415e-01],\n",
            "          [ 7.2836e-03, -3.6408e-03, -3.6206e-02,  ...,  3.7952e-01,\n",
            "           -8.5370e-01, -3.1237e-01],\n",
            "          [-1.5936e+00, -2.5413e+00,  2.8632e-01,  ..., -1.5039e-01,\n",
            "           -1.6964e+00,  2.4137e-01],\n",
            "          ...,\n",
            "          [-4.7860e-01,  1.8509e+00,  1.1682e+00,  ...,  1.0887e+00,\n",
            "            4.7924e-01, -7.0221e-01],\n",
            "          [ 5.1922e-02,  9.7992e-01,  1.3525e+00,  ...,  9.6881e-01,\n",
            "            8.8886e-01, -1.3300e+00],\n",
            "          [ 8.6321e-01,  6.2839e-01,  7.8458e-01,  ...,  1.0392e-01,\n",
            "           -1.2078e+00,  2.7792e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4990e-01, -6.0683e-01, -3.6565e-01,  ...,  2.1742e-01,\n",
            "            1.4809e-01,  6.6833e-01],\n",
            "          [-2.7557e-02,  1.4586e-02, -8.0660e-03,  ...,  3.7871e-01,\n",
            "            1.4075e+00,  1.2440e+00],\n",
            "          [ 3.5578e-01, -3.7804e-01, -1.4415e+00,  ...,  3.2487e-01,\n",
            "            7.2729e-01,  1.0101e+00],\n",
            "          ...,\n",
            "          [-9.0918e-02,  2.1693e+00,  9.4555e-01,  ..., -1.7792e-01,\n",
            "            9.8718e-01,  9.6080e-01],\n",
            "          [ 6.4466e-02,  9.8948e-01,  1.0525e+00,  ..., -4.5197e-01,\n",
            "            1.1780e+00,  1.7295e+00],\n",
            "          [ 2.7522e-01,  2.1465e-01,  6.7315e-01,  ...,  9.6189e-02,\n",
            "            1.5857e+00,  1.7873e+00]],\n",
            "\n",
            "         [[-2.6710e-01, -2.7688e-02,  1.6116e-01,  ..., -7.8147e-01,\n",
            "            1.3222e+00, -9.3958e-01],\n",
            "          [ 8.9924e-04, -1.2337e-02, -1.7575e-02,  ...,  8.6969e-02,\n",
            "            9.3207e-02, -2.6534e-01],\n",
            "          [-3.0527e-01,  8.5365e-01, -1.4861e+00,  ...,  6.5573e-01,\n",
            "           -3.4306e-02, -1.3847e+00],\n",
            "          ...,\n",
            "          [-1.9845e-01,  3.7059e-01, -1.1218e+00,  ...,  6.3006e-01,\n",
            "            1.3762e-02, -9.4115e-01],\n",
            "          [ 1.2293e+00, -6.3686e-01, -9.8008e-01,  ..., -1.2834e-01,\n",
            "           -1.4140e+00, -1.5576e+00],\n",
            "          [ 5.9184e-01, -6.1343e-01, -9.4893e-01,  ...,  4.3119e-01,\n",
            "            3.8343e-01, -3.9330e-01]],\n",
            "\n",
            "         [[-3.1270e-01, -3.1496e-01, -7.8246e-01,  ..., -4.6917e+00,\n",
            "           -7.6097e-04,  2.0281e-01],\n",
            "          [ 2.3572e-03, -6.3305e-03, -2.3762e-02,  ..., -6.7332e+00,\n",
            "           -1.2607e-01,  1.6350e-01],\n",
            "          [-1.6546e-01,  1.4038e+00, -1.9473e+00,  ..., -1.9831e+00,\n",
            "           -3.3244e-01,  9.9801e-02],\n",
            "          ...,\n",
            "          [ 5.4504e-01,  3.4057e-01, -7.0927e-01,  ..., -3.4844e+00,\n",
            "           -3.7894e-01,  1.1082e+00],\n",
            "          [-5.1476e-02, -1.3168e-02, -1.5338e+00,  ..., -1.9063e+00,\n",
            "           -3.2021e-02, -1.9893e-01],\n",
            "          [ 5.0993e-01, -7.4327e-01, -1.2563e+00,  ..., -2.7274e+00,\n",
            "           -7.9309e-02,  3.3604e-01]]]]), tensor([[[[-5.6592e-01,  4.6886e-02, -6.2613e-01,  ...,  1.7244e-03,\n",
            "           -7.2348e-02, -1.1334e-01],\n",
            "          [ 5.5086e-02,  2.9950e-02,  5.2402e-02,  ..., -6.1886e-03,\n",
            "           -3.4219e-02,  5.2401e-03],\n",
            "          [ 3.4533e-02, -1.1309e+00, -1.1956e+00,  ...,  4.0820e-02,\n",
            "           -9.9365e-01, -8.8758e-01],\n",
            "          ...,\n",
            "          [ 1.1848e-01, -1.2902e-01, -1.3357e+00,  ...,  3.0610e-01,\n",
            "           -1.7542e-01,  6.6973e-01],\n",
            "          [-1.4919e+00,  8.7359e-02, -1.4216e+00,  ...,  3.0093e-01,\n",
            "            9.1111e-01,  4.7499e-01],\n",
            "          [-2.7200e-01, -3.6039e-01, -4.0493e-01,  ..., -3.5288e-01,\n",
            "           -4.4318e-01, -2.3572e-01]],\n",
            "\n",
            "         [[-1.6708e-01,  5.5101e-01,  2.0338e-01,  ...,  4.6694e-01,\n",
            "            1.2787e-01,  4.2486e-01],\n",
            "          [ 1.1761e-01, -8.9910e-02, -3.3854e-02,  ...,  1.0130e-01,\n",
            "            9.9794e-02, -1.0466e-01],\n",
            "          [-3.2648e-01,  4.6637e-01, -2.3756e-01,  ...,  3.0698e-01,\n",
            "           -7.3945e-01,  2.2916e-03],\n",
            "          ...,\n",
            "          [-5.4471e-01,  1.3377e+00, -1.1740e-01,  ...,  1.0605e+00,\n",
            "           -1.0498e+00,  2.4076e-01],\n",
            "          [-5.5912e-01,  1.0036e+00, -1.1292e+00,  ...,  7.3798e-01,\n",
            "           -9.1249e-01, -3.7231e-01],\n",
            "          [ 3.3513e-01,  6.3273e-01, -5.2553e-01,  ..., -6.0864e-01,\n",
            "            8.4741e-01,  2.1999e-01]],\n",
            "\n",
            "         [[-3.5818e-01,  2.8781e-01,  4.0954e-01,  ..., -1.0330e+00,\n",
            "            2.2584e-01, -3.6053e-01],\n",
            "          [ 4.2380e-02,  1.9480e-02, -1.8272e-02,  ..., -6.0190e-01,\n",
            "           -3.4651e-02, -7.0129e-02],\n",
            "          [-3.6202e-01, -7.6475e-01,  9.2699e-02,  ..., -1.1698e+00,\n",
            "           -7.1054e-01,  7.9626e-01],\n",
            "          ...,\n",
            "          [ 6.1739e-01,  9.1686e-01, -6.5142e-01,  ..., -1.6492e+00,\n",
            "            2.5034e-01,  8.6309e-01],\n",
            "          [-7.0750e-01,  3.7799e-01,  9.6872e-01,  ..., -1.7465e+00,\n",
            "            9.4360e-01, -4.1675e-01],\n",
            "          [ 2.9372e-01, -5.8779e-01,  3.3141e-01,  ..., -1.3992e+00,\n",
            "            2.4822e-01,  6.5786e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.3078e-01,  2.5580e-01, -1.2579e-01,  ...,  2.1123e-01,\n",
            "            2.2763e-01,  2.9137e-01],\n",
            "          [-4.2471e-02,  5.4266e-02, -5.5124e-03,  ...,  1.1273e-03,\n",
            "           -4.5743e-02, -2.2530e-02],\n",
            "          [-7.0641e-01, -9.0545e-01,  4.4381e-01,  ...,  9.5880e-01,\n",
            "            7.1038e-01,  4.6072e-01],\n",
            "          ...,\n",
            "          [-8.6032e-01, -8.1202e-02,  4.1821e-01,  ..., -9.5384e-01,\n",
            "            7.5097e-01,  8.4486e-01],\n",
            "          [-5.5627e-01, -1.8734e-01,  2.1383e+00,  ...,  1.1446e+00,\n",
            "           -2.1608e-01,  1.6430e+00],\n",
            "          [-7.5004e-01, -7.1964e-01,  4.3687e-02,  ..., -2.3449e-01,\n",
            "           -8.1741e-01,  1.1505e-01]],\n",
            "\n",
            "         [[ 1.8488e-01,  1.0036e-01, -4.5979e-01,  ...,  1.8084e-02,\n",
            "            5.7925e-02,  1.3868e-01],\n",
            "          [-2.1072e-02, -5.2050e-02,  2.0367e-02,  ...,  3.9988e-02,\n",
            "           -3.7157e-02, -4.6855e-04],\n",
            "          [ 3.6291e-01,  2.3220e-01,  1.1535e-01,  ..., -1.0160e+00,\n",
            "            7.2960e-01, -1.5694e-01],\n",
            "          ...,\n",
            "          [-1.5986e-01,  5.8829e-01,  9.1480e-02,  ...,  1.8072e+00,\n",
            "           -3.2123e-01, -6.7483e-01],\n",
            "          [ 6.6669e-01, -2.6312e+00, -1.1114e+00,  ..., -2.9166e-02,\n",
            "            1.8125e+00, -1.6614e+00],\n",
            "          [ 4.3447e-01, -8.5305e-01,  4.5403e-01,  ...,  5.5394e-01,\n",
            "           -1.5865e-01,  6.1680e-02]],\n",
            "\n",
            "         [[-1.9865e-01,  1.6061e-01, -1.1685e-01,  ...,  9.6700e-02,\n",
            "           -3.6567e-01, -1.9354e-01],\n",
            "          [-1.8534e-02,  8.1323e-02,  6.5284e-02,  ...,  4.7746e-02,\n",
            "           -2.9446e-02,  2.3176e-03],\n",
            "          [-7.0618e-01,  7.6762e-01, -2.3728e-02,  ...,  1.1080e+00,\n",
            "            5.9788e-01, -6.2247e-01],\n",
            "          ...,\n",
            "          [-1.1632e-01,  2.5736e-02,  1.3433e+00,  ..., -6.7415e-01,\n",
            "           -3.2870e-02, -1.1977e+00],\n",
            "          [ 7.1218e-01, -1.6762e+00,  1.2474e+00,  ..., -1.7610e-01,\n",
            "           -2.6929e-02, -5.2373e-01],\n",
            "          [ 2.5871e-01,  1.3242e+00,  2.2939e-01,  ..., -3.7447e-01,\n",
            "            6.2949e-01,  8.8787e-01]]]])), (tensor([[[[-2.2325e-01,  1.3919e-01,  7.6650e-01,  ..., -4.4998e-01,\n",
            "            2.6266e-01,  3.4611e-01],\n",
            "          [ 1.5511e-03,  9.6600e-03,  7.8419e-03,  ...,  1.9575e-01,\n",
            "           -2.0587e-01, -6.8078e-01],\n",
            "          [ 1.0020e+00,  2.0309e-01,  2.2315e+00,  ..., -3.0201e-01,\n",
            "            8.9312e-03,  2.0057e-01],\n",
            "          ...,\n",
            "          [ 4.8344e-01,  7.9903e-01,  1.4633e+00,  ..., -2.3941e-01,\n",
            "            7.2477e-01, -9.4745e-02],\n",
            "          [-2.5289e-02,  9.9632e-01,  1.6528e+00,  ...,  1.4165e-01,\n",
            "            1.0701e+00,  9.1946e-01],\n",
            "          [-4.4007e-01,  2.7773e-01,  1.7438e+00,  ...,  4.0432e-01,\n",
            "           -4.9326e-01,  1.8924e-01]],\n",
            "\n",
            "         [[ 1.0122e-01, -9.1483e-02,  2.2569e-01,  ...,  6.8517e-01,\n",
            "            1.1359e+00,  1.3093e+00],\n",
            "          [-2.9371e-02, -4.2635e-03,  1.0092e-02,  ...,  4.2608e-02,\n",
            "            2.0991e-01, -1.6539e-01],\n",
            "          [-7.6017e-01, -8.4234e-01,  1.5560e+00,  ...,  1.7972e+00,\n",
            "            1.7601e-02,  1.0879e+00],\n",
            "          ...,\n",
            "          [-1.8163e-01, -3.4100e-01,  4.0189e-01,  ...,  1.0606e+00,\n",
            "            1.5204e-01, -8.9994e-01],\n",
            "          [ 4.9282e-02, -3.5390e-01,  1.2809e+00,  ...,  1.4036e+00,\n",
            "            7.3257e-01,  3.8191e-01],\n",
            "          [ 2.4427e-02, -1.6737e-01, -7.2550e-02,  ..., -3.2774e-01,\n",
            "            7.0849e-01,  1.1064e-01]],\n",
            "\n",
            "         [[-6.3811e-01,  1.5586e-01,  7.7502e-01,  ..., -1.7769e-01,\n",
            "           -4.4229e-02,  4.1081e-01],\n",
            "          [-1.0617e-02, -1.7741e-03,  2.8675e-03,  ...,  1.7775e-01,\n",
            "           -6.8279e-02,  3.5346e-01],\n",
            "          [-1.4772e-01, -2.6312e-01,  6.0898e-01,  ..., -2.7788e-02,\n",
            "            1.7525e-01, -3.1897e-01],\n",
            "          ...,\n",
            "          [ 1.9358e-01,  1.2128e-01, -7.1328e-01,  ...,  1.9014e+00,\n",
            "           -1.2386e+00,  9.4461e-01],\n",
            "          [ 1.5551e-01, -5.6876e-01, -9.2523e-01,  ...,  8.7133e-01,\n",
            "           -1.1717e+00, -3.8920e-01],\n",
            "          [-6.8953e-01,  6.0397e-01, -1.9096e+00,  ...,  7.5726e-01,\n",
            "           -6.2401e-01, -4.1156e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.5292e-01,  7.8949e-01, -1.3297e-01,  ..., -4.3657e-01,\n",
            "           -4.4091e-02,  4.1129e-01],\n",
            "          [ 5.6988e-05, -1.7947e-02, -5.0975e-03,  ..., -1.8472e-01,\n",
            "            2.9096e-02, -1.5178e-01],\n",
            "          [-1.3575e+00, -2.9289e-01,  5.4625e-01,  ..., -1.4439e+00,\n",
            "           -2.6450e-01, -3.7692e-01],\n",
            "          ...,\n",
            "          [-1.4338e+00, -1.0352e+00,  1.4887e+00,  ..., -1.2937e+00,\n",
            "            8.6011e-01, -1.4174e+00],\n",
            "          [-1.7568e-01,  6.0463e-02,  1.0844e+00,  ..., -3.2661e-01,\n",
            "            8.6600e-01, -7.4043e-01],\n",
            "          [ 3.0708e-01, -8.4196e-01,  1.8958e+00,  ..., -3.1021e-02,\n",
            "           -4.7004e-01, -3.7194e-01]],\n",
            "\n",
            "         [[-1.1233e-01,  4.0070e-02, -7.5275e-01,  ..., -1.1444e+00,\n",
            "           -7.2211e-01, -8.3423e-02],\n",
            "          [ 2.4772e-02, -1.1701e-03,  2.9146e-03,  ...,  1.0743e-01,\n",
            "            4.5628e-01,  2.4478e-01],\n",
            "          [ 1.9562e+00,  1.0541e+00, -2.4222e+00,  ..., -3.4514e-01,\n",
            "            6.8020e-02, -3.1319e-01],\n",
            "          ...,\n",
            "          [ 2.5360e-01,  1.4927e-01, -4.0626e-01,  ..., -3.3233e-01,\n",
            "           -3.9113e-01,  6.3446e-02],\n",
            "          [-8.0964e-02,  3.6226e-01, -1.1937e+00,  ...,  1.5463e+00,\n",
            "            2.4715e-01, -9.3517e-01],\n",
            "          [-4.8675e-01, -2.2552e-02, -1.9889e+00,  ...,  2.2627e-02,\n",
            "            1.0253e+00, -1.0441e-01]],\n",
            "\n",
            "         [[ 1.6213e-01,  5.0755e-02,  2.8415e-01,  ..., -1.3411e+00,\n",
            "            9.0072e-02,  3.2825e+00],\n",
            "          [-2.3478e-03, -2.2848e-02, -1.5874e-02,  ...,  2.8550e-01,\n",
            "            2.4803e-01,  3.9804e+00],\n",
            "          [-5.9299e-01, -6.9771e-01,  8.2901e-01,  ..., -3.8422e-01,\n",
            "           -8.4613e-02,  1.6999e+00],\n",
            "          ...,\n",
            "          [ 5.7142e-01,  1.3425e+00,  1.5631e+00,  ..., -1.0408e+00,\n",
            "           -6.4243e-01,  2.9868e+00],\n",
            "          [-1.0673e+00,  1.0156e+00,  1.2992e+00,  ..., -6.6475e-01,\n",
            "           -1.3559e+00,  2.5565e+00],\n",
            "          [-1.8977e-01,  3.6764e-01,  6.2465e-01,  ...,  7.8541e-02,\n",
            "            1.5342e-01,  3.9240e+00]]]]), tensor([[[[-4.4186e-01, -2.1620e-01,  5.2687e-01,  ..., -2.4171e-02,\n",
            "           -4.0341e-02,  3.5989e-01],\n",
            "          [-5.1922e-02, -5.9267e-03, -1.9460e-02,  ...,  2.0284e-02,\n",
            "           -8.5529e-03,  6.6286e-02],\n",
            "          [ 2.1186e-01, -1.4410e+00,  1.1874e+00,  ...,  1.4528e+00,\n",
            "           -9.0415e-01,  5.1925e-01],\n",
            "          ...,\n",
            "          [-2.7809e-01, -6.9136e-01, -4.8031e-01,  ..., -7.4530e-01,\n",
            "            1.2379e-01, -9.7448e-01],\n",
            "          [ 4.8545e-01, -7.1284e-02,  8.6689e-01,  ..., -4.0503e-01,\n",
            "           -2.0662e+00,  3.5206e-01],\n",
            "          [-5.6563e-01,  1.2355e+00,  1.5075e-01,  ..., -9.7378e-02,\n",
            "            4.6264e-01, -1.1675e+00]],\n",
            "\n",
            "         [[-1.1444e-01, -3.1515e-02,  2.1523e-01,  ..., -3.8929e-02,\n",
            "            4.7787e-02,  3.8279e-01],\n",
            "          [-5.8031e-02, -1.4137e-02, -6.3432e-02,  ...,  1.3726e-02,\n",
            "           -1.0181e-02, -3.5498e-02],\n",
            "          [-2.6937e-01,  6.5985e-01,  7.0718e-01,  ..., -7.1848e-01,\n",
            "           -8.0945e-01,  3.8104e-01],\n",
            "          ...,\n",
            "          [ 6.8666e-01,  5.4126e-01,  2.5657e-01,  ...,  2.5484e-01,\n",
            "           -3.2843e-01, -6.4214e-01],\n",
            "          [ 1.8847e-01, -8.2870e-01,  6.0997e-01,  ..., -4.7499e-01,\n",
            "           -1.4150e+00, -1.3956e-01],\n",
            "          [-2.1711e-02,  6.5065e-01, -4.8984e-02,  ..., -1.0924e+00,\n",
            "            6.3937e-01,  3.7249e-02]],\n",
            "\n",
            "         [[ 2.1416e-01, -1.1839e-01, -1.0964e-01,  ...,  1.8246e-01,\n",
            "           -2.8808e-01,  6.6456e-01],\n",
            "          [ 2.6423e-02, -2.1453e-02,  3.6974e-03,  ...,  1.3342e-03,\n",
            "           -3.9301e-02, -2.0173e-03],\n",
            "          [ 7.1876e-01,  1.0075e+00,  4.3006e-01,  ...,  2.4278e-01,\n",
            "           -2.5075e-01,  7.3851e-01],\n",
            "          ...,\n",
            "          [ 1.0556e-01,  3.0638e-01, -3.9542e-01,  ...,  2.3236e-01,\n",
            "            8.6929e-01, -5.8210e-01],\n",
            "          [-3.1472e-01,  2.0033e+00, -3.1728e-01,  ..., -4.8134e-01,\n",
            "            1.4395e+00, -4.7934e-01],\n",
            "          [-5.9913e-02, -2.0132e-01, -5.0696e-03,  ..., -3.0524e-01,\n",
            "           -2.4253e-01,  2.5173e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1155e-01, -1.3505e-01,  4.3211e-03,  ..., -1.0498e-01,\n",
            "           -2.2096e-01,  6.9029e-03],\n",
            "          [-6.5000e-03, -4.2068e-02, -3.2189e-02,  ...,  7.6137e-02,\n",
            "           -2.8829e-02,  3.8313e-02],\n",
            "          [-4.3880e-01, -4.8264e-01,  5.7234e-01,  ..., -1.6353e-01,\n",
            "           -1.5121e-01, -7.3062e-01],\n",
            "          ...,\n",
            "          [ 4.5533e-01, -5.7771e-01,  2.0590e-01,  ...,  2.4793e-01,\n",
            "            3.9038e-01, -2.0233e+00],\n",
            "          [ 2.0995e-02, -7.1442e-01,  9.9416e-01,  ...,  1.3472e-01,\n",
            "           -1.9724e+00,  4.0544e-01],\n",
            "          [ 8.6537e-01,  9.6758e-03, -1.7832e-01,  ...,  2.9349e-01,\n",
            "           -5.2618e-01, -9.5410e-01]],\n",
            "\n",
            "         [[-2.9142e-01,  1.4534e-02,  3.5186e-01,  ...,  5.9805e-02,\n",
            "            6.4411e-01, -6.5895e-01],\n",
            "          [-3.2627e-02,  2.3887e-02,  3.3580e-02,  ..., -7.7873e-02,\n",
            "            5.8643e-02,  6.7453e-03],\n",
            "          [-8.5122e-01,  6.3753e-01,  2.1494e-01,  ...,  3.8087e-01,\n",
            "           -4.7048e-01, -5.4483e-01],\n",
            "          ...,\n",
            "          [-2.3571e-01, -4.9193e-02, -4.7979e-01,  ..., -9.3995e-01,\n",
            "           -8.6425e-01,  9.3633e-01],\n",
            "          [ 7.2068e-01, -1.1199e+00, -7.1801e-01,  ...,  2.8061e+00,\n",
            "           -1.4744e+00,  1.8099e+00],\n",
            "          [ 4.4310e-01, -6.9001e-01, -3.3174e-01,  ..., -6.6679e-01,\n",
            "            3.8970e-01,  3.8737e-01]],\n",
            "\n",
            "         [[-2.6735e-01, -2.6807e-01, -1.6745e-01,  ...,  9.1477e-02,\n",
            "            3.2574e-01, -2.9621e-03],\n",
            "          [-2.1637e-02,  4.2727e-02,  2.6591e-02,  ..., -3.1585e-02,\n",
            "           -6.4815e-02, -1.1452e-02],\n",
            "          [-4.6996e-01, -5.8673e-01,  1.4159e+00,  ...,  1.7574e-01,\n",
            "           -5.6887e-01,  6.3504e-01],\n",
            "          ...,\n",
            "          [ 2.4068e-01, -5.7829e-01,  7.0664e-01,  ..., -1.7127e-02,\n",
            "           -1.6272e-02,  8.8230e-01],\n",
            "          [ 1.2094e+00,  9.8557e-01,  1.2934e+00,  ..., -2.9542e-01,\n",
            "            1.1266e+00, -1.2941e-01],\n",
            "          [-2.6672e-01, -8.9497e-01, -2.2406e-01,  ...,  5.3243e-02,\n",
            "            1.8906e-01,  4.7658e-01]]]])), (tensor([[[[ 2.4879e-01, -5.7204e-01,  1.6807e-01,  ..., -2.9699e-01,\n",
            "            3.5850e-01,  9.3923e-01],\n",
            "          [-1.0261e-02, -2.1541e-02,  6.3662e-04,  ..., -8.2757e-01,\n",
            "            5.6972e-02,  5.4948e-02],\n",
            "          [ 1.9824e+00, -2.0750e+00,  2.8769e-01,  ..., -1.2914e+00,\n",
            "            4.1384e-01,  1.1816e+00],\n",
            "          ...,\n",
            "          [-4.9591e-02,  7.3914e-01,  8.3840e-01,  ..., -1.6942e+00,\n",
            "           -2.9129e-01, -6.7169e-02],\n",
            "          [-5.8256e-01,  9.6079e-01,  2.0724e+00,  ..., -1.4141e+00,\n",
            "            2.3400e+00, -5.3910e-01],\n",
            "          [-6.7477e-01,  8.0558e-01,  1.5757e+00,  ..., -1.2354e-01,\n",
            "            1.0664e+00,  2.1492e-01]],\n",
            "\n",
            "         [[ 7.2891e-02,  1.2834e+00, -1.3240e+00,  ...,  4.9744e-01,\n",
            "           -1.5349e+00, -4.0929e-01],\n",
            "          [ 8.1012e-04, -1.1860e-02,  9.9375e-03,  ...,  5.1442e-01,\n",
            "           -9.6734e-01,  2.4594e-02],\n",
            "          [-8.5702e-01,  1.8902e+00, -2.3996e+00,  ...,  9.9784e-01,\n",
            "           -1.0258e+00, -4.2334e-01],\n",
            "          ...,\n",
            "          [-1.7719e+00, -1.6391e+00, -2.5040e+00,  ...,  3.9260e-01,\n",
            "           -1.5166e+00, -1.1819e+00],\n",
            "          [-1.1771e-01, -1.2657e+00, -1.1307e+00,  ...,  1.5207e+00,\n",
            "           -2.0259e+00, -4.8147e-01],\n",
            "          [ 4.4377e-01, -3.1229e-02, -2.3431e-01,  ...,  6.7009e-01,\n",
            "           -6.8296e-02,  6.6965e-01]],\n",
            "\n",
            "         [[-4.6542e-01, -6.4377e-01, -4.5570e-02,  ...,  3.0769e-01,\n",
            "           -9.9288e-01, -5.3143e-01],\n",
            "          [-7.3224e-03, -1.9569e-02,  1.6566e-02,  ..., -1.2933e-01,\n",
            "           -1.0319e+00, -6.3157e-01],\n",
            "          [ 2.1610e+00,  6.5881e-01,  4.3798e-02,  ..., -4.5886e-01,\n",
            "           -1.0059e+00, -1.6642e+00],\n",
            "          ...,\n",
            "          [ 1.4057e+00,  1.1735e+00, -1.2607e+00,  ..., -7.8757e-01,\n",
            "           -1.8019e+00, -3.4105e-01],\n",
            "          [-2.6994e-01, -3.9813e-02, -2.3977e-02,  ...,  6.0686e-02,\n",
            "           -2.1795e+00,  1.6046e-01],\n",
            "          [-2.1426e+00, -3.6333e-02, -2.5385e+00,  ..., -2.6699e-01,\n",
            "            4.7946e-02, -7.7417e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.5636e-01,  5.0188e-01, -3.3320e-01,  ...,  1.2031e+00,\n",
            "           -7.6135e-01,  6.0208e-01],\n",
            "          [-9.0256e-03,  6.4717e-03,  1.6763e-02,  ..., -4.0246e-01,\n",
            "           -4.3742e-01,  2.0902e-01],\n",
            "          [ 2.4160e+00,  2.1605e+00, -1.0263e+00,  ...,  1.0096e+00,\n",
            "           -5.8557e-01,  6.7590e-01],\n",
            "          ...,\n",
            "          [ 1.0425e+00, -2.2104e+00, -2.2096e+00,  ...,  2.0022e-01,\n",
            "           -2.0282e-01, -2.1391e-01],\n",
            "          [-7.3359e-01, -1.8636e+00, -1.6192e+00,  ..., -6.6236e-03,\n",
            "           -1.0949e+00,  6.3202e-01],\n",
            "          [-1.0017e+00, -1.1130e+00, -1.3408e+00,  ..., -5.7245e-01,\n",
            "           -5.3241e-01, -7.8441e-02]],\n",
            "\n",
            "         [[ 5.5204e-01,  2.5688e-01,  5.2918e-01,  ..., -1.4414e+00,\n",
            "            9.7456e-01, -9.5776e-01],\n",
            "          [ 4.5373e-03,  1.1104e-02,  1.9575e-02,  ..., -5.8661e-01,\n",
            "            9.7894e-01, -1.5531e+00],\n",
            "          [-4.8524e-01, -1.0548e+00,  2.2475e-01,  ..., -1.1640e-01,\n",
            "            1.1873e+00, -8.8558e-01],\n",
            "          ...,\n",
            "          [-4.1144e-01, -2.0432e+00, -8.0691e-01,  ..., -7.4068e-01,\n",
            "            1.3524e+00, -4.9043e-01],\n",
            "          [ 1.3922e+00, -6.4754e-02, -1.7717e+00,  ..., -4.0824e-01,\n",
            "            1.5071e+00, -4.0333e-01],\n",
            "          [-2.4650e-01, -8.4626e-03, -1.2246e+00,  ..., -4.1829e-01,\n",
            "            6.9677e-01, -9.7906e-01]],\n",
            "\n",
            "         [[ 4.9029e-01,  7.0784e-01, -3.0208e-01,  ...,  4.5153e-01,\n",
            "            2.4257e-01, -2.6874e-01],\n",
            "          [ 1.8022e-03,  9.5801e-03,  1.7781e-02,  ..., -1.7553e-01,\n",
            "            1.7844e-01, -1.9153e-01],\n",
            "          [-1.6069e+00,  1.2728e+00, -8.4711e-01,  ...,  6.8560e-01,\n",
            "           -3.7616e-01,  2.8495e-01],\n",
            "          ...,\n",
            "          [-1.6745e+00, -2.1866e+00, -1.7485e+00,  ..., -8.8187e-01,\n",
            "            2.3937e-01, -3.6998e-01],\n",
            "          [-1.3777e-01, -1.3059e-01,  7.4737e-02,  ..., -1.7533e+00,\n",
            "            9.0940e-01,  1.0941e-01],\n",
            "          [ 1.0890e+00, -9.3595e-01, -1.1829e+00,  ...,  9.3922e-01,\n",
            "            4.8557e-01, -4.2712e-01]]]]), tensor([[[[-9.5145e-01,  3.1029e-01, -6.8102e-01,  ..., -2.2576e-01,\n",
            "           -1.7518e-01, -5.4700e-01],\n",
            "          [-1.4943e-01,  1.5403e-02,  2.9804e-02,  ...,  5.5093e-02,\n",
            "            1.8964e-02,  7.3055e-02],\n",
            "          [-1.2913e+00, -2.2896e-01, -5.7341e-01,  ...,  1.3846e-01,\n",
            "           -7.1058e-01, -1.1378e+00],\n",
            "          ...,\n",
            "          [-2.8865e-01,  4.5197e-01,  8.8871e-01,  ...,  6.6767e-01,\n",
            "           -6.9515e-01,  7.2005e-02],\n",
            "          [-1.5431e+00, -1.2898e+00, -3.7351e-01,  ...,  1.3674e+00,\n",
            "           -5.1808e-02,  1.3500e+00],\n",
            "          [-1.3047e-01, -1.3069e-01,  1.7930e-01,  ...,  6.1123e-03,\n",
            "            2.6810e-01,  9.6635e-02]],\n",
            "\n",
            "         [[-1.2382e-02,  6.2023e-01, -3.2196e-01,  ..., -9.3120e-01,\n",
            "            7.0613e-02,  5.4179e-01],\n",
            "          [-5.1343e-02,  9.3411e-02,  5.3923e-02,  ..., -7.6725e-01,\n",
            "           -4.1037e-02,  7.4103e-03],\n",
            "          [-1.6781e+00,  1.0277e+00,  8.2313e-01,  ..., -1.9919e+00,\n",
            "            1.6271e-01, -6.7903e-01],\n",
            "          ...,\n",
            "          [-5.7555e-02,  8.8947e-01,  5.0863e-01,  ..., -3.2243e+00,\n",
            "            1.0890e+00,  1.2521e+00],\n",
            "          [ 1.4304e+00,  7.0625e-01,  1.5382e+00,  ..., -1.8858e+00,\n",
            "           -7.0791e-01, -9.0633e-02],\n",
            "          [-2.0883e+00, -6.4380e-01,  1.2818e+00,  ..., -3.2063e+00,\n",
            "           -1.3800e-01, -9.2606e-02]],\n",
            "\n",
            "         [[ 1.3278e+00,  1.2650e+00, -1.5629e+00,  ...,  3.2615e-01,\n",
            "           -1.4316e-01,  1.8765e+00],\n",
            "          [-2.5783e-01, -1.1151e-01,  3.5533e-01,  ..., -2.2461e-01,\n",
            "            3.0805e-01, -3.7593e-02],\n",
            "          [ 6.2339e-01,  3.9564e-01, -1.1193e+00,  ..., -1.2032e+00,\n",
            "           -1.0790e-01,  1.6133e+00],\n",
            "          ...,\n",
            "          [-2.3750e+00,  1.6868e+00,  9.0439e-01,  ..., -2.1477e+00,\n",
            "            2.9007e-01,  7.1370e-01],\n",
            "          [-1.9715e+00,  3.7217e-01,  1.8709e+00,  ..., -1.0314e+00,\n",
            "            3.3812e-01, -1.4743e+00],\n",
            "          [-1.8877e+00,  3.0687e-01,  1.2047e+00,  ..., -2.3761e+00,\n",
            "            1.0321e+00, -4.1647e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.9434e-01, -1.4239e-01,  1.8307e-01,  ..., -3.9624e-01,\n",
            "            2.2144e-01,  5.0443e-04],\n",
            "          [-1.4505e-01, -2.5285e-02,  2.0171e-01,  ..., -1.3748e-01,\n",
            "            3.6335e-02,  2.8018e-03],\n",
            "          [-8.9995e-02,  1.1136e+00,  4.8985e-01,  ...,  9.2691e-02,\n",
            "            3.9011e-01,  6.9596e-02],\n",
            "          ...,\n",
            "          [-3.6885e-01, -8.2345e-01,  3.7203e-01,  ...,  1.2395e+00,\n",
            "           -3.8676e-01, -2.6270e-01],\n",
            "          [ 1.3668e-01, -7.0858e-01,  3.1176e-01,  ...,  9.2396e-02,\n",
            "           -9.2084e-01,  4.3596e-01],\n",
            "          [ 6.4078e-01, -1.2097e+00, -1.5963e-02,  ...,  5.8029e-01,\n",
            "            5.2946e-01, -1.0025e+00]],\n",
            "\n",
            "         [[ 2.5634e-01, -3.7694e-01, -2.4854e-02,  ..., -3.2875e-01,\n",
            "            2.2289e-01,  4.2306e-01],\n",
            "          [ 1.2493e-01, -8.6287e-01,  1.6629e-02,  ..., -4.9556e-02,\n",
            "           -1.4356e-02, -8.9665e-02],\n",
            "          [-2.4819e-01, -1.4191e-01,  1.0951e+00,  ..., -1.3899e-02,\n",
            "            4.0202e-01,  7.4384e-01],\n",
            "          ...,\n",
            "          [ 3.9915e-01,  5.5766e-01, -7.2399e-01,  ..., -2.2179e-01,\n",
            "           -4.9316e-01, -5.5680e-01],\n",
            "          [ 1.7264e-01,  3.9347e-01, -7.2131e-01,  ..., -4.0623e-01,\n",
            "           -2.0422e-01,  7.7538e-03],\n",
            "          [ 2.0664e-01, -6.4468e-01,  4.1735e-01,  ...,  1.0627e+00,\n",
            "            7.9485e-01, -3.0606e-01]],\n",
            "\n",
            "         [[-1.4431e-01,  1.7469e-01,  3.6059e-01,  ...,  1.7404e-01,\n",
            "            2.7076e-01, -6.2103e-01],\n",
            "          [-8.4518e-02, -9.1581e-02,  3.2027e-03,  ...,  4.7406e-02,\n",
            "            5.0237e-02, -1.4243e-01],\n",
            "          [-3.2293e-01,  1.5321e-01,  4.2249e-01,  ...,  5.7845e-01,\n",
            "           -6.5102e-02, -5.7532e-01],\n",
            "          ...,\n",
            "          [ 8.0898e-01,  1.8921e-01, -1.3223e+00,  ...,  4.9814e-02,\n",
            "           -7.7211e-01,  3.9456e-01],\n",
            "          [ 2.7149e+00,  1.5867e+00, -3.8448e+00,  ...,  9.1797e-01,\n",
            "           -6.9491e-01, -2.1719e+00],\n",
            "          [-5.0500e-02,  5.0858e-01, -1.1585e+00,  ...,  2.2986e-01,\n",
            "           -1.2291e+00, -6.5563e-01]]]])), (tensor([[[[-1.1286e+00, -3.3421e-01, -9.8928e-01,  ...,  2.7621e-01,\n",
            "            1.6730e-01,  7.3014e+00],\n",
            "          [-1.5648e-02, -4.1500e-02, -1.5977e-02,  ...,  6.2581e-02,\n",
            "            1.9617e-01,  9.0658e+00],\n",
            "          [ 1.5701e+00,  1.2780e+00, -1.4625e+00,  ...,  3.9340e-01,\n",
            "            3.8077e-01,  3.9974e+00],\n",
            "          ...,\n",
            "          [ 4.2835e+00,  2.4167e+00, -3.8194e+00,  ...,  7.5821e-01,\n",
            "            5.1888e-01,  4.2182e+00],\n",
            "          [ 4.5283e+00,  7.4360e-01, -3.7978e+00,  ..., -4.9200e-01,\n",
            "           -3.4027e-03,  3.2686e+00],\n",
            "          [ 5.5853e-01, -6.4493e-01, -3.6422e+00,  ..., -8.2710e-01,\n",
            "           -1.4651e-01,  4.0640e+00]],\n",
            "\n",
            "         [[ 4.1079e-01,  2.5418e-01,  4.8319e-02,  ...,  5.7816e-01,\n",
            "            1.2008e+00, -3.0897e-01],\n",
            "          [-1.5178e-03,  3.8162e-02,  5.2256e-02,  ...,  1.2087e-01,\n",
            "           -5.7284e-02,  2.2469e-01],\n",
            "          [-3.7672e-01, -1.1677e+00, -5.2552e-01,  ...,  6.2457e-01,\n",
            "           -1.8282e-01, -5.0166e-01],\n",
            "          ...,\n",
            "          [-2.4753e+00,  7.6086e-01, -9.3072e-01,  ..., -5.3482e-01,\n",
            "            3.4927e-01, -4.0118e-01],\n",
            "          [-1.1881e+00,  9.6342e-01, -6.9884e-01,  ..., -9.4290e-01,\n",
            "            1.3429e+00, -1.7033e-01],\n",
            "          [-4.8246e-01,  3.2838e-01, -7.0471e-01,  ..., -4.6902e-01,\n",
            "            5.2644e-01, -6.9863e-01]],\n",
            "\n",
            "         [[-5.3571e-01,  4.9492e-01,  8.2955e-01,  ..., -5.6379e-01,\n",
            "           -1.1246e+00,  3.1380e-01],\n",
            "          [-4.8736e-03,  2.5869e-03,  1.5973e-02,  ..., -9.4593e-01,\n",
            "           -2.3175e-01,  8.1492e-01],\n",
            "          [ 9.2943e-01,  1.5629e-02, -1.8275e-01,  ..., -1.2760e+00,\n",
            "           -1.2170e+00,  1.0650e+00],\n",
            "          ...,\n",
            "          [ 1.9346e+00, -2.5170e+00, -1.9381e+00,  ..., -2.1032e+00,\n",
            "           -1.1984e-01,  1.0048e+00],\n",
            "          [ 2.2344e+00, -1.2625e+00, -2.2361e+00,  ..., -8.6336e-01,\n",
            "            4.4158e-01,  3.7449e-01],\n",
            "          [ 9.3077e-01, -5.1994e-01, -2.4098e+00,  ..., -1.2329e+00,\n",
            "           -5.5540e-01,  1.4824e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1665e-01,  2.1233e-01, -6.2048e-01,  ..., -1.2470e-01,\n",
            "            8.8912e-01, -4.2025e-02],\n",
            "          [ 9.4869e-04, -2.8707e-02,  8.2248e-03,  ..., -9.5263e-02,\n",
            "            5.9689e-01, -2.3358e-01],\n",
            "          [-2.1508e-01,  8.1256e-01, -1.1165e+00,  ..., -3.1946e-01,\n",
            "            1.3206e+00,  1.7452e-01],\n",
            "          ...,\n",
            "          [ 1.1523e+00,  1.4982e-01, -3.6020e-01,  ..., -4.4831e-01,\n",
            "            9.2737e-01, -4.8687e-01],\n",
            "          [ 9.6597e-01, -5.3911e-01, -7.5909e-01,  ..., -5.2381e-01,\n",
            "            2.2580e+00, -6.0330e-01],\n",
            "          [ 5.0657e-02, -8.9906e-01,  4.6662e-01,  ...,  5.8509e-01,\n",
            "            2.0437e-01, -6.6540e-01]],\n",
            "\n",
            "         [[ 1.1135e-01,  2.7255e-01, -3.7357e-01,  ..., -1.9236e+00,\n",
            "            1.6097e-01,  9.6362e-01],\n",
            "          [ 5.1845e-02, -2.9753e-02, -1.8583e-02,  ..., -1.2774e+00,\n",
            "            1.6667e-01,  3.5431e-01],\n",
            "          [ 8.7371e-01,  9.3256e-01, -1.5219e-01,  ..., -1.2355e+00,\n",
            "            8.4378e-01, -1.0197e+00],\n",
            "          ...,\n",
            "          [ 1.0473e+00,  1.9173e+00,  2.1983e+00,  ..., -1.3456e+00,\n",
            "           -5.7315e-01,  9.1871e-03],\n",
            "          [ 8.8929e-01, -9.7786e-02,  2.2143e+00,  ..., -1.6072e+00,\n",
            "           -7.9452e-01, -4.0504e-01],\n",
            "          [-2.8234e-01,  2.4415e-01,  2.3700e+00,  ..., -3.6909e+00,\n",
            "           -1.0050e-01,  6.7758e-01]],\n",
            "\n",
            "         [[-1.2515e-01, -1.3999e+00, -5.8043e-01,  ..., -1.8589e-01,\n",
            "           -3.7570e-01,  6.0639e-01],\n",
            "          [-2.6249e-02,  1.8036e-02, -1.2435e-02,  ...,  8.8564e-01,\n",
            "           -4.6383e-01,  1.3597e-01],\n",
            "          [ 2.5649e+00, -2.0112e+00,  6.5448e-01,  ..., -1.1461e-01,\n",
            "            2.7343e-01,  7.5879e-01],\n",
            "          ...,\n",
            "          [ 1.5526e+00,  3.6625e+00,  1.8014e+00,  ...,  4.9499e-01,\n",
            "           -2.0494e-02, -1.7211e-02],\n",
            "          [-9.9099e-02,  1.6155e+00,  9.1350e-01,  ..., -1.4075e-01,\n",
            "           -1.8547e+00, -2.0769e-01],\n",
            "          [-5.0000e-01,  1.4288e+00,  1.8607e+00,  ...,  1.0151e+00,\n",
            "           -2.6231e+00,  3.4677e-01]]]]), tensor([[[[ 9.9745e-01, -1.0992e+00, -6.1867e-01,  ...,  2.8570e-03,\n",
            "            4.8207e-01, -3.8892e-02],\n",
            "          [-1.5750e-01,  1.4317e-01, -2.0701e-01,  ...,  1.2632e-01,\n",
            "           -6.2183e-01, -1.6424e-01],\n",
            "          [ 1.0317e+00, -9.6789e-01, -1.0425e-01,  ...,  1.8098e+00,\n",
            "            1.1511e+00,  6.7347e-01],\n",
            "          ...,\n",
            "          [ 1.0921e+00,  6.5226e-02, -2.2129e+00,  ...,  4.5097e-01,\n",
            "            1.7351e-01,  3.4167e-01],\n",
            "          [-9.5471e-01,  6.3915e-01, -1.9566e+00,  ..., -4.3723e-01,\n",
            "            1.3851e+00,  1.2685e+00],\n",
            "          [-7.7337e-01,  5.9480e-01,  2.0525e-01,  ...,  2.6396e-01,\n",
            "            9.3849e-01,  6.9033e-01]],\n",
            "\n",
            "         [[-3.9916e-02, -1.4717e-01,  4.9637e-01,  ...,  3.0272e-01,\n",
            "           -5.0795e-01, -1.4795e-01],\n",
            "          [-3.4123e-02,  1.3432e-01,  1.5146e-01,  ...,  9.0277e-02,\n",
            "            8.5265e-02, -2.5115e-02],\n",
            "          [ 1.0570e+00, -1.2759e+00,  6.5713e-01,  ...,  5.8421e-01,\n",
            "           -6.9505e-01,  6.3319e-01],\n",
            "          ...,\n",
            "          [ 1.0394e+00,  1.7771e+00, -8.4961e-01,  ..., -3.4163e-02,\n",
            "           -6.3301e-01,  7.9115e-01],\n",
            "          [ 1.7866e+00,  2.8039e-01, -1.6864e+00,  ..., -3.2449e-01,\n",
            "           -4.1442e-01,  4.1451e-01],\n",
            "          [ 3.2936e-01,  2.7612e-01, -6.8803e-01,  ...,  4.6670e-01,\n",
            "            2.7392e-01,  3.1914e-01]],\n",
            "\n",
            "         [[ 3.4136e-01, -3.9726e-01,  1.2158e+00,  ...,  6.3700e-01,\n",
            "           -5.2260e-01,  1.1205e+00],\n",
            "          [ 5.8592e-02, -1.7811e-01,  4.6814e-02,  ...,  1.5195e-01,\n",
            "           -2.1433e-01, -2.0346e-02],\n",
            "          [-5.4274e-01, -1.2172e+00,  1.5330e+00,  ...,  1.1899e-02,\n",
            "            4.3936e-02,  1.6996e+00],\n",
            "          ...,\n",
            "          [-4.0003e-01,  7.6221e-02,  2.0525e-01,  ..., -4.1805e-01,\n",
            "           -4.6655e-01, -2.4089e-01],\n",
            "          [-7.0033e-01, -7.5389e-01,  1.0025e+00,  ..., -4.9244e-01,\n",
            "           -1.0106e+00, -3.5615e-01],\n",
            "          [-2.0896e+00,  8.0286e-01, -1.2222e+00,  ...,  9.9955e-02,\n",
            "           -3.3519e-01,  2.8101e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.2097e-01,  6.8852e-02, -1.4340e+00,  ...,  7.1231e-02,\n",
            "           -6.2585e-05,  4.5342e-01],\n",
            "          [ 4.6553e-02, -2.5196e-02,  9.8432e-02,  ..., -1.4319e-02,\n",
            "            3.1466e-02, -6.6896e-02],\n",
            "          [-8.7825e-01, -2.2796e+00, -4.9032e-01,  ...,  9.9317e-01,\n",
            "           -5.7149e-01,  1.7056e+00],\n",
            "          ...,\n",
            "          [ 6.7223e-01, -1.1317e-01,  4.8832e-01,  ..., -3.7489e-01,\n",
            "            2.6409e-02,  3.7364e-01],\n",
            "          [ 7.6339e-01,  8.9486e-01, -1.4317e+00,  ..., -1.2271e+00,\n",
            "            1.7185e-01, -1.1045e+00],\n",
            "          [ 9.5962e-01,  1.0966e+00,  4.2767e-03,  ..., -3.6323e-02,\n",
            "            5.1449e-01,  3.1544e-02]],\n",
            "\n",
            "         [[ 6.5976e-01,  6.8320e-01, -4.6120e-01,  ..., -1.7441e-01,\n",
            "           -7.8529e-02,  3.2743e-01],\n",
            "          [ 4.8012e-02,  1.9184e-02, -3.4302e-02,  ...,  2.9601e-01,\n",
            "            6.8454e-02,  2.1937e-01],\n",
            "          [ 6.5807e-01, -1.3401e+00,  4.6101e-01,  ...,  1.0554e+00,\n",
            "           -5.7548e-01,  2.3591e+00],\n",
            "          ...,\n",
            "          [ 1.4400e+00,  7.4456e-02,  1.0601e-01,  ..., -9.4942e-01,\n",
            "            4.1236e-02,  1.0604e+00],\n",
            "          [ 1.1964e+00, -1.1516e+00, -5.7120e-02,  ..., -2.4938e-01,\n",
            "            2.3930e-01,  1.8321e+00],\n",
            "          [-6.7465e-01, -8.6785e-01, -5.5906e-01,  ..., -1.7477e+00,\n",
            "           -1.4651e-01, -8.8794e-02]],\n",
            "\n",
            "         [[-8.1506e-02,  1.3176e-01, -1.7452e-01,  ...,  6.9942e-02,\n",
            "           -5.0928e-01,  2.0620e-01],\n",
            "          [ 1.4995e-02,  3.4482e-02,  8.2729e-02,  ..., -4.0882e-02,\n",
            "           -7.5127e-02, -3.1352e-02],\n",
            "          [ 1.3393e-01,  1.2419e+00, -3.3312e-01,  ...,  1.4409e+00,\n",
            "           -5.9392e-01,  1.3956e-01],\n",
            "          ...,\n",
            "          [ 2.5079e-01,  5.0490e-01,  6.0631e-01,  ...,  5.6850e-01,\n",
            "           -1.6322e+00, -6.2284e-01],\n",
            "          [ 5.2768e-01,  4.4116e-01,  8.9130e-01,  ..., -2.1340e-01,\n",
            "           -1.6273e+00,  5.4829e-01],\n",
            "          [ 4.0553e-01,  1.9085e-01, -1.0060e-01,  ...,  6.5918e-01,\n",
            "            2.2738e-01, -1.1850e-01]]]]))), hidden_states=None, attentions=None)\n"
          ]
        }
      ],
      "source": [
        "# Load the fine-tuned model and tokenizer\n",
        "model = AutoModel.from_pretrained('./tdp_stablelm2_ft')\n",
        "tokenizer = AutoTokenizer.from_pretrained('./tdp_stablelm2_ft')\n",
        "\n",
        "# Test the tokenizer and model (example sentence)\n",
        "input_text = \"This is a test input for my fine-tuned model.\"\n",
        "inputs = tokenizer(input_text, return_tensors='pt')\n",
        "\n",
        "# Perform forward pass through the model\n",
        "outputs = model(**inputs)\n",
        "\n",
        "# Print the model's output (you can process this further based on the model type)\n",
        "print(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRAUF_Vn6Kjz"
      },
      "source": [
        "### Testing the Fine-Tined Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRjlZHh355EJ"
      },
      "outputs": [],
      "source": [
        "# # Load the model for causal language modeling (if applicable)\n",
        "# model = AutoModelForCausalLM.from_pretrained('./tdp_stablelm2_ft')\n",
        "# tokenizer = AutoTokenizer.from_pretrained('./tdp_stablelm2_ft')\n",
        "\n",
        "# # Tokenize your input for generation\n",
        "# input_ids = tokenizer.encode(\"What products are offered at UOB?\", return_tensors='pt')\n",
        "\n",
        "# # Generate text\n",
        "# generated_output = model.generate(input_ids, max_length=200)\n",
        "\n",
        "# # Decode the generated text\n",
        "# generated_text = tokenizer.decode(generated_output[0], skip_special_tokens=True)\n",
        "\n",
        "# print(generated_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwkMQWhfLs46"
      },
      "source": [
        "### Reload the tokenizer and model\n",
        "\n",
        "Over here, we are going to reload the full floating point fp16 model (not the quantized version as defined above). Next, we will merge the adapter that we have trained and stored in the llm-adapter folder, with the model that we just loaded to output our finalised fine-tuned model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ybQmt2ANLy2z"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"stabilityai/stablelm-2-1_6b\")\n",
        "fp16_model = AutoModelForCausalLM.from_pretrained(\n",
        "  \"stabilityai/stablelm-2-1_6b\",\n",
        "  low_cpu_mem_usage=True,\n",
        "  return_dict=True,\n",
        "  torch_dtype=torch.float16,\n",
        "  device_map=\"auto\",\n",
        ")\n",
        "\n",
        "model = PeftModel.from_pretrained(fp16_model, \"/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/fine-tuned/tdp_stablelm2_ft\")\n",
        "model = model.merge_and_unload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXrRelB9PlLk"
      },
      "source": [
        "After merging the LoRA adapter, we will save the final model and tokenizer in a new directory to prepare for gguf conversion\n",
        "\n",
        "If the runtime and computational resources are being used to run the above code, skip this line and go straight to tehe GGUF / llama.cpp conversion since our model and tokenizers are alreay saved in the path below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG0KLhyHPuc7",
        "outputId": "8c2549f9-a34c-4245-c270-86a35d9f6969"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/tdp_stablelm2_ft_merged/tokenizer_config.json',\n",
              " '/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/tdp_stablelm2_ft_merged/special_tokens_map.json',\n",
              " '/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/tdp_stablelm2_ft_merged/vocab.json',\n",
              " '/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/tdp_stablelm2_ft_merged/merges.txt',\n",
              " '/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/tdp_stablelm2_ft_merged/added_tokens.json',\n",
              " '/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/tdp_stablelm2_ft_merged/tokenizer.json')"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "saved_path = '/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/tdp_stablelm2_ft_merged'\n",
        "\n",
        "model.save_pretrained(saved_path)\n",
        "tokenizer.save_pretrained(saved_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYD45CgRNrzb"
      },
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "We need to build the llama.cpp in order to use the conversion tools. Do allocate time for this as it took on average 48mins to run!!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzceA-nc6Y1r",
        "outputId": "96dc0d86-a3d0-4e8a-a351-4e999f343689"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'llama.cpp'...\n",
            "remote: Enumerating objects: 34952, done.\u001b[K\n",
            "remote: Counting objects: 100% (9117/9117), done.\u001b[K\n",
            "remote: Compressing objects: 100% (595/595), done.\u001b[K\n",
            "remote: Total 34952 (delta 8829), reused 8571 (delta 8520), pack-reused 25835 (from 1)\u001b[K\n",
            "Receiving objects: 100% (34952/34952), 57.84 MiB | 13.45 MiB/s, done.\n",
            "Resolving deltas: 100% (25427/25427), done.\n",
            "Already up to date.\n",
            "I ccache not found. Consider installing it for faster compilation.\n",
            "I llama.cpp build info: \n",
            "I UNAME_S:   Linux\n",
            "I UNAME_P:   x86_64\n",
            "I UNAME_M:   x86_64\n",
            "I CFLAGS:    -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE  -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion \n",
            "I CXXFLAGS:  -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE \n",
            "I NVCCFLAGS: -std=c++11 -O3 -g \n",
            "I LDFLAGS:    \n",
            "I CC:        cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "I CXX:       c++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "\n",
            "rm -vrf *.dot libllava.a llama-baby-llama llama-batched llama-batched-bench llama-bench llama-benchmark-matmult llama-cli llama-convert-llama2c-to-ggml llama-embedding llama-eval-callback llama-export-lora llama-gbnf-validator llama-gguf llama-gguf-hash llama-gguf-split llama-gritlm llama-imatrix llama-infill llama-llava-cli llama-minicpmv-cli llama-lookahead llama-lookup llama-lookup-create llama-lookup-merge llama-lookup-stats llama-parallel llama-passkey llama-perplexity llama-q8dot llama-quantize llama-quantize-stats llama-retrieval llama-save-load-state llama-server llama-simple llama-speculative llama-tokenize llama-vdot llama-cvector-generator llama-gen-docs tests/test-c.o tests/test-arg-parser tests/test-autorelease tests/test-backend-ops tests/test-chat-template tests/test-double-float tests/test-grad0 tests/test-grammar-integration tests/test-grammar-parser tests/test-json-schema-to-grammar tests/test-llama-grammar tests/test-log tests/test-model-load-cancel tests/test-opt tests/test-quantize-fns tests/test-quantize-perf tests/test-rope tests/test-sampling tests/test-tokenizer-0 tests/test-tokenizer-1-bpe tests/test-tokenizer-1-spm\n",
            "rm -rvf src/*.o\n",
            "rm -rvf tests/*.o\n",
            "rm -rvf examples/*.o\n",
            "rm -rvf common/*.o\n",
            "rm -rvf *.a\n",
            "rm -rvf *.dll\n",
            "rm -rvf *.so\n",
            "rm -rvf *.dot\n",
            "rm -rvf ggml/*.a\n",
            "rm -rvf ggml/*.dll\n",
            "rm -rvf ggml/*.so\n",
            "rm -vrf ggml/src/*.o\n",
            "rm -rvf ggml/src/llamafile/*.o\n",
            "rm -rvf common/build-info.cpp\n",
            "rm -vrf ggml/src/ggml-metal-embed.metal\n",
            "rm -vrf ggml/src/ggml-cuda/*.o\n",
            "rm -vrf ggml/src/ggml-cuda/template-instances/*.o\n",
            "rm -rvf libllava.a llama-baby-llama llama-batched llama-batched-bench llama-bench llama-benchmark-matmult llama-cli llama-convert-llama2c-to-ggml llama-embedding llama-eval-callback llama-export-lora llama-gbnf-validator llama-gguf llama-gguf-hash llama-gguf-split llama-gritlm llama-imatrix llama-infill llama-llava-cli llama-minicpmv-cli llama-lookahead llama-lookup llama-lookup-create llama-lookup-merge llama-lookup-stats llama-parallel llama-passkey llama-perplexity llama-q8dot llama-quantize llama-quantize-stats llama-retrieval llama-save-load-state llama-server llama-simple llama-speculative llama-tokenize llama-vdot llama-cvector-generator llama-gen-docs tests/test-c.o\n",
            "rm -rvf tests/test-arg-parser tests/test-autorelease tests/test-backend-ops tests/test-chat-template tests/test-double-float tests/test-grad0 tests/test-grammar-integration tests/test-grammar-parser tests/test-json-schema-to-grammar tests/test-llama-grammar tests/test-log tests/test-model-load-cancel tests/test-opt tests/test-quantize-fns tests/test-quantize-perf tests/test-rope tests/test-sampling tests/test-tokenizer-0 tests/test-tokenizer-1-bpe tests/test-tokenizer-1-spm\n",
            "rm -f vulkan-shaders-gen ggml/src/ggml-vulkan-shaders.hpp ggml/src/ggml-vulkan-shaders.cpp\n",
            "rm -rvf main quantize quantize-stats perplexity imatrix embedding vdot q8dot convert-llama2c-to-ggml simple batched batched-bench save-load-state server gguf gguf-split eval-callback llama-bench libllava.a llava-cli baby-llama retrieval speculative infill tokenize benchmark-matmult parallel export-lora lookahead lookup passkey gritlm\n",
            "find examples pocs -type f -name \"*.o\" -delete\n",
            "I ccache not found. Consider installing it for faster compilation.\n",
            "I llama.cpp build info: \n",
            "I UNAME_S:   Linux\n",
            "I UNAME_P:   x86_64\n",
            "I UNAME_M:   x86_64\n",
            "I CFLAGS:    -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion \n",
            "I CXXFLAGS:  -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include \n",
            "I NVCCFLAGS: -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 \n",
            "I LDFLAGS:   -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "I CC:        cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "I CXX:       c++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "I NVCC:      Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "\n",
            "!!! DEPRECATION WARNING !!!\n",
            "The following LLAMA_ options are deprecated and will be removed in the future. Use the GGML_ prefix instead\n",
            "- LLAMA_CUDA\n",
            "- LLAMA_METAL\n",
            "- LLAMA_METAL_EMBED_LIBRARY\n",
            "- LLAMA_OPENMP\n",
            "- LLAMA_RPC\n",
            "- LLAMA_SYCL\n",
            "- LLAMA_SYCL_F16\n",
            "- LLAMA_OPENBLAS\n",
            "- LLAMA_OPENBLAS64\n",
            "- LLAMA_BLIS\n",
            "- LLAMA_NO_LLAMAFILE\n",
            "- LLAMA_NO_ACCELERATE\n",
            "- LLAMA_NO_OPENMP\n",
            "- LLAMA_NO_METAL\n",
            "- LLAMA_NO_CCACHE\n",
            "\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c ggml/src/llamafile/sgemm.cpp -o ggml/src/llamafile/sgemm.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda.cu -o ggml/src/ggml-cuda.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/acc.cu -o ggml/src/ggml-cuda/acc.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/arange.cu -o ggml/src/ggml-cuda/arange.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/argsort.cu -o ggml/src/ggml-cuda/argsort.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/binbcast.cu -o ggml/src/ggml-cuda/binbcast.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/clamp.cu -o ggml/src/ggml-cuda/clamp.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/concat.cu -o ggml/src/ggml-cuda/concat.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/convert.cu -o ggml/src/ggml-cuda/convert.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/conv-transpose-1d.cu -o ggml/src/ggml-cuda/conv-transpose-1d.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/cpy.cu -o ggml/src/ggml-cuda/cpy.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/cross-entropy-loss.cu -o ggml/src/ggml-cuda/cross-entropy-loss.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/diagmask.cu -o ggml/src/ggml-cuda/diagmask.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/dmmv.cu -o ggml/src/ggml-cuda/dmmv.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/fattn.cu -o ggml/src/ggml-cuda/fattn.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/fattn-tile-f16.cu -o ggml/src/ggml-cuda/fattn-tile-f16.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/fattn-tile-f32.cu -o ggml/src/ggml-cuda/fattn-tile-f32.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/getrows.cu -o ggml/src/ggml-cuda/getrows.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/im2col.cu -o ggml/src/ggml-cuda/im2col.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/mmq.cu -o ggml/src/ggml-cuda/mmq.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/mmvq.cu -o ggml/src/ggml-cuda/mmvq.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/norm.cu -o ggml/src/ggml-cuda/norm.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/opt-step-adamw.cu -o ggml/src/ggml-cuda/opt-step-adamw.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/out-prod.cu -o ggml/src/ggml-cuda/out-prod.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/pad.cu -o ggml/src/ggml-cuda/pad.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/pool2d.cu -o ggml/src/ggml-cuda/pool2d.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/quantize.cu -o ggml/src/ggml-cuda/quantize.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/rope.cu -o ggml/src/ggml-cuda/rope.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/rwkv-wkv.cu -o ggml/src/ggml-cuda/rwkv-wkv.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/scale.cu -o ggml/src/ggml-cuda/scale.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/softmax.cu -o ggml/src/ggml-cuda/softmax.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/sum.cu -o ggml/src/ggml-cuda/sum.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cub/util_arch.cuh:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/cub/config.cuh:35\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/cub/cub.cuh:37\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kggml/src/ggml-cuda/sum.cu:8\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/cub/util_cpp_dialect.cuh:142:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KCUB requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define CUB_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  142 |      CUB_COM\u001b[01;35m\u001b[KPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                        \n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/thrust/detail/config/config.h:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/thrust/detail/config.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/thrust/type_traits/integer_sequence.h:25\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/cub/block/specializations/../../block/../block/radix_rank_sort_operations.cuh:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/cub/block/specializations/../../block/block_radix_rank.cuh:41\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/cub/block/specializations/../../block/block_radix_sort.cuh:38\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/cub/block/specializations/block_histogram_sort.cuh:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/cub/block/block_histogram.cuh:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/cub/cub.cuh:43\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kggml/src/ggml-cuda/sum.cu:8\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/thrust/detail/config/cpp_dialect.h:131:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KThrust requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define THRUST_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  131 |      THRUST_\u001b[01;35m\u001b[KCOMPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                           \n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cub/util_arch.cuh:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/cub/config.cuh:35\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/cub/cub.cuh:37\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kggml/src/ggml-cuda/sum.cu:8\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/cub/util_cpp_dialect.cuh:142:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KCUB requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define CUB_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  142 |      CUB_COM\u001b[01;35m\u001b[KPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                        \n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/thrust/detail/config/config.h:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/thrust/detail/config.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/thrust/type_traits/integer_sequence.h:25\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/cub/block/specializations/../../block/../block/radix_rank_sort_operations.cuh:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/cub/block/specializations/../../block/block_radix_rank.cuh:41\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/cub/block/specializations/../../block/block_radix_sort.cuh:38\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/cub/block/specializations/block_histogram_sort.cuh:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/cub/block/block_histogram.cuh:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/cub/cub.cuh:43\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kggml/src/ggml-cuda/sum.cu:8\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/thrust/detail/config/cpp_dialect.h:131:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KThrust requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define THRUST_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  131 |      THRUST_\u001b[01;35m\u001b[KCOMPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                           \n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/sumrows.cu -o ggml/src/ggml-cuda/sumrows.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/tsembd.cu -o ggml/src/ggml-cuda/tsembd.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/unary.cu -o ggml/src/ggml-cuda/unary.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/upscale.cu -o ggml/src/ggml-cuda/upscale.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.cu -o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.cu -o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.cu -o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.cu -o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.cu -o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.cu -o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.cu -o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.cu -o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.cu -o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.cu -o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.cu -o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.cu -o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.cu -o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.cu -o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.cu -o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.cu -o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.cu -o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.cu -o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.cu -o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.cu -o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.cu -o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.cu -o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.cu -o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu -o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu -o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu -o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu -o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu -o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu -o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu -o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu -o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu -o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o\n",
            "nvcc -std=c++11 -O3 -g -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu -o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o\n",
            "cc  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion    -c ggml/src/ggml.c -o ggml/src/ggml.o\n",
            "cc  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion    -c ggml/src/ggml-alloc.c -o ggml/src/ggml-alloc.o\n",
            "cc  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion    -c ggml/src/ggml-backend.c -o ggml/src/ggml-backend.o\n",
            "cc -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion     -c ggml/src/ggml-quants.c -o ggml/src/ggml-quants.o\n",
            "cc -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion     -c ggml/src/ggml-aarch64.c -o ggml/src/ggml-aarch64.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c src/llama.cpp -o src/llama.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c src/llama-vocab.cpp -o src/llama-vocab.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c src/llama-grammar.cpp -o src/llama-grammar.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c src/llama-sampling.cpp -o src/llama-sampling.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c src/unicode.cpp -o src/unicode.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c src/unicode-data.cpp -o src/unicode-data.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c common/common.cpp -o common/common.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c common/arg.cpp -o common/arg.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c common/log.cpp -o common/log.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c common/console.cpp -o common/console.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c common/ngram-cache.cpp -o common/ngram-cache.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c common/sampling.cpp -o common/sampling.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c common/train.cpp -o common/train.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c common/build-info.cpp -o common/build-info.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c common/json-schema-to-grammar.cpp -o common/json-schema-to-grammar.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -static -fPIC -c examples/llava/llava.cpp -o libllava.a -Wno-cast-qual\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/baby-llama/baby-llama.cpp -o examples/baby-llama/baby-llama.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/baby-llama/baby-llama.o -o llama-baby-llama -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/batched/batched.cpp -o examples/batched/batched.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/batched/batched.o -o llama-batched -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/batched-bench/batched-bench.cpp -o examples/batched-bench/batched-bench.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/batched-bench/batched-bench.o -o llama-batched-bench -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/llama-bench/llama-bench.cpp -o examples/llama-bench/llama-bench.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/llama-bench/llama-bench.o -o llama-bench -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/benchmark/benchmark-matmult.cpp -o examples/benchmark/benchmark-matmult.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o common/build-info.o examples/benchmark/benchmark-matmult.o -o llama-benchmark-matmult -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/main/main.cpp -o examples/main/main.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/main/main.o -o llama-cli -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "\n",
            "====  Run ./llama-cli -h for help.  ====\n",
            "\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/convert-llama2c-to-ggml/convert-llama2c-to-ggml.cpp -o examples/convert-llama2c-to-ggml/convert-llama2c-to-ggml.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/convert-llama2c-to-ggml/convert-llama2c-to-ggml.o -o llama-convert-llama2c-to-ggml -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/embedding/embedding.cpp -o examples/embedding/embedding.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/embedding/embedding.o -o llama-embedding -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/eval-callback/eval-callback.cpp -o examples/eval-callback/eval-callback.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/eval-callback/eval-callback.o -o llama-eval-callback -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/export-lora/export-lora.cpp -o examples/export-lora/export-lora.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/export-lora/export-lora.o -o llama-export-lora -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/gbnf-validator/gbnf-validator.cpp -o examples/gbnf-validator/gbnf-validator.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/gbnf-validator/gbnf-validator.o -o llama-gbnf-validator -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/gguf/gguf.cpp -o examples/gguf/gguf.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o examples/gguf/gguf.o -o llama-gguf -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "cc -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion  -Iexamples/gguf-hash/deps -c examples/gguf-hash/deps/sha1/sha1.c -o examples/gguf-hash/deps/sha1/sha1.o\n",
            "cc -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion  -Iexamples/gguf-hash/deps -c examples/gguf-hash/deps/xxhash/xxhash.c -o examples/gguf-hash/deps/xxhash/xxhash.o\n",
            "cc -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion  -Iexamples/gguf-hash/deps -c examples/gguf-hash/deps/sha256/sha256.c -o examples/gguf-hash/deps/sha256/sha256.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Iexamples/gguf-hash/deps -c examples/gguf-hash/gguf-hash.cpp -o examples/gguf-hash/gguf-hash.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  examples/gguf-hash/deps/sha1/sha1.o examples/gguf-hash/deps/xxhash/xxhash.o examples/gguf-hash/deps/sha256/sha256.o ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/gguf-hash/gguf-hash.o -o llama-gguf-hash -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/gguf-split/gguf-split.cpp -o examples/gguf-split/gguf-split.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/gguf-split/gguf-split.o -o llama-gguf-split -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/gritlm/gritlm.cpp -o examples/gritlm/gritlm.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/gritlm/gritlm.o -o llama-gritlm -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/imatrix/imatrix.cpp -o examples/imatrix/imatrix.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/imatrix/imatrix.o -o llama-imatrix -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/infill/infill.cpp -o examples/infill/infill.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/infill/infill.o -o llama-infill -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  examples/llava/llava-cli.cpp examples/llava/llava.cpp examples/llava/clip.cpp ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o -o llama-llava-cli -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib  -Wno-cast-qual\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  examples/llava/minicpmv-cli.cpp examples/llava/llava.cpp examples/llava/clip.cpp ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o -o llama-minicpmv-cli -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib  -Wno-cast-qual\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/lookahead/lookahead.cpp -o examples/lookahead/lookahead.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/lookahead/lookahead.o -o llama-lookahead -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/lookup/lookup.cpp -o examples/lookup/lookup.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/lookup/lookup.o -o llama-lookup -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/lookup/lookup-create.cpp -o examples/lookup/lookup-create.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/lookup/lookup-create.o -o llama-lookup-create -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/lookup/lookup-merge.cpp -o examples/lookup/lookup-merge.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/lookup/lookup-merge.o -o llama-lookup-merge -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/lookup/lookup-stats.cpp -o examples/lookup/lookup-stats.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/lookup/lookup-stats.o -o llama-lookup-stats -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/parallel/parallel.cpp -o examples/parallel/parallel.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/parallel/parallel.o -o llama-parallel -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/passkey/passkey.cpp -o examples/passkey/passkey.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/passkey/passkey.o -o llama-passkey -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/perplexity/perplexity.cpp -o examples/perplexity/perplexity.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/perplexity/perplexity.o -o llama-perplexity -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c pocs/vdot/q8dot.cpp -o pocs/vdot/q8dot.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/ggml.o ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o pocs/vdot/q8dot.o -o llama-q8dot -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/quantize/quantize.cpp -o examples/quantize/quantize.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/quantize/quantize.o -o llama-quantize -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/quantize-stats/quantize-stats.cpp -o examples/quantize-stats/quantize-stats.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/quantize-stats/quantize-stats.o -o llama-quantize-stats -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/retrieval/retrieval.cpp -o examples/retrieval/retrieval.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/retrieval/retrieval.o -o llama-retrieval -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/save-load-state/save-load-state.cpp -o examples/save-load-state/save-load-state.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/save-load-state/save-load-state.o -o llama-save-load-state -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/server/server.cpp -o examples/server/server.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o -Iexamples/server examples/server/server.o -o llama-server -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib  \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/simple/simple.cpp -o examples/simple/simple.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/simple/simple.o -o llama-simple -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/speculative/speculative.cpp -o examples/speculative/speculative.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/speculative/speculative.o -o llama-speculative -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/tokenize/tokenize.cpp -o examples/tokenize/tokenize.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/tokenize/tokenize.o -o llama-tokenize -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c pocs/vdot/vdot.cpp -o pocs/vdot/vdot.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/ggml.o ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o pocs/vdot/vdot.o -o llama-vdot -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/cvector-generator/cvector-generator.cpp -o examples/cvector-generator/cvector-generator.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/cvector-generator/cvector-generator.o -o llama-cvector-generator -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/gen-docs/gen-docs.cpp -o examples/gen-docs/gen-docs.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/gen-docs/gen-docs.o -o llama-gen-docs -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "cc -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion  -c tests/test-c.c -o tests/test-c.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/deprecation-warning/deprecation-warning.cpp -o examples/deprecation-warning/deprecation-warning.o\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  examples/deprecation-warning/deprecation-warning.o -o main -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "NOTICE: The 'main' binary is deprecated. Please use 'llama-cli' instead.\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  examples/deprecation-warning/deprecation-warning.o -o server -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/wsl/lib \n",
            "NOTICE: The 'server' binary is deprecated. Please use 'llama-server' instead.\n"
          ]
        }
      ],
      "source": [
        "# Command took on average 48mins to run!!!!\n",
        "!git clone https://github.com/ggerganov/llama.cpp\n",
        "!cd llama.cpp && git pull && make clean && LLAMA_CUDA=1 make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zVYFzclDRu7_",
        "outputId": "8da7e1da-f97f-4585-a6f6-2e1ad17ff829"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: numpy~=1.26.4 in /usr/local/lib/python3.10/dist-packages (from -r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: sentencepiece~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 2)) (0.2.0)\n",
            "Collecting transformers<5.0.0,>=4.45.1 (from -r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3))\n",
            "  Downloading transformers-4.45.1-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gguf>=0.1.0 (from -r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 4))\n",
            "  Downloading gguf-0.10.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting protobuf<5.0.0,>=4.21.0 (from -r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 5))\n",
            "  Downloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting torch~=2.2.1 (from -r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3))\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torch-2.2.2%2Bcpu-cp310-cp310-linux_x86_64.whl (186.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.8/186.8 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.45.1->-r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.45.1->-r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (0.24.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.45.1->-r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.45.1->-r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.45.1->-r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.45.1->-r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.45.1->-r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (0.4.5)\n",
            "Collecting tokenizers<0.21,>=0.20 (from transformers<5.0.0,>=4.45.1->-r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3))\n",
            "  Downloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.45.1->-r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch~=2.2.1->-r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch~=2.2.1->-r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch~=2.2.1->-r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch~=2.2.1->-r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch~=2.2.1->-r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch~=2.2.1->-r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.45.1->-r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.45.1->-r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.45.1->-r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.45.1->-r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch~=2.2.1->-r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (1.3.0)\n",
            "Downloading transformers-4.45.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gguf-0.10.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, gguf, torch, tokenizers, transformers\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.4.1+cu121\n",
            "    Uninstalling torch-2.4.1+cu121:\n",
            "      Successfully uninstalled torch-2.4.1+cu121\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.44.2\n",
            "    Uninstalling transformers-4.44.2:\n",
            "      Successfully uninstalled transformers-4.44.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "optimum 1.22.0 requires transformers[sentencepiece]<4.45.0,>=4.29, but you have transformers 4.45.1 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.5 which is incompatible.\n",
            "torchaudio 2.4.1+cu121 requires torch==2.4.1, but you have torch 2.2.2+cpu which is incompatible.\n",
            "torchvision 0.19.1+cu121 requires torch==2.4.1, but you have torch 2.2.2+cpu which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gguf-0.10.0 protobuf-4.25.5 tokenizers-0.20.0 torch-2.2.2+cpu transformers-4.45.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "98faa8b291f84ca1a55356f82fe81ced",
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen",
                  "transformers"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Install the requirements\n",
        "!pip3 install -r llama.cpp/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6TegpvqSAc0"
      },
      "source": [
        "We are running the actual conversion over here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzJImCwEXfW4"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQXxCX4ZSEIE",
        "outputId": "a2c55fef-f8b9-4db8-a0da-5852e0c58754"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:hf-to-gguf:Loading model: tdp_stablelm2_ft_merged\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model.safetensors'\n",
            "INFO:hf-to-gguf:output.weight,             torch.float16 --> F16, shape = {2048, 100352}\n",
            "INFO:hf-to-gguf:token_embd.weight,         torch.float16 --> F16, shape = {2048, 100352}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.bias,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,     torch.float16 --> F16, shape = {5632, 2048}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,     torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,       torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.bias,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,  torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.bias,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,     torch.float16 --> F16, shape = {5632, 2048}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,     torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,       torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.bias,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,  torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.bias,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,   torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,    torch.float16 --> F16, shape = {5632, 2048}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,    torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,      torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.bias,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight, torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.bias,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,   torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,    torch.float16 --> F16, shape = {5632, 2048}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,    torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,      torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.bias,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight, torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.bias,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,   torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,    torch.float16 --> F16, shape = {5632, 2048}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,    torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,      torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.bias,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight, torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.bias,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,   torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,    torch.float16 --> F16, shape = {5632, 2048}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,    torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,      torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.bias,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight, torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.bias,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,   torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,    torch.float16 --> F16, shape = {5632, 2048}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,    torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,      torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.bias,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight, torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.bias,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,   torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,    torch.float16 --> F16, shape = {5632, 2048}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,    torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,      torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.bias,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight, torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.bias,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,   torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,    torch.float16 --> F16, shape = {5632, 2048}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,    torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,      torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.bias,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight, torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.bias,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,   torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,    torch.float16 --> F16, shape = {5632, 2048}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,    torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,      torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.bias,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight, torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.bias,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,   torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,    torch.float16 --> F16, shape = {5632, 2048}\n",
            "INFO:hf-to-gguf:blk.18.ffn_gate.weight,    torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,      torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.bias,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight, torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.bias,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,   torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,    torch.float16 --> F16, shape = {5632, 2048}\n",
            "INFO:hf-to-gguf:blk.19.ffn_gate.weight,    torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,      torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.bias,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight, torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.bias,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,     torch.float16 --> F16, shape = {5632, 2048}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,     torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,       torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.bias,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,  torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.bias,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,   torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,    torch.float16 --> F16, shape = {5632, 2048}\n",
            "INFO:hf-to-gguf:blk.20.ffn_gate.weight,    torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,      torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.bias,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight, torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.bias,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,   torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,    torch.float16 --> F16, shape = {5632, 2048}\n",
            "INFO:hf-to-gguf:blk.21.ffn_gate.weight,    torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,      torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.bias,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight, torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.bias,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,   torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,    torch.float16 --> F16, shape = {5632, 2048}\n",
            "INFO:hf-to-gguf:blk.22.ffn_gate.weight,    torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,      torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.bias,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight, torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.bias,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,   torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,    torch.float16 --> F16, shape = {5632, 2048}\n",
            "INFO:hf-to-gguf:blk.23.ffn_gate.weight,    torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,      torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.bias,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight, torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.bias,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.weight,      torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.bias,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,     torch.float16 --> F16, shape = {5632, 2048}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,     torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,       torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.bias,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,  torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.bias,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,     torch.float16 --> F16, shape = {5632, 2048}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,     torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,       torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.bias,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,  torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.bias,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,     torch.float16 --> F16, shape = {5632, 2048}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,     torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,       torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.bias,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,  torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.bias,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,     torch.float16 --> F16, shape = {5632, 2048}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,     torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,       torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.bias,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,  torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.bias,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,     torch.float16 --> F16, shape = {5632, 2048}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,     torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,       torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.bias,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,  torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.bias,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,     torch.float16 --> F16, shape = {5632, 2048}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,     torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,       torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.bias,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,  torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.bias,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,    torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,     torch.float16 --> F16, shape = {5632, 2048}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,     torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,       torch.float16 --> F16, shape = {2048, 5632}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.bias,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,  torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.bias,         torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,       torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:output_norm.bias,          torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:output_norm.weight,        torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:gguf.vocab:Adding 100000 merge(s).\n",
            "INFO:gguf.vocab:Setting special token type bos to 100257\n",
            "INFO:gguf.vocab:Setting special token type eos to 100257\n",
            "INFO:gguf.vocab:Setting special token type unk to 100257\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/tdp_stablelm2_ft_merged/stablelm-2-1.6B-F16.gguf: n_tensors = 340, total_size = 3.3G\n",
            "Writing: 100% 3.29G/3.29G [00:43<00:00, 76.4Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to /content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/tdp_stablelm2_ft_merged/stablelm-2-1.6B-F16.gguf\n"
          ]
        }
      ],
      "source": [
        "!python llama.cpp/convert_hf_to_gguf.py \"/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/tdp_stablelm2_ft_merged\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiNq1hLXuM3P",
        "outputId": "50753b87-3f72-413f-fdf1-889cc55485c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['config.json',\n",
              " 'generation_config.json',\n",
              " 'model.safetensors',\n",
              " 'tokenizer_config.json',\n",
              " 'special_tokens_map.json',\n",
              " 'vocab.json',\n",
              " 'merges.txt',\n",
              " 'tokenizer.json',\n",
              " 'stablelm-2-1.6B-F16.gguf',\n",
              " 'ggml-model-Q4_K_M.gguf']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir(\"/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/tdp_stablelm2_ft_merged\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF9sl8j1YR2x"
      },
      "source": [
        "#### Quantization\n",
        "\n",
        "Llama.cpp gives us a ton of quantization options. Here's a couple resources to dive deeper into which options are available. We will use the Q4_K_M format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvNtIHkdSmKk",
        "outputId": "b83c1a8c-d3d5-4c9f-c3fa-a4c7b41bd154"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "main: build = 3861 (f1b8c427)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/tdp_stablelm2_ft_merged/stablelm-2-1.6B-F16.gguf' to '/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/tdp_stablelm2_ft_merged/ggml-model-Q4_K_M.gguf' as Q4_K_M\n",
            "llama_model_loader: loaded meta data with 25 key-value pairs and 340 tensors from /content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/tdp_stablelm2_ft_merged/stablelm-2-1.6B-F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = stablelm\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Stablelm 2 1_6b\n",
            "llama_model_loader: - kv   3:                       general.organization str              = Stabilityai\n",
            "llama_model_loader: - kv   4:                           general.basename str              = stablelm-2\n",
            "llama_model_loader: - kv   5:                         general.size_label str              = 1.6B\n",
            "llama_model_loader: - kv   6:                    stablelm.context_length u32              = 4096\n",
            "llama_model_loader: - kv   7:                  stablelm.embedding_length u32              = 2048\n",
            "llama_model_loader: - kv   8:                       stablelm.block_count u32              = 24\n",
            "llama_model_loader: - kv   9:               stablelm.feed_forward_length u32              = 5632\n",
            "llama_model_loader: - kv  10:              stablelm.rope.dimension_count u32              = 16\n",
            "llama_model_loader: - kv  11:              stablelm.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv  12:           stablelm.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv  13:             stablelm.use_parallel_residual bool             = false\n",
            "llama_model_loader: - kv  14:      stablelm.attention.layer_norm_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  15:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  16:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  17:                         tokenizer.ggml.pre str              = stablelm2\n",
            "llama_model_loader: - kv  18:                      tokenizer.ggml.tokens arr[str,100352]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  19:                  tokenizer.ggml.token_type arr[i32,100352]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  20:                      tokenizer.ggml.merges arr[str,100000]  = [\"Ġ Ġ\", \"ĠĠ ĠĠ\", \"i n\", \"Ġ t\",...\n",
            "llama_model_loader: - kv  21:                tokenizer.ggml.bos_token_id u32              = 100257\n",
            "llama_model_loader: - kv  22:                tokenizer.ggml.eos_token_id u32              = 100257\n",
            "llama_model_loader: - kv  23:            tokenizer.ggml.unknown_token_id u32              = 100257\n",
            "llama_model_loader: - kv  24:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:  170 tensors\n",
            "llama_model_loader: - type  f16:  170 tensors\n",
            "[   1/ 340]                        output.weight - [ 2048, 100352,     1,     1], type =    f16, converting to q6_K .. size =   392.00 MiB ->   160.78 MiB\n",
            "[   2/ 340]                    token_embd.weight - [ 2048, 100352,     1,     1], type =    f16, converting to q4_K .. size =   392.00 MiB ->   110.25 MiB\n",
            "[   3/ 340]                 blk.0.attn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[   4/ 340]               blk.0.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[   5/ 340]                blk.0.ffn_down.weight - [ 5632,  2048,     1,     1], type =    f16, converting to q6_K .. size =    22.00 MiB ->     9.02 MiB\n",
            "[   6/ 340]                blk.0.ffn_gate.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[   7/ 340]                  blk.0.ffn_up.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[   8/ 340]                  blk.0.ffn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[   9/ 340]                blk.0.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  10/ 340]                    blk.0.attn_k.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  11/ 340]                  blk.0.attn_k.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  12/ 340]             blk.0.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  13/ 340]                    blk.0.attn_q.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  14/ 340]                  blk.0.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  15/ 340]                    blk.0.attn_v.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  16/ 340]                  blk.0.attn_v.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  17/ 340]                 blk.1.attn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  18/ 340]               blk.1.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  19/ 340]                blk.1.ffn_down.weight - [ 5632,  2048,     1,     1], type =    f16, converting to q6_K .. size =    22.00 MiB ->     9.02 MiB\n",
            "[  20/ 340]                blk.1.ffn_gate.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[  21/ 340]                  blk.1.ffn_up.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[  22/ 340]                  blk.1.ffn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  23/ 340]                blk.1.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  24/ 340]                    blk.1.attn_k.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  25/ 340]                  blk.1.attn_k.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  26/ 340]             blk.1.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  27/ 340]                    blk.1.attn_q.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  28/ 340]                  blk.1.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  29/ 340]                    blk.1.attn_v.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  30/ 340]                  blk.1.attn_v.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  31/ 340]                blk.10.attn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  32/ 340]              blk.10.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  33/ 340]               blk.10.ffn_down.weight - [ 5632,  2048,     1,     1], type =    f16, converting to q6_K .. size =    22.00 MiB ->     9.02 MiB\n",
            "[  34/ 340]               blk.10.ffn_gate.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[  35/ 340]                 blk.10.ffn_up.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[  36/ 340]                 blk.10.ffn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  37/ 340]               blk.10.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  38/ 340]                   blk.10.attn_k.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  39/ 340]                 blk.10.attn_k.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  40/ 340]            blk.10.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  41/ 340]                   blk.10.attn_q.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  42/ 340]                 blk.10.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  43/ 340]                   blk.10.attn_v.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  44/ 340]                 blk.10.attn_v.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  45/ 340]                blk.11.attn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  46/ 340]              blk.11.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  47/ 340]               blk.11.ffn_down.weight - [ 5632,  2048,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[  48/ 340]               blk.11.ffn_gate.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[  49/ 340]                 blk.11.ffn_up.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[  50/ 340]                 blk.11.ffn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  51/ 340]               blk.11.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  52/ 340]                   blk.11.attn_k.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  53/ 340]                 blk.11.attn_k.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  54/ 340]            blk.11.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  55/ 340]                   blk.11.attn_q.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  56/ 340]                 blk.11.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  57/ 340]                   blk.11.attn_v.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  58/ 340]                 blk.11.attn_v.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  59/ 340]                blk.12.attn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  60/ 340]              blk.12.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  61/ 340]               blk.12.ffn_down.weight - [ 5632,  2048,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[  62/ 340]               blk.12.ffn_gate.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[  63/ 340]                 blk.12.ffn_up.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[  64/ 340]                 blk.12.ffn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  65/ 340]               blk.12.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  66/ 340]                   blk.12.attn_k.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  67/ 340]                 blk.12.attn_k.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  68/ 340]            blk.12.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  69/ 340]                   blk.12.attn_q.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  70/ 340]                 blk.12.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  71/ 340]                   blk.12.attn_v.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  72/ 340]                 blk.12.attn_v.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  73/ 340]                blk.13.attn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  74/ 340]              blk.13.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  75/ 340]               blk.13.ffn_down.weight - [ 5632,  2048,     1,     1], type =    f16, converting to q6_K .. size =    22.00 MiB ->     9.02 MiB\n",
            "[  76/ 340]               blk.13.ffn_gate.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[  77/ 340]                 blk.13.ffn_up.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[  78/ 340]                 blk.13.ffn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  79/ 340]               blk.13.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  80/ 340]                   blk.13.attn_k.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  81/ 340]                 blk.13.attn_k.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  82/ 340]            blk.13.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  83/ 340]                   blk.13.attn_q.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  84/ 340]                 blk.13.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  85/ 340]                   blk.13.attn_v.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  86/ 340]                 blk.13.attn_v.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  87/ 340]                blk.14.attn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  88/ 340]              blk.14.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  89/ 340]               blk.14.ffn_down.weight - [ 5632,  2048,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[  90/ 340]               blk.14.ffn_gate.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[  91/ 340]                 blk.14.ffn_up.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[  92/ 340]                 blk.14.ffn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  93/ 340]               blk.14.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  94/ 340]                   blk.14.attn_k.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  95/ 340]                 blk.14.attn_k.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  96/ 340]            blk.14.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  97/ 340]                   blk.14.attn_q.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  98/ 340]                 blk.14.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  99/ 340]                   blk.14.attn_v.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 100/ 340]                 blk.14.attn_v.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 101/ 340]                blk.15.attn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 102/ 340]              blk.15.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 103/ 340]               blk.15.ffn_down.weight - [ 5632,  2048,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 104/ 340]               blk.15.ffn_gate.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 105/ 340]                 blk.15.ffn_up.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 106/ 340]                 blk.15.ffn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 107/ 340]               blk.15.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 108/ 340]                   blk.15.attn_k.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 109/ 340]                 blk.15.attn_k.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 110/ 340]            blk.15.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 111/ 340]                   blk.15.attn_q.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 112/ 340]                 blk.15.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 113/ 340]                   blk.15.attn_v.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 114/ 340]                 blk.15.attn_v.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 115/ 340]                blk.16.attn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 116/ 340]              blk.16.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 117/ 340]               blk.16.ffn_down.weight - [ 5632,  2048,     1,     1], type =    f16, converting to q6_K .. size =    22.00 MiB ->     9.02 MiB\n",
            "[ 118/ 340]               blk.16.ffn_gate.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 119/ 340]                 blk.16.ffn_up.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 120/ 340]                 blk.16.ffn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 121/ 340]               blk.16.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 122/ 340]                   blk.16.attn_k.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 123/ 340]                 blk.16.attn_k.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 124/ 340]            blk.16.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 125/ 340]                   blk.16.attn_q.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 126/ 340]                 blk.16.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 127/ 340]                   blk.16.attn_v.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 128/ 340]                 blk.16.attn_v.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 129/ 340]                blk.17.attn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 130/ 340]              blk.17.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 131/ 340]               blk.17.ffn_down.weight - [ 5632,  2048,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 132/ 340]               blk.17.ffn_gate.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 133/ 340]                 blk.17.ffn_up.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 134/ 340]                 blk.17.ffn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 135/ 340]               blk.17.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 136/ 340]                   blk.17.attn_k.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 137/ 340]                 blk.17.attn_k.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 138/ 340]            blk.17.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 139/ 340]                   blk.17.attn_q.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 140/ 340]                 blk.17.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 141/ 340]                   blk.17.attn_v.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 142/ 340]                 blk.17.attn_v.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 143/ 340]                blk.18.attn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 144/ 340]              blk.18.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 145/ 340]               blk.18.ffn_down.weight - [ 5632,  2048,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 146/ 340]               blk.18.ffn_gate.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 147/ 340]                 blk.18.ffn_up.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 148/ 340]                 blk.18.ffn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 149/ 340]               blk.18.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 150/ 340]                   blk.18.attn_k.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 151/ 340]                 blk.18.attn_k.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 152/ 340]            blk.18.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 153/ 340]                   blk.18.attn_q.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 154/ 340]                 blk.18.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 155/ 340]                   blk.18.attn_v.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 156/ 340]                 blk.18.attn_v.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 157/ 340]                blk.19.attn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 158/ 340]              blk.19.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 159/ 340]               blk.19.ffn_down.weight - [ 5632,  2048,     1,     1], type =    f16, converting to q6_K .. size =    22.00 MiB ->     9.02 MiB\n",
            "[ 160/ 340]               blk.19.ffn_gate.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 161/ 340]                 blk.19.ffn_up.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 162/ 340]                 blk.19.ffn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 163/ 340]               blk.19.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 164/ 340]                   blk.19.attn_k.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 165/ 340]                 blk.19.attn_k.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 166/ 340]            blk.19.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 167/ 340]                   blk.19.attn_q.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 168/ 340]                 blk.19.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 169/ 340]                   blk.19.attn_v.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 170/ 340]                 blk.19.attn_v.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 171/ 340]                 blk.2.attn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 172/ 340]               blk.2.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 173/ 340]                blk.2.ffn_down.weight - [ 5632,  2048,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 174/ 340]                blk.2.ffn_gate.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 175/ 340]                  blk.2.ffn_up.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 176/ 340]                  blk.2.ffn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 177/ 340]                blk.2.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 178/ 340]                    blk.2.attn_k.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 179/ 340]                  blk.2.attn_k.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 180/ 340]             blk.2.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 181/ 340]                    blk.2.attn_q.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 182/ 340]                  blk.2.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 183/ 340]                    blk.2.attn_v.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 184/ 340]                  blk.2.attn_v.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 185/ 340]                blk.20.attn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 186/ 340]              blk.20.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 187/ 340]               blk.20.ffn_down.weight - [ 5632,  2048,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 188/ 340]               blk.20.ffn_gate.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 189/ 340]                 blk.20.ffn_up.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 190/ 340]                 blk.20.ffn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 191/ 340]               blk.20.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 192/ 340]                   blk.20.attn_k.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 193/ 340]                 blk.20.attn_k.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 194/ 340]            blk.20.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 195/ 340]                   blk.20.attn_q.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 196/ 340]                 blk.20.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 197/ 340]                   blk.20.attn_v.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 198/ 340]                 blk.20.attn_v.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 199/ 340]                blk.21.attn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 200/ 340]              blk.21.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 201/ 340]               blk.21.ffn_down.weight - [ 5632,  2048,     1,     1], type =    f16, converting to q6_K .. size =    22.00 MiB ->     9.02 MiB\n",
            "[ 202/ 340]               blk.21.ffn_gate.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 203/ 340]                 blk.21.ffn_up.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 204/ 340]                 blk.21.ffn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 205/ 340]               blk.21.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 206/ 340]                   blk.21.attn_k.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 207/ 340]                 blk.21.attn_k.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 208/ 340]            blk.21.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 209/ 340]                   blk.21.attn_q.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 210/ 340]                 blk.21.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 211/ 340]                   blk.21.attn_v.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 212/ 340]                 blk.21.attn_v.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 213/ 340]                blk.22.attn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 214/ 340]              blk.22.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 215/ 340]               blk.22.ffn_down.weight - [ 5632,  2048,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 216/ 340]               blk.22.ffn_gate.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 217/ 340]                 blk.22.ffn_up.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 218/ 340]                 blk.22.ffn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 219/ 340]               blk.22.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 220/ 340]                   blk.22.attn_k.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 221/ 340]                 blk.22.attn_k.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 222/ 340]            blk.22.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 223/ 340]                   blk.22.attn_q.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 224/ 340]                 blk.22.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 225/ 340]                   blk.22.attn_v.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 226/ 340]                 blk.22.attn_v.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 227/ 340]                blk.23.attn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 228/ 340]              blk.23.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 229/ 340]               blk.23.ffn_down.weight - [ 5632,  2048,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 230/ 340]               blk.23.ffn_gate.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 231/ 340]                 blk.23.ffn_up.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 232/ 340]                 blk.23.ffn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 233/ 340]               blk.23.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 234/ 340]                   blk.23.attn_k.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 235/ 340]                 blk.23.attn_k.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 236/ 340]            blk.23.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 237/ 340]                   blk.23.attn_q.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 238/ 340]                 blk.23.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 239/ 340]                   blk.23.attn_v.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 240/ 340]                 blk.23.attn_v.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 241/ 340]                 blk.3.attn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 242/ 340]               blk.3.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 243/ 340]                blk.3.ffn_down.weight - [ 5632,  2048,     1,     1], type =    f16, converting to q6_K .. size =    22.00 MiB ->     9.02 MiB\n",
            "[ 244/ 340]                blk.3.ffn_gate.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 245/ 340]                  blk.3.ffn_up.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 246/ 340]                  blk.3.ffn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 247/ 340]                blk.3.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 248/ 340]                    blk.3.attn_k.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 249/ 340]                  blk.3.attn_k.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 250/ 340]             blk.3.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 251/ 340]                    blk.3.attn_q.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 252/ 340]                  blk.3.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 253/ 340]                    blk.3.attn_v.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 254/ 340]                  blk.3.attn_v.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 255/ 340]                 blk.4.attn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 256/ 340]               blk.4.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 257/ 340]                blk.4.ffn_down.weight - [ 5632,  2048,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 258/ 340]                blk.4.ffn_gate.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 259/ 340]                  blk.4.ffn_up.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 260/ 340]                  blk.4.ffn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 261/ 340]                blk.4.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 262/ 340]                    blk.4.attn_k.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 263/ 340]                  blk.4.attn_k.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 264/ 340]             blk.4.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 265/ 340]                    blk.4.attn_q.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 266/ 340]                  blk.4.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 267/ 340]                    blk.4.attn_v.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 268/ 340]                  blk.4.attn_v.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 269/ 340]                 blk.5.attn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 270/ 340]               blk.5.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 271/ 340]                blk.5.ffn_down.weight - [ 5632,  2048,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 272/ 340]                blk.5.ffn_gate.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 273/ 340]                  blk.5.ffn_up.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 274/ 340]                  blk.5.ffn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 275/ 340]                blk.5.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 276/ 340]                    blk.5.attn_k.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 277/ 340]                  blk.5.attn_k.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 278/ 340]             blk.5.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 279/ 340]                    blk.5.attn_q.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 280/ 340]                  blk.5.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 281/ 340]                    blk.5.attn_v.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 282/ 340]                  blk.5.attn_v.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 283/ 340]                 blk.6.attn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 284/ 340]               blk.6.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 285/ 340]                blk.6.ffn_down.weight - [ 5632,  2048,     1,     1], type =    f16, converting to q6_K .. size =    22.00 MiB ->     9.02 MiB\n",
            "[ 286/ 340]                blk.6.ffn_gate.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 287/ 340]                  blk.6.ffn_up.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 288/ 340]                  blk.6.ffn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 289/ 340]                blk.6.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 290/ 340]                    blk.6.attn_k.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 291/ 340]                  blk.6.attn_k.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 292/ 340]             blk.6.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 293/ 340]                    blk.6.attn_q.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 294/ 340]                  blk.6.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 295/ 340]                    blk.6.attn_v.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 296/ 340]                  blk.6.attn_v.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 297/ 340]                 blk.7.attn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 298/ 340]               blk.7.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 299/ 340]                blk.7.ffn_down.weight - [ 5632,  2048,     1,     1], type =    f16, converting to q6_K .. size =    22.00 MiB ->     9.02 MiB\n",
            "[ 300/ 340]                blk.7.ffn_gate.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 301/ 340]                  blk.7.ffn_up.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 302/ 340]                  blk.7.ffn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 303/ 340]                blk.7.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 304/ 340]                    blk.7.attn_k.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 305/ 340]                  blk.7.attn_k.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 306/ 340]             blk.7.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 307/ 340]                    blk.7.attn_q.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 308/ 340]                  blk.7.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 309/ 340]                    blk.7.attn_v.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 310/ 340]                  blk.7.attn_v.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 311/ 340]                 blk.8.attn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 312/ 340]               blk.8.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 313/ 340]                blk.8.ffn_down.weight - [ 5632,  2048,     1,     1], type =    f16, converting to q6_K .. size =    22.00 MiB ->     9.02 MiB\n",
            "[ 314/ 340]                blk.8.ffn_gate.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 315/ 340]                  blk.8.ffn_up.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 316/ 340]                  blk.8.ffn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 317/ 340]                blk.8.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 318/ 340]                    blk.8.attn_k.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 319/ 340]                  blk.8.attn_k.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 320/ 340]             blk.8.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 321/ 340]                    blk.8.attn_q.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 322/ 340]                  blk.8.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 323/ 340]                    blk.8.attn_v.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 324/ 340]                  blk.8.attn_v.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 325/ 340]                 blk.9.attn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 326/ 340]               blk.9.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 327/ 340]                blk.9.ffn_down.weight - [ 5632,  2048,     1,     1], type =    f16, converting to q6_K .. size =    22.00 MiB ->     9.02 MiB\n",
            "[ 328/ 340]                blk.9.ffn_gate.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 329/ 340]                  blk.9.ffn_up.weight - [ 2048,  5632,     1,     1], type =    f16, converting to q4_K .. size =    22.00 MiB ->     6.19 MiB\n",
            "[ 330/ 340]                  blk.9.ffn_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 331/ 340]                blk.9.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 332/ 340]                    blk.9.attn_k.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 333/ 340]                  blk.9.attn_k.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 334/ 340]             blk.9.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 335/ 340]                    blk.9.attn_q.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 336/ 340]                  blk.9.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 337/ 340]                    blk.9.attn_v.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 338/ 340]                  blk.9.attn_v.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 339/ 340]                     output_norm.bias - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 340/ 340]                   output_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "llama_model_quantize_internal: model size  =  3137.33 MB\n",
            "llama_model_quantize_internal: quant size  =   980.27 MB\n",
            "\n",
            "main: quantize time = 195394.49 ms\n",
            "main:    total time = 195394.49 ms\n",
            "cp: cannot stat 'tdp_stablelm2_ft_merged/ggml-model-Q4_K_M.gguf': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# Running the quantization script\n",
        "!cd llama.cpp && ./llama-quantize \"/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/tdp_stablelm2_ft_merged/stablelm-2-1.6B-F16.gguf\" \"/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/tdp_stablelm2_ft_merged/ggml-model-Q4_K_M.gguf\" Q4_K_M\n",
        "\n",
        "\n",
        "# Download the quantized gguf onto our local machine\n",
        "files.download(\"/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/tdp_stablelm2_ft_merged/ggml-model-Q4_K_M.gguf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "id": "agbV959ZwWl3",
        "outputId": "43adc986-da9e-4f8a-e2ab-1e56ff2d5b19"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_7ecc7e2b-9bd2-4a44-98f3-3915ff036cd9\", \"ggml-model-Q4_K_M.gguf\", 1031442240)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# files.download(\"/content/drive/My Drive/TDP Capstone Grp 7/LLM Model Training/qLoRA/tdp_stablelm2_ft_merged/ggml-model-Q4_K_M.gguf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssD6JUbuVfOQ"
      },
      "source": [
        "### Run and Deploy the Fine-tuned Model (run in local)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awD3zBU0V4j0"
      },
      "source": [
        "Building the Ollama Modelfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mRhfYvwWV4MP"
      },
      "outputs": [],
      "source": [
        "tuned_model_path = \"tdp_stablelm2_ft_merged/ggml-model-Q4_K_M.gguf\"\n",
        "sys_message = \"You are a helpful United Overseas Bank (Singapore) AI chatbot that is capable of handling customer queries. \\\n",
        "  Every response must be detailed and informative. In addition, you should avoid answering questions that are not related to banking with UOB\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GkBPQBNeU7tn"
      },
      "outputs": [],
      "source": [
        "cmds = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lp2kytNkYRLh"
      },
      "outputs": [],
      "source": [
        "base_model = f\"FROM {tuned_model_path}\"\n",
        "template = '''TEMPLATE \"{{ if .System }}<|im_start|>system\n",
        "{{ .System }}<|im_end|>\n",
        "{{ end }}{{ if .Prompt }}<|im_start|>user\n",
        "{{ .Prompt }}<|im_end|>\n",
        "{{ end }}<|im_start|>assistant\n",
        "{{ .Response }}<|im_end|>\n",
        "\"'''\n",
        "\n",
        "params = '''PARAMETER stop <|im_start|>\n",
        "PARAMETER stop <|im_end|>'''\n",
        "\n",
        "system = f'''SYSTEM \"\"\"{sys_message}\"\"\"'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7_SpEzXMY3I7"
      },
      "outputs": [],
      "source": [
        "cmds.append(base_model)\n",
        "cmds.append(template)\n",
        "cmds.append(params)\n",
        "cmds.append(system)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "NQCcbTCUYzDd"
      },
      "outputs": [],
      "source": [
        "def generate_model(cmds):\n",
        "  modelfile = \"\"\n",
        "  for command in cmds:\n",
        "    modelfile += command + \"\\n\"\n",
        "  with open(\"stablelm2.modelfile\", \"w\") as f:\n",
        "    f.write(modelfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "S1iyC4ejY4Rk"
      },
      "outputs": [],
      "source": [
        "generate_model(cmds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLDFw9KDZKsM"
      },
      "source": [
        "If you do not see a modelfile in your working directory, do not proceed any further"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BMlqJV-d-1-"
      },
      "source": [
        "#### **Installing** Ollama and compiling with GGUF file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUlotlMZZPE5",
        "outputId": "6f6d263c-7016-4d5c-900d-984eca0e0bce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NAME                 \tID          \tSIZE  \tMODIFIED    \n",
            "mistral:latest       \tf974a74358d6\t4.1 GB\t7 days ago \t\n",
            "myOwnStablelm2:latest\t1df5ba03896a\t982 MB\t9 days ago \t\n",
            "stablelm2:latest     \t714a6116cffa\t982 MB\t4 weeks ago\t\n",
            "llama3:latest        \t365c0bd3c000\t4.7 GB\t5 weeks ago\t\n",
            "llama3.1:latest      \t91ab477bec9d\t4.7 GB\t5 weeks ago\t\n"
          ]
        }
      ],
      "source": [
        "!ollama list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnkJEVFaZ_Q6"
      },
      "source": [
        "#### Creating a new custom LLM Ollama Model on your Local Machine using the .gguf and modefile\n",
        "\n",
        "The suggestion would be to download the .gguf file and run the code to deploy our model to ollama locally, so that we can call the model for our project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HunL4V0ve5GF"
      },
      "source": [
        "Note: Run the creation of our ollama model from the gguf file on VSC to deploy it locally, after the gguf file has been downloaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "henuFbZMZWEF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25ltransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data 0% ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data 11% ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data 27% ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data 35% ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data 49% ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data 63% ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data 70% ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data 85% ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data 100% ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data 100% \n",
            "using existing layer sha256:ba27dcf43c2c2173dff0ba9f16a046e04d2bee1ed6cb0a98f57385e0e6505f52 \n",
            "using existing layer sha256:62fbfd9ed093d6e5ac83190c86eec5369317919f4b149598d2dbb38900e9faef \n",
            "creating new layer sha256:120976c3fe61e2690c3f3d98567aebb8d98ffcd011403b08a75e498f2ef4982e \n",
            "using existing layer sha256:f02dd72bb2423204352eabc5637b44d79d17f109fdb510a7c51455892aa2d216 \n",
            "creating new layer sha256:bcf18541c31d9e84a767fe9723cf6c1e331920af3d7651fa4bba0e5dfb0613ec \n",
            "writing manifest \n",
            "success \u001b[?25h\n"
          ]
        }
      ],
      "source": [
        "!ollama create betaStableLm2Tdp --file stablelm2.modelfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NAME                   \tID          \tSIZE  \tMODIFIED       \n",
            "betaStableLm2Tdp:latest\tf478475d58b8\t1.0 GB\t10 seconds ago\t\n",
            "mistral:latest         \tf974a74358d6\t4.1 GB\t7 days ago    \t\n",
            "myOwnStablelm2:latest  \t1df5ba03896a\t982 MB\t9 days ago    \t\n",
            "stablelm2:latest       \t714a6116cffa\t982 MB\t4 weeks ago   \t\n",
            "llama3:latest          \t365c0bd3c000\t4.7 GB\t5 weeks ago   \t\n",
            "llama3.1:latest        \t91ab477bec9d\t4.7 GB\t5 weeks ago   \t\n"
          ]
        }
      ],
      "source": [
        "!ollama list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25h\u001b[?25l\u001b[?25l\u001b[2K\u001b[1G\u001b[?25h\u001b[2K\u001b[1G\u001b[?25h\u001b[?2004h>>> \u001b[38;5;245mSend a message (/? for help)\u001b[28D\u001b[0m\u001b[K\n",
            "Use Ctrl + d or /bye to exit.\n",
            ">>> \u001b[38;5;245mSend a message (/? for help)\u001b[28D\u001b[0m\u001b[K\n",
            ">>> \u001b[38;5;245mSend a message (/? for help)\u001b[28D\u001b[0m"
          ]
        }
      ],
      "source": [
        "!ollama run betaStableLm2Tdp"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "VnFiyBOc329l",
        "usT78VPP5Zpm",
        "oRAUF_Vn6Kjz"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0201f1448c0249b89b2fe71bd874fda7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05abd2e1e4f947b2b54bd9b52df3a9a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "070a1e66e98940eb95d3cef2a4d99d9e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "090eb5b8a1c2402eb9e698c10f7b104d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e27a37a2d554637964b940ded4a3add",
            "max": 916645,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db31141c74564eafb9115c3e66c85978",
            "value": 916645
          }
        },
        "09380cc645cc442aa316e6e03afe18d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0962fbf95241460aab6348e7f73185d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d33255960fb4500ba4fbb6d4f8ac70b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa126eea47bc47eab85f04528586a702",
              "IPY_MODEL_1b83eb86128642cdb7461970fbcdd814",
              "IPY_MODEL_f4fe561341d244c48c14e45f5daabfd5"
            ],
            "layout": "IPY_MODEL_92c50421005347c083e114673c137636"
          }
        },
        "12c84a660401439cb322aa2008a19a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13f3a584d5594486be19ed7ef9e0fdcf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14fc6131676d49bd9fb9291a7f38b4c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_575833f960dd4506875881f44fb01949",
            "placeholder": "​",
            "style": "IPY_MODEL_a09acacb19194fd2b7ae959cb941fb0e",
            "value": " 425/425 [00:00&lt;00:00, 1526.40 examples/s]"
          }
        },
        "15a249fa525c4f5da77ad795ed791f07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5edf315263f479eac1f44e2a888d34c",
            "placeholder": "​",
            "style": "IPY_MODEL_6abb9c4a09124dbaa6e6c94c97cf0e89",
            "value": "Map (num_proc=2): 100%"
          }
        },
        "1b83eb86128642cdb7461970fbcdd814": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a8d463f7a754ac1a3821ee563df3cd9",
            "max": 3289069520,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d73e13bd537b4409a70c0492d01ede03",
            "value": 3289069520
          }
        },
        "1ea19c77a3354775ba855808159e796d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e282227485bf44388be7f7e798f19488",
              "IPY_MODEL_c9ab56284a1348ba80a894a11520929b",
              "IPY_MODEL_628edcaad42c49fc99d8124aa03046e0"
            ],
            "layout": "IPY_MODEL_070a1e66e98940eb95d3cef2a4d99d9e"
          }
        },
        "1f7284253958462ea4c543a80a773c03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22a7a65991234125a4311e75552263cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26b8018898ba457cbe99f862b6a7d35b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28b06d3f34c3487db5a949680e7af2fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a394b972188460a8e1dfd67029a347a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ee9ea9c164c43b0b51e722053ec2c6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26b8018898ba457cbe99f862b6a7d35b",
            "max": 121,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c57cce9fb044bec805fabf17dd13430",
            "value": 121
          }
        },
        "3434046db9ce4c4e886f1a19540bafc0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3468089bb5ee470c92391a1017b824d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c01d5a76b93d4980a7403360e677a595",
              "IPY_MODEL_090eb5b8a1c2402eb9e698c10f7b104d",
              "IPY_MODEL_e3c841d07aff448b8dbfc597672b7848"
            ],
            "layout": "IPY_MODEL_6b8e8c9dbc9042c2ba70db5041341bca"
          }
        },
        "38d31a9345a54b36afb185991b289eb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "398d2114becd4bf78ba290b2d7e301ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ae0f756e3834aa1816b3c97cdd48d44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f57c34a13544fb8b57e63e3f6ca62df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13f3a584d5594486be19ed7ef9e0fdcf",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0ea52da58b54ec8940ad3c5e8d4722d",
            "value": 48
          }
        },
        "49bd504e600d469ebd41857c5f193090": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e466de9d9aab4f24a8b34945eab163ef",
            "placeholder": "​",
            "style": "IPY_MODEL_12c84a660401439cb322aa2008a19a0f",
            "value": " 4.24M/4.24M [00:00&lt;00:00, 6.51MB/s]"
          }
        },
        "49ce788a98a345519a5d5748f6214e25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b1dbc2613844998a9b885cf0a27406b",
            "placeholder": "​",
            "style": "IPY_MODEL_b118f0b8d6274bb0877057bccc4724ab",
            "value": "config.json: 100%"
          }
        },
        "49e000824a744fa997eacf82e857e114": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0add396f9134d32bd5d85b5582ac747",
            "placeholder": "​",
            "style": "IPY_MODEL_2a394b972188460a8e1dfd67029a347a",
            "value": "Map (num_proc=2): 100%"
          }
        },
        "4a24b11079ed4dffa5e709d2fcd6a935": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a8d463f7a754ac1a3821ee563df3cd9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b237243c5b14dadb7aafaaf9ad56d7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b5966fd1e06425f917fdf65c5936a9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e27a37a2d554637964b940ded4a3add": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fe90e4917aa4df5aaf53dcab1b35b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15a249fa525c4f5da77ad795ed791f07",
              "IPY_MODEL_3f57c34a13544fb8b57e63e3f6ca62df",
              "IPY_MODEL_ecd8170e95f7459a9b11cb91887e1c39"
            ],
            "layout": "IPY_MODEL_7170ea832f9a4cb0aa9c7581d743b9b8"
          }
        },
        "5104a78a08174ea6865cd8b402a04705": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f032c1f9646847c8a5745808634d12f4",
            "max": 784,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f66101576b9a4d63b8802c52e0e0f69a",
            "value": 784
          }
        },
        "55683e303a3e477ea7a9f1e7bc582ac3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5653ac1286fb4fd48265e4f2a87c1fea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49ce788a98a345519a5d5748f6214e25",
              "IPY_MODEL_60e78d6539414a0f841c49b2a17554eb",
              "IPY_MODEL_9079a2eac26441caa0003091d4a0bb86"
            ],
            "layout": "IPY_MODEL_7f6a46b74d6e4c9cbe351a8ff5539348"
          }
        },
        "575833f960dd4506875881f44fb01949": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57dc961c243b4d9a88f7512fc036cae2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "584e5da9547d4ff7bc90adf28ffb5a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59c35900928d41aa886e73a56d28ddd7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b1dbc2613844998a9b885cf0a27406b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60174b47f1fb4c968a90fff592ca5ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af8502dd84ca461ba2007b05fc8c3905",
            "placeholder": "​",
            "style": "IPY_MODEL_f9ba62604f0e42c69e66d470749895ac",
            "value": " 121/121 [00:00&lt;00:00, 8.45kB/s]"
          }
        },
        "60e78d6539414a0f841c49b2a17554eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a24b11079ed4dffa5e709d2fcd6a935",
            "max": 608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77378f5ffd144bd3816eb22d0e82bf9d",
            "value": 608
          }
        },
        "611289e800484b739a452f6972beabf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "628edcaad42c49fc99d8124aa03046e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cd4e20b2cce48f581cd8f8bb3e6a316",
            "placeholder": "​",
            "style": "IPY_MODEL_05abd2e1e4f947b2b54bd9b52df3a9a8",
            "value": " 2.01M/2.01M [00:01&lt;00:00, 1.87MB/s]"
          }
        },
        "636599867a984788876f71746ac61306": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd35c4a339214fc380b289f4bff2464a",
            "max": 4239399,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86eb74d22fe14228a3eb4e155d3a75d8",
            "value": 4239399
          }
        },
        "6abb9c4a09124dbaa6e6c94c97cf0e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b8e8c9dbc9042c2ba70db5041341bca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c57cce9fb044bec805fabf17dd13430": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c9a54cd07f94024a717002536e88e0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28b06d3f34c3487db5a949680e7af2fb",
            "placeholder": "​",
            "style": "IPY_MODEL_611289e800484b739a452f6972beabf5",
            "value": "generation_config.json: 100%"
          }
        },
        "7170ea832f9a4cb0aa9c7581d743b9b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77378f5ffd144bd3816eb22d0e82bf9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a3f1672e7f546668304e2c2440c30e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49e000824a744fa997eacf82e857e114",
              "IPY_MODEL_b17bf7633de54da6ba7fc5214823cd37",
              "IPY_MODEL_14fc6131676d49bd9fb9291a7f38b4c9"
            ],
            "layout": "IPY_MODEL_09380cc645cc442aa316e6e03afe18d7"
          }
        },
        "7cd4e20b2cce48f581cd8f8bb3e6a316": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f6a46b74d6e4c9cbe351a8ff5539348": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83ff78060dc94bd980f920d93364c0da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbf670d03cb04ad0a5e7d8acc4177bbd",
              "IPY_MODEL_636599867a984788876f71746ac61306",
              "IPY_MODEL_49bd504e600d469ebd41857c5f193090"
            ],
            "layout": "IPY_MODEL_994046c4a89d4319b481403aeb2518e6"
          }
        },
        "86eb74d22fe14228a3eb4e155d3a75d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b69b96a7eb842b69630f069543ca8fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b91b9cd20634b23b9a2e683241854d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5d26b29ddaf49e6878306f267d0c6a6",
              "IPY_MODEL_5104a78a08174ea6865cd8b402a04705",
              "IPY_MODEL_eda5fead2f124a41a074af2d6b1f31aa"
            ],
            "layout": "IPY_MODEL_398d2114becd4bf78ba290b2d7e301ec"
          }
        },
        "8e7d3b7aaab345b6afe30a0f1ccd3224": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9079a2eac26441caa0003091d4a0bb86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3434046db9ce4c4e886f1a19540bafc0",
            "placeholder": "​",
            "style": "IPY_MODEL_df46052c6ad34b869a24f15e9f18f471",
            "value": " 608/608 [00:00&lt;00:00, 17.9kB/s]"
          }
        },
        "920c8c71fa1447fb9e8713240f59e754": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9675b71001a7498faba5fea6c2ecc3bd",
              "IPY_MODEL_d69bc87d52f74657a087a8499d931524",
              "IPY_MODEL_f800765a9e3e4e12a0b114c98780f706"
            ],
            "layout": "IPY_MODEL_eece0ba8d45b460e95c7c7b94a4fc64f"
          }
        },
        "92c50421005347c083e114673c137636": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9435b6e68b924d1c990fbb3d99c59dfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94de1d60000c4bcdb9a012781d991388": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9675b71001a7498faba5fea6c2ecc3bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0201f1448c0249b89b2fe71bd874fda7",
            "placeholder": "​",
            "style": "IPY_MODEL_0962fbf95241460aab6348e7f73185d9",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "989f3ae751404deb9cc1f496fb1386a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "994046c4a89d4319b481403aeb2518e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a09acacb19194fd2b7ae959cb941fb0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8998522442b4ee9ac6da7764bf7263c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae0df6f2ecb5434c8c2a4da20e57e871": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af8502dd84ca461ba2007b05fc8c3905": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0ea52da58b54ec8940ad3c5e8d4722d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b118f0b8d6274bb0877057bccc4724ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b17bf7633de54da6ba7fc5214823cd37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc245434fabe4912a46860704557278c",
            "max": 425,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9435b6e68b924d1c990fbb3d99c59dfc",
            "value": 425
          }
        },
        "b5d26b29ddaf49e6878306f267d0c6a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b69b96a7eb842b69630f069543ca8fb",
            "placeholder": "​",
            "style": "IPY_MODEL_584e5da9547d4ff7bc90adf28ffb5a0d",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "b8f7ce9232cb4a3f844eefc4f910ac78": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c018cecf43f248d79b3c649d4d4d9280": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c01d5a76b93d4980a7403360e677a595": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f7284253958462ea4c543a80a773c03",
            "placeholder": "​",
            "style": "IPY_MODEL_c48dc25df06e403ba89f8df778162286",
            "value": "merges.txt: 100%"
          }
        },
        "c09978d8ce6d4c1c857fd0bf84d0baaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c9a54cd07f94024a717002536e88e0e",
              "IPY_MODEL_2ee9ea9c164c43b0b51e722053ec2c6d",
              "IPY_MODEL_60174b47f1fb4c968a90fff592ca5ad0"
            ],
            "layout": "IPY_MODEL_4b237243c5b14dadb7aafaaf9ad56d7f"
          }
        },
        "c48d320ce6a540859c2d16d92ce34a87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c48dc25df06e403ba89f8df778162286": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9ab56284a1348ba80a894a11520929b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22a7a65991234125a4311e75552263cf",
            "max": 2012401,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b5966fd1e06425f917fdf65c5936a9c",
            "value": 2012401
          }
        },
        "cbf670d03cb04ad0a5e7d8acc4177bbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4997d0bd24746c59f46760c2e321dea",
            "placeholder": "​",
            "style": "IPY_MODEL_fc0899a34b3a41f68099c914a73ba595",
            "value": "tokenizer.json: 100%"
          }
        },
        "d5edf315263f479eac1f44e2a888d34c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d69bc87d52f74657a087a8499d931524": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55683e303a3e477ea7a9f1e7bc582ac3",
            "max": 895,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da2e325a62e3473389846d1d35bb9f56",
            "value": 895
          }
        },
        "d73e13bd537b4409a70c0492d01ede03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da2e325a62e3473389846d1d35bb9f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db31141c74564eafb9115c3e66c85978": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd35c4a339214fc380b289f4bff2464a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df46052c6ad34b869a24f15e9f18f471": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0add396f9134d32bd5d85b5582ac747": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e282227485bf44388be7f7e798f19488": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94de1d60000c4bcdb9a012781d991388",
            "placeholder": "​",
            "style": "IPY_MODEL_8e7d3b7aaab345b6afe30a0f1ccd3224",
            "value": "vocab.json: 100%"
          }
        },
        "e3c841d07aff448b8dbfc597672b7848": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8f7ce9232cb4a3f844eefc4f910ac78",
            "placeholder": "​",
            "style": "IPY_MODEL_c48d320ce6a540859c2d16d92ce34a87",
            "value": " 917k/917k [00:00&lt;00:00, 1.91MB/s]"
          }
        },
        "e466de9d9aab4f24a8b34945eab163ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecd8170e95f7459a9b11cb91887e1c39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59c35900928d41aa886e73a56d28ddd7",
            "placeholder": "​",
            "style": "IPY_MODEL_f4f46740704e4baa9ceb9d01b63ce3c4",
            "value": " 48/48 [00:00&lt;00:00, 159.28 examples/s]"
          }
        },
        "eda5fead2f124a41a074af2d6b1f31aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8998522442b4ee9ac6da7764bf7263c",
            "placeholder": "​",
            "style": "IPY_MODEL_c018cecf43f248d79b3c649d4d4d9280",
            "value": " 784/784 [00:00&lt;00:00, 35.6kB/s]"
          }
        },
        "eece0ba8d45b460e95c7c7b94a4fc64f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f032c1f9646847c8a5745808634d12f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4997d0bd24746c59f46760c2e321dea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4f46740704e4baa9ceb9d01b63ce3c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4fe561341d244c48c14e45f5daabfd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57dc961c243b4d9a88f7512fc036cae2",
            "placeholder": "​",
            "style": "IPY_MODEL_38d31a9345a54b36afb185991b289eb8",
            "value": " 3.29G/3.29G [02:31&lt;00:00, 12.2MB/s]"
          }
        },
        "f66101576b9a4d63b8802c52e0e0f69a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f800765a9e3e4e12a0b114c98780f706": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9fa68db8e804f47bd251e29b17a0640",
            "placeholder": "​",
            "style": "IPY_MODEL_3ae0f756e3834aa1816b3c97cdd48d44",
            "value": " 895/895 [00:00&lt;00:00, 60.0kB/s]"
          }
        },
        "f9ba62604f0e42c69e66d470749895ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9fa68db8e804f47bd251e29b17a0640": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa126eea47bc47eab85f04528586a702": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae0df6f2ecb5434c8c2a4da20e57e871",
            "placeholder": "​",
            "style": "IPY_MODEL_989f3ae751404deb9cc1f496fb1386a1",
            "value": "model.safetensors: 100%"
          }
        },
        "fc0899a34b3a41f68099c914a73ba595": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc245434fabe4912a46860704557278c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
